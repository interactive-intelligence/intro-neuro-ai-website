{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r2yx31WhTqox"
   },
   "source": [
    "### CIFAR-10 CNN Project\n",
    "\n",
    "##### How to work through this project:\n",
    "- Go cell by cell and finish the marked #TODO's\n",
    "- You don't need to touch the code marked between the `#---------#`. Those are puzzle pieces that your code will fit into!\n",
    "    - However, I **STRONGLY** encourage you to understand every single line between those blocks. They are essential!\n",
    "    - It is crucial that your variable names are what we expect them to be, or the puzzle pieces won't fit.\n",
    "- Tutorials/helpful information will be placed in the `.md` cells above the \"work\" cells. Consult them if you are stuck.\n",
    "- If you REALLY cannot find the correct code to make the cell run, consult the `[proj]-ans.ipynb`.\n",
    "- The final product (what we expect to see if you run all the cells consecutively) will be placed in the `answers/` directory.\n",
    "    - Chances are your output won't be the exact same (stochasticity!) but it should be similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sc0vIjz1Tqo2"
   },
   "outputs": [],
   "source": [
    "# Get used to these imports!\n",
    "#----------------------------------------------------------------#\n",
    "import random\n",
    "#To install: pip install numpy\n",
    "import numpy as np\n",
    "#To install: pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#To install: pip install torchvision\n",
    "import torchvision as tv\n",
    "import torchvision.transforms as transforms\n",
    "#To install: pip install torch (not GPU compatible)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#To install: pip install Pillow\n",
    "from PIL import Image\n",
    "#----------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VVwjjbHVTqo4",
    "outputId": "e743fab3-5530-4cde-b87d-3c5f1c85842c"
   },
   "outputs": [],
   "source": [
    "# Below is the train/test data from CIFAR-10. Try and find their shapes\n",
    "# This is different than normal MNIST! You will see this below\n",
    "#----------------------------------------------------------------#\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     # normalization - Adjusts features so that they are on a similar scale\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "train_set = tv.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "test_set = tv.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "# Helps us convert numbers to labels\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "#----------------------------------------------------------------#\n",
    "## TODO: What is the shape of our inputs and outputs?\n",
    "# print the number of images in train_set and test_set,\n",
    "# then print out the dimension of each image\n",
    "\"\"\"\n",
    "IMPORTANT: Each element of the dataset is a tuple (image, label).\n",
    "THIS IS DIFFERENT FROM MNIST!!!\n",
    "\n",
    "Tips:\n",
    "- Use len to get length of dataset\n",
    "- To get the first element of a tuple, use [0]\n",
    "- use .numpy() to convert tensor to numpy array, then write .shape to get shape\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pATz1Y5uTqo6"
   },
   "source": [
    "The following code block is short, but ***incredibly important***. It shows how to set up a **Dataloader** which is needed to pass data through a neural network. Try to get familiar with the syntax.\n",
    "\n",
    "Notice how even though we have changed the Dataset, the dataloaders are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hDEhuMWHTqo7"
   },
   "outputs": [],
   "source": [
    "# Creates dataloaders from the CIFAR-10 dataset\n",
    "batch_size = 20\n",
    "#----------------------------------------------------------------#\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "#----------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOPcqpryTqo8"
   },
   "source": [
    "Lets visualize the data! This will be different than last time since we are working with dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "qHrJ9BGRTqo8",
    "outputId": "f76fe0c2-d772-4e66-84e1-b8e2a2d89d13"
   },
   "outputs": [],
   "source": [
    "# Visualizes num_to_viz digits and labels with plt.matshow and plt.show. Notice how reshape is used to get the data into proper format for visualization.\n",
    "# Note the use of reshape!\n",
    "#----------------------------------------------------------------#\n",
    "num_to_viz = 3\n",
    "toPilImage = transforms.ToPILImage()\n",
    "\n",
    "for i in range(num_to_viz):\n",
    "    j = random.randrange(50000)\n",
    "    # unnormalize image\n",
    "    image_to_viz = toPilImage(train_set[j][0] / 2 + 0.5)\n",
    "    image_to_viz_label = train_set[j][1]\n",
    "    plt.imshow(image_to_viz)\n",
    "    plt.title(classes[image_to_viz_label])\n",
    "    plt.show()\n",
    "#----------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2AziHGYTqo9"
   },
   "source": [
    "So far, this has been similar to the MNIST-DNN Project. When does it diverge? Well first we are going to make a DNN to try and classify these fashion images and then check the accuracy we get. Then we will compare it to the accuracy of a CNN on the **exact same data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iCUv5tKSTqo9"
   },
   "outputs": [],
   "source": [
    "# Goal: Make a neural network that can classify CIFAR-10\n",
    "# No example network provided this time! Refer back to Unit 2 if youre stuck on how to make a DNN\n",
    "\n",
    "## TODO: Create the following required NN class that can work with CIFAR-10 data, and then instantiate a model\n",
    "\n",
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!#\n",
    "###! MAKE SURE YOUR NEURAL NETWORK HAS AT LEAST 3 HIDDEN LAYERS AND DOES NOT HAVE HARDCODED LAYER SIZE VALUES!###\n",
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!#\n",
    "\n",
    "# CIFAR10_DNN: The name of your class\n",
    "# model: An instance of CIFAR10_DNN\n",
    "\"\"\"\n",
    "Tips:\n",
    "- Think about what input and output sizes you want\n",
    "- Hidden layers can be most anything, just make sure to reduce gradually\n",
    "- Remind yourself what activations are and why they are useful\n",
    "- Make sure to name your class \"CIFAR10_DNN\"\n",
    "- Instead of hardcoding the numbers in for the layer sizes, make them passable parameters\n",
    "- Make sure to actually make your model using model = CIFAR10_DNN(...) as the last line\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nYJho-CaTqo-"
   },
   "source": [
    "__Now your task will be to train and test the model__. Again, refer back to **unit 2** if any of this has slipped from your memory (that is totally fine). However, don't get discouraged at the difficulty because none of this is new! You did it before and can do it again. We have provided the loss function and optimizer, but nothing else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qHBEEVhfTqo_",
    "outputId": "85e1814e-6109-41d6-f67f-bb93207cc708"
   },
   "outputs": [],
   "source": [
    "# Feel free to mess with the code in here once you have finished the project to see what effect it will have.\n",
    "# For now, though, simply read and accept the syntax as-is\n",
    "#----------------------------------------------------------------#\n",
    "loss_func = nn.CrossEntropyLoss() # Mean Squared Error\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # Adaptive Optimizer\n",
    "#----------------------------------------------------------------#\n",
    "\n",
    "## TODO: Implement the training loop for your model. Reference unit 2 example if stuck."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEcrHaZnTqo_"
   },
   "source": [
    "Here is the testing loop again. Run it to see how your accuracy is!\n",
    "\n",
    "Then run all your code and see what your **final accuracy** is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KYerGNExTqpA",
    "outputId": "69a86e5d-6040-4dbf-ccde-859e8608e4e4"
   },
   "outputs": [],
   "source": [
    "# Note the use of torch.no_grad() and torch.max(). Be sure you know what they are doing\n",
    "#----------------------------------------------------------------#\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 3*32*32)\n",
    "        outputs = model(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the 10000 test images: {acc} %')\n",
    "#----------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5zM5N8gTqpA"
   },
   "source": [
    "Expected accuracy: ~50%\n",
    "\n",
    "Great job! We have made a DNN classifier for CIFAR-10. Hopefully you are comfortable making models now, **since you will now be making a CNN!**\n",
    "\n",
    "Let's see if the CNN's architectural differences will allow it to score higher than a standard DNN.\n",
    "\n",
    "Check out these resources. If you get stuck, look at the third resource. We will do something similar:\n",
    "- [Conv2d Documentation](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)\n",
    "- [F_MNIST with a CNN Tutorial](https://medium.com/@nutanbhogendrasharma/pytorch-convolutional-neural-network-with-mnist-dataset-4e8a4265e118)\n",
    "- [Training a Classifier](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mrkbRGC1TqpB"
   },
   "outputs": [],
   "source": [
    "# Goal: Make a convolutional neural network that can classify CIFAR-10\n",
    "# Provided below is a syntactical example of a CNN, study it and try and make one that will fit CIFAR-10\n",
    "\n",
    "class CNN_EXAMPLE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_EXAMPLE, self).__init__()\n",
    "\n",
    "        # Structure\n",
    "        input_channels = 1 # Represents the number of color channels an image has. We are working with grayscale so it will be 1. RGB would be 3.\n",
    "\n",
    "        # Convolutional Layers\n",
    "        self.conv_l1 = nn.Conv2d(in_channels=input_channels, out_channels=5, kernel_size=(3, 3), stride=1)\n",
    "\n",
    "        # Feedforward Layers\n",
    "        self.ff1 = nn.Linear(845, 10) # The input number selected here is dependent on the size of the output from the previous layers. You can do some printing of shapes to figure out what it should be.\n",
    "\n",
    "        # Maxpool Layers\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=(2,2), stride=2)\n",
    "\n",
    "        # Activations\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.conv_l1(input)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        print(x.detach().numpy().shape) # Can help you find the necessary input size for the feedforward part!!!\n",
    "\n",
    "        output = self.ff1(x)\n",
    "\n",
    "        return output\n",
    "\n",
    "## TODO: Create the following required NN class that can work with CIFAR-10 data, and then instantiate a model\n",
    "\n",
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!#\n",
    "###! MAKE SURE YOUR NEURAL NETWORK HAS AT LEAST 2 CONVOLUTION LAYERS! THE EXAMPLE ONLY HAS 1 !###\n",
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!#\n",
    "\n",
    "# CIFAR10_CNN: The name of your class\n",
    "# cnn_model: An instance of CIFAR10_CNN\n",
    "\"\"\"\n",
    "Tips:\n",
    "- The transition from convolutional to linear layers is tough\n",
    "    - Print out the shape of the object right before it is supposed to go into the linear layer to find out how big the layer input size should be\n",
    "    - **You may need to make the training loop in advance to do this**\n",
    "- When you flatten, do it exactly as shown in the example (x = torch.flatten(x, 1)) to ensure you flatten across the right dimension\n",
    "- Ignore the first dimension when printing out the shape of x before flattening (as shown above in the example), since it is the batch size\n",
    "- Make sure to name your class \"CIFAR10_CNN\"\n",
    "- Instead of hardcoding the numbers in for the input channels and output size, make them passable parameters\n",
    "- Make sure to actually make your model using f_model = CIFAR10_CNN(...) as the last line\n",
    "- Our images are in RGB, so the first conv layer should have 3 input channels!\n",
    "\"\"\"\n",
    "\n",
    "#! Answer (one of many!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YNI24xkSTqpC"
   },
   "source": [
    "Below is where you should make your training loop. It will be very similar to the DNN training loop **with some slight alterations**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b7jipHeLTqpC",
    "outputId": "37730304-659b-4f7c-e865-d27063785528"
   },
   "outputs": [],
   "source": [
    "# Feel free to mess with the code in here once you have finished the project to see what effect it will have.\n",
    "# For now, though, simply read and accept the syntax as-is\n",
    "#----------------------------------------------------------------#\n",
    "loss_func = nn.CrossEntropyLoss() # Mean Squared Error\n",
    "# You're allowed to play with the learning rate here\n",
    "optimizer = torch.optim.Adam(cnn_model.parameters(), lr=0.0007) # Adaptive Optimizer\n",
    "#----------------------------------------------------------------#\n",
    "\n",
    "## TODO: Implement the training loop for your model\n",
    "\n",
    "\"\"\"\n",
    "Tips:\n",
    "- Is there any need to reshape at all? Think about what a convolution acts on dimension-wise\n",
    "- Everything except for the thing mentioned above will be the same!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J9T7zeTgTqpD"
   },
   "source": [
    "Here is the testing loop again. Run it to see how your accuracy is!\n",
    "\n",
    "Then run all your code and see what your **final accuracy** is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ow-bPKlrTqpD",
    "outputId": "47ce12c2-9d30-4ef0-8887-9abf38363edb"
   },
   "outputs": [],
   "source": [
    "# Note the use of torch.no_grad() and torch.max(). Be sure you know what they are doing\n",
    "#----------------------------------------------------------------#\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        outputs = cnn_model(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the 10000 test images: {acc} %')\n",
    "#----------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alJwweEUTqpE"
   },
   "source": [
    "Expected accuracy ~70%\n",
    "\n",
    "Looks like the CNN did do better! Feel free to mess with the parameters to see if you can get a better score. **Note that CNNs are more finnicky than DNNs, so your score may tank sometimes**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TgTa02l9TqpE"
   },
   "source": [
    "### Congratulations on completing the project! Check your results with the notebook in the `answers` directory and then send your final accuracy to your club/channel/mentor!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "test (conda env)",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "f3204eab9621eb34088b9e71fcdb754ce79a12fd6a4cd73f4898b86bb3d12718"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
