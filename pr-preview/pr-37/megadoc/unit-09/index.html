
<!DOCTYPE html>
<html lang="en-US">
<head>
 <meta charset="UTF-8">
 <meta http-equiv="X-UA-Compatible" content="IE=Edge">
<link rel="stylesheet" href="/https://intro-neuro-ai-website-pr-preview.onrender.com/pr-preview/pr-37/assets/css/just-the-docs-default.css">
    <script src="/https://intro-neuro-ai-website-pr-preview.onrender.com/pr-preview/pr-37/assets/js/vendor/lunr.min.js"></script>
  <script src="/https://intro-neuro-ai-website-pr-preview.onrender.com/pr-preview/pr-37/assets/js/just-the-docs.js"></script>
 <meta name="viewport" content="width=device-width, initial-scale=1">
<title>Unit 09 | I2 Intro Neuro/AI</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="Unit 09" />
<meta name="author" content="Interactive Intelligence" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Welcome to Interactive Intelligence’s Introduction to Neuro/AI crash course!" />
<meta property="og:description" content="Welcome to Interactive Intelligence’s Introduction to Neuro/AI crash course!" />
<link rel="canonical" href="https://course.uw-i2.org/https://intro-neuro-ai-website-pr-preview.onrender.com/pr-preview/pr-37/megadoc/unit-09/" />
<meta property="og:url" content="https://course.uw-i2.org/https://intro-neuro-ai-website-pr-preview.onrender.com/pr-preview/pr-37/megadoc/unit-09/" />
<meta property="og:site_name" content="I2 Intro Neuro/AI" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Unit 09" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","author":{"@type":"Person","name":"Interactive Intelligence"},"description":"Welcome to Interactive Intelligence’s Introduction to Neuro/AI crash course!","headline":"Unit 09","url":"https://course.uw-i2.org/https://intro-neuro-ai-website-pr-preview.onrender.com/pr-preview/pr-37/megadoc/unit-09/"}</script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.css"
    integrity="sha384-bYdxxUwYipFNohQlHt0bjN/LCpueqWz13HufFEV1SUatKs1cm4L6fFgCi1jT643X" crossorigin="anonymous">
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.js"
    integrity="sha384-Qsn9KnoKISj6dI8g7p1HBlNpVx0I8p1SvlwOldgi3IorMle61nQy4zEahWYtljaz" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/auto-render.min.js"
    integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"></script>
  <script>
    document.addEventListener("DOMContentLoaded", function () {
      renderMathInElement(document.body, {
        // customised options
        // • auto-render specific keys, e.g.:
        delimiters: [
          { left: '$$', right: '$$', display: true },
          { left: '$', right: '$', display: false },
          { left: '\\(', right: '\\)', display: false },
          { left: '\\[', right: '\\]', display: true }
        ],
        // • rendering keys, e.g.:
        throwOnError: false
      });
    });
  </script>
<body>
  <a class="skip-to-main" href="#main-content">Skip to main content</a>
  <svg xmlns="http://www.w3.org/2000/svg" class="d-none">
  <symbol id="svg-link" viewBox="0 0 24 24">
 <title>Link</title>
  <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link">
   <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path>
  </svg>
</symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
 <title>Menu</title>
  <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu">
   <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line>
  </svg>
</symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
 <title>Expand</title>
  <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right">
   <polyline points="9 18 15 12 9 6"></polyline>
  </svg>
</symbol>
<symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link">
 <title id="svg-external-link-title">(external link)</title>
 <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line>
</symbol>
    <symbol id="svg-doc" viewBox="0 0 24 24">
 <title>Document</title>
  <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file">
   <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline>
  </svg>
</symbol>
    <symbol id="svg-search" viewBox="0 0 24 24">
 <title>Search</title>
  <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search">
    <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line>
  </svg>
</symbol>
<symbol id="svg-copy" viewBox="0 0 16 16">
 <title>Copy</title>
  <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16">
   <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/>
   <path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/>
  </svg>
</symbol>
<symbol id="svg-copied" viewBox="0 0 16 16">
 <title>Copied</title>
  <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16">
   <path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/>
   <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/>
  </svg>
</symbol>
</svg>
 <div class="side-bar">
 <div class="site-header">
    <a href="/https://intro-neuro-ai-website-pr-preview.onrender.com/pr-preview/pr-37/" class="site-title lh-tight">
  I2 Intro Neuro/AI
</a>
    <a href="#" id="menu-button" class="site-button">
      <svg viewBox="0 0 24 24" class="icon"><use xlink:href="#svg-menu"></use></svg>
    </a>
 </div>
 <nav aria-label="Main" id="site-nav" class="site-nav">
     <ul class="nav-list"><li class="nav-list-item"><a href="/https://intro-neuro-ai-website-pr-preview.onrender.com/pr-preview/pr-37/announcements/" class="nav-list-link">Announcements</a><li class="nav-list-item"><a href="/https://intro-neuro-ai-website-pr-preview.onrender.com/pr-preview/pr-37/staff/" class="nav-list-link">Course Staff</a><li class="nav-list-item"><a href="/https://intro-neuro-ai-website-pr-preview.onrender.com/pr-preview/pr-37/graduates/" class="nav-list-link">Graduates</a><li class="nav-list-item active"><a href="#" class="nav-list-expander" aria-label="toggle links in Megadoc category">
            <svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg>
          </a><a href="/https://intro-neuro-ai-website-pr-preview.onrender.com/pr-preview/pr-37/megadoc/" class="nav-list-link">Megadoc</a><ul class="nav-list"><li class="nav-list-item "><a href="/https://intro-neuro-ai-website-pr-preview.onrender.com/pr-preview/pr-37/megadoc/unit-01/" class="nav-list-link">Unit 01</a><li class="nav-list-item "><a href="/https://intro-neuro-ai-website-pr-preview.onrender.com/pr-preview/pr-37/megadoc/unit-02/" class="nav-list-link">Unit 02</a><li class="nav-list-item "><a href="/https://intro-neuro-ai-website-pr-preview.onrender.com/pr-preview/pr-37/megadoc/unit-03/" class="nav-list-link">Unit 03</a><li class="nav-list-item "><a href="/https://intro-neuro-ai-website-pr-preview.onrender.com/pr-preview/pr-37/megadoc/unit-04/" class="nav-list-link">Unit 04</a><li class="nav-list-item "><a href="/https://intro-neuro-ai-website-pr-preview.onrender.com/pr-preview/pr-37/megadoc/unit-05/" class="nav-list-link">Unit 05</a><li class="nav-list-item "><a href="/https://intro-neuro-ai-website-pr-preview.onrender.com/pr-preview/pr-37/megadoc/unit-06/" class="nav-list-link">Unit 06</a><li class="nav-list-item "><a href="/https://intro-neuro-ai-website-pr-preview.onrender.com/pr-preview/pr-37/megadoc/unit-07/" class="nav-list-link">Unit 07</a><li class="nav-list-item "><a href="/https://intro-neuro-ai-website-pr-preview.onrender.com/pr-preview/pr-37/megadoc/unit-08/" class="nav-list-link">Unit 08</a><li class="nav-list-item  active"><a href="/https://intro-neuro-ai-website-pr-preview.onrender.com/pr-preview/pr-37/megadoc/unit-09/" class="nav-list-link active">Unit 09</a><li class="nav-list-item "><a href="/https://intro-neuro-ai-website-pr-preview.onrender.com/pr-preview/pr-37/megadoc/unit-10/" class="nav-list-link">Unit 10</a><li class="nav-list-item "><a href="/https://intro-neuro-ai-website-pr-preview.onrender.com/pr-preview/pr-37/megadoc/unit-11/" class="nav-list-link">Unit 11</a><li class="nav-list-item "><a href="/https://intro-neuro-ai-website-pr-preview.onrender.com/pr-preview/pr-37/megadoc/unit-12/" class="nav-list-link">Unit 12</a><li class="nav-list-item "><a href="/https://intro-neuro-ai-website-pr-preview.onrender.com/pr-preview/pr-37/megadoc/unit-13/" class="nav-list-link">Unit 13</a><li class="nav-list-item "><a href="/https://intro-neuro-ai-website-pr-preview.onrender.com/pr-preview/pr-37/megadoc/unit-A/" class="nav-list-link">Unit A</a><li class="nav-list-item "><a href="/https://intro-neuro-ai-website-pr-preview.onrender.com/pr-preview/pr-37/megadoc/unit-B/" class="nav-list-link">Unit B</a></ul><li class="nav-list-item"><a href="/https://intro-neuro-ai-website-pr-preview.onrender.com/pr-preview/pr-37/schedule/" class="nav-list-link">Schedule</a></ul>
 </nav>
   <footer class="site-footer">
      This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll.
   </footer>
</div>
 <div class="main" id="top">
   <div id="main-header" class="main-header">
<div class="search">
 <div class="search-input-wrap">
    <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search I2 Intro Neuro/AI" aria-label="Search I2 Intro Neuro/AI" autocomplete="off">
    <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label>
 </div>
 <div id="search-results" class="search-results"></div>
</div>
   <nav aria-label="Auxiliary" class="aux-nav">
 <ul class="aux-nav-list">
     <li class="aux-nav-list-item">
        <a href="https://interactive-intelligence.github.io" class="site-button"
        >
          UW Interactive Intelligence Website
        </a>
 </ul>
</nav>
</div>
   <div id="main-content-wrap" class="main-content-wrap">
   <nav aria-label="Breadcrumb" class="breadcrumb-nav">
     <ol class="breadcrumb-nav-list">
         <li class="breadcrumb-nav-list-item"><a href="/https://intro-neuro-ai-website-pr-preview.onrender.com/pr-preview/pr-37/megadoc/">Megadoc</a>
       <li class="breadcrumb-nav-list-item"><span>Unit 09</span>
     </ol>
   </nav>
     <div id="main-content" class="main-content" role="main">
         <h1 id="unit-9-fairness-and-theory">
    <a href="#unit-9-fairness-and-theory" class="anchor-heading" aria-labelledby="unit-9-fairness-and-theory"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Unit 9: Fairness and Theory
</h1>
<p>Machine learning models are interesting, but they have substantive effects on the world they are deployed in. How can we make these models fairer, safer, less biased, and/or more responsible? Is this even rigorously possible? (Some researchers suggest not!) What is the source of bias? (“Garbage In, Garbage Out” is a stunted answer, and maybe even misleading.) These are all questions which are intimately linked with <em>deep learning theory</em>, a growing field which attempts to explain how neural networks work rather than attempting to advance the SOTA in performance or a similar task. Because of the close relationship between theory and fairness research, we will be exploring them together. After going through this unit, you will be able to reason about deep learning at a very abstract level (a powerful tool for research and experimentation); identify the core theoretical essence of various models and approaches; think critically about what the concepts of ‘bias’, ‘fairness’, ‘robustness’, ‘responsibility’, and ‘fairness’ mean and how we might build models which better embody these values.</p>
<p>It is recommended to read the listed papers in order, and to at least skim each one.</p>
<p><strong>Theory</strong></p>
<ol>
 <li><a href="https://en.wikipedia.org/wiki/Universal_approximation_theorem">Universal Approximation Theorem</a>. While it’s not necessary to completely understand the proof, make sure you understand at least what the theorem is stating and why it is an interesting result.
 <li>Read this <a href="https://medium.com/analytics-vidhya/you-dont-understand-neural-networks-until-you-understand-the-universal-approximation-theorem-85b3e7677126">introductory article</a> written by Andre (the author of this unit) on the UAT, then <a href="https://twitter.com/ylecun/status/1409940043951742981?lang=en">this Twitter thread</a> of Yann Lecun blasting it. Then, read Lecun et al.’s paper <a href="https://arxiv.org/pdf/2110.09485.pdf">Learning in High Dimension Always Amounts to Extrapolation</a>. Lastly, read this document of <a href="https://gowrishankar.info/blog/deep-learning-is-not-as-impressive-as-you-think-its-mere-interpolation/">the debate on Twitter</a>. Now think about what your position in this debate is. What is interpolation? What is extrapolation? Do neural networks extrapolate? Is this a meaningful concept at all, and if not, what might be a more meaningful one? Keep thinking about these questions throughout the theory section.
 <li><a href="https://arxiv.org/pdf/1912.02292.pdf">Deep Double Descent: Where Bigger Models and More Data Hurt</a>. A ‘classic’ empirical finding which points towards a weirdness of deep learning models as opposed to less parametrized, classical models.
 <li><a href="https://lilianweng.github.io/posts/2019-03-14-overfit/">Are Deep Neural Networks Dramatically Overfitted?</a> A great technical blog post giving more theory on the question of overfitting.
 <li><a href="https://arxiv.org/pdf/1611.03530.pdf">Understanding Deep Learning Requires Rethinking Generalization</a>. Important empirical results and speculative theoretical work.
 <li><a href="https://arxiv.org/pdf/2011.00241.pdf">Methods for Pruning Deep Neural Networks</a>. You can skim this one, but it’s a good coverage of pruning – an empirical method whose success is surprising and is worth thinking about.
 <li><a href="https://arxiv.org/abs/1803.03635">The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks</a>. This is our second major theory paper. What explains the results found and answers the questions raised in 2, 3, 4, and 5? The Lottery Ticket Hypothesis is a compelling theory.
 <li><a href="https://arxiv.org/pdf/1905.01067.pdf">Deconstructing Lottery Tickets: Zeros, Signs, and the Supermask</a>. A further investigation into the Lottery Ticket Hypothesis.
 <li><a href="https://arxiv.org/pdf/1911.13299.pdf">What’s Hidden in a Randomly Weighted Neural Network?</a> A fascinating result from the Lottery Ticket Hypothesis.
 <li>Neural Tangent Kernel. Choose at least one of these to read.
   <ol>
     <li><a href="https://lilianweng.github.io/posts/2022-09-08-ntk/">https://lilianweng.github.io/posts/2022-09-08-ntk/</a>
     <li><a href="https://blog.ml.cmu.edu/2019/10/03/ultra-wide-deep-nets-and-the-neural-tangent-kernel-ntk/">https://blog.ml.cmu.edu/2019/10/03/ultra-wide-deep-nets-and-the-neural-tangent-kernel-ntk/</a>
     <li><a href="https://rajatvd.github.io/NTK/">https://rajatvd.github.io/NTK/</a>
     <li><a href="https://www.inference.vc/neural-tangent-kernels-some-intuition-for-kernel-gradient-descent/">https://www.inference.vc/neural-tangent-kernels-some-intuition-for-kernel-gradient-descent/</a>
   </ol>
 <li><a href="https://arxiv.org/pdf/2105.04026.pdf">The Modern Mathematics of Deep Learning</a>. A landmark work in developing a mathematical theory of deep learning. Skim sections 2.3, 3.2, 3.3, and 4. Make sure you at least understand the results at a high level.
 <li><a href="https://arxiv.org/pdf/2207.05221.pdf">Language Models (Mostly) Know What They Know</a>. A theoretical method for probing language model knowledge reveals interesting epistemic structures.
 <li>Bonus: <a href="https://transformer-circuits.pub/2021/framework/index.html">A Mathematical Framework for Transformer Circuits</a>. Think you know how transformers work? Think again!
</ol>
<p><strong>Fairness, Responsibility, Safety</strong></p>
<ol>
 <li><a href="https://arxiv.org/pdf/1908.09635.pdf">A Survey on Bias and Fairness in Machine Learning</a>. A good and comprehensive survey of general concerns and approaches to addressing bias in machine learning problems.
 <li><a href="https://arxiv.org/pdf/1609.07236.pdf">On the (im)possibility of fairness</a>. No need to read it too in detail; skimming it and understanding the main result is fine. Argues that different mathematized components of algorithmic fairness are fundamentally incompatible with each other in the ideal.
 <li><a href="https://econcs.seas.harvard.edu/files/econcs/files/green_icml18.pdf">The Myth in the Methodology: Towards a Recontextualization of Fairness in Machine Learning</a>. We’ve got it all wrong, philosopher Lily Hu shows us. Fairness cannot be mathematized.
 <li><a href="https://arxiv.org/ftp/arxiv/papers/2006/2006.01770.pdf">What’s sex got to do with fair machine learning?</a> An investigation of gender variables in machine learning models.
 <li><a href="https://scholar.harvard.edu/files/lilyhu/files/what_is_race.pdf">What is ‘race’ in algorithmic discrimination on the basis of race?</a> An investigation of race variables in machine learning methods.
 <li><a href="https://www.sciencedirect.com/science/article/pii/S2666389921000611">Moving beyond “algorithmic bias is a data problem”</a>. Sara Hooker takes on the pervasive idea of GIGO (Garbage In, Garbage Out) suggests that data is the root source of bias.
 <li><a href="https://arxiv.org/abs/1911.05248">What Do Compressed Deep Neural Networks Forget?</a> An empirical follow-up from the previous opinion piece. How do different compression methods affect model performance?
   <ol>
     <li>Optional: <a href="https://arxiv.org/pdf/2010.03058.pdf">Characterizing and Mitigating Bias in Compact Models</a>. Related work if you are interested in additional research in this direction.
   </ol>
 <li><a href="https://www.amacad.org/publication/curious-case-commonsense-intelligence">The Curious Case of Common Sense</a>. Our very own professor Yejin Choi reflects on the difficulty of codifying common sense into AI models.
   <ol>
     <li>You may be interested in Yejin Choi’s research papers, each of which address different dimensions of common sense reasoning: <a href="https://homes.cs.washington.edu/~yejin/">https://homes.cs.washington.edu/~yejin/</a>
   </ol>
 <li><a href="https://arxiv.org/pdf/2110.07574.pdf">Can Machines learn Morality? The Delphi Experiment</a>. An attempt to train a language model to understand commonsense morality. You can play with the Delphi model at <a href="https://delphi.allenai.org/">https://delphi.allenai.org/</a>.
 <li><a href="https://arxiv.org/abs/2212.08073">Constitutional AI: Harmlessness from AI Feedback</a>. An important proposal for a framework to regulate AI with AI from a set of constitutional principles.
 <li><a href="https://www.anthropic.com/index/predictability-and-surprise-in-large-generative-models">Predictability and Surprise in Large Generative Models</a>. An empirical and theoretical investigation of the difficulties of regulating LLMs.
 <li><a href="https://arxiv.org/abs/2009.06489">The Hardware Lottery</a>. Thinking about how AI development is constrained by the hardware available.
 <li><a href="https://www.pnas.org/doi/full/10.1073/pnas.2115730119">Socially situated artificial intelligence enables learning from human interaction</a>. A very interesting paper from our very own professor Ranjay Krishna on how humans can more actively engage with and shape AI models.
 <li><a href="https://arxiv.org/pdf/2108.07258.pdf">On the Opportunities and Risks of Foundation Models</a>. A classic in AI safety. Read the introduction (section 1) and “Society” (section 5) at minimum.
 <li><a href="https://www.newyorker.com/magazine/2019/09/30/the-dark-side-of-techno-utopianism">The Dark Side of Techno-Utopianism</a>. An accessible and thoughtful conclusion to this unit: what is our role in tech, and is it as rosy as we think it is?
</ol>
<p><strong>Task</strong></p>
<p>Read the <a href="https://arxiv.org/abs/2005.14165">GPT-3 paper</a>, the <a href="https://cdn.openai.com/papers/gpt-4-system-card.pdf">GPT-4 model card</a>, or the <a href="https://arxiv.org/pdf/2201.08239.pdf">LaMDA paper</a> (or another recent large language model paper). Focus on the discussions on safety and fairness. Drawing upon the sources in both the theory and the fairness sections of this unit, criticize the evaluations – identify what is mistaken, what assumptions are made, what is socially problematic, what possible biases may have been unidentified or which lie latent in the design, etc.</p>
     </div>
   </div>
<div class="search-overlay"></div>
 </div>
  
