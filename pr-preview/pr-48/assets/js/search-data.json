{"0": {
    "doc": "AI Ethics",
    "title": "AI Ethics",
    "content": "Welcome to the AI Ethics section of the I2 course! In this pivotal module, we’ll journey through the ethical maze of AI, grounding our understanding in real-world applications and dilemmas. We will cover the following subsections of AI Ethics: . | Introduction to AI Ethics | Key Ethical Issues in AI - From Bias to Accountability | AI, Privacy, and Security | Ethical Dilemmas and Real-World Applications | Ethics in AI Research and Applications | Global Perspectives on AI Ethics | . ",
    "url": "/pr-preview/pr-48/content/ai_ethics/",
    
    "relUrl": "/content/ai_ethics/"
  },"1": {
    "doc": "AI Ethics",
    "title": "Literacy &amp; Technical Track Content",
    "content": "Task 1: . Read the articles and watch the videos below. Answer any synthesis questions placed along the way. Video: Introduction to AI Ethics (7 min) . Article: Principles of AI Ethics (3 min) . Synthesis Questions: . | How have the core principles of AI ethics evolved over time? | In what ways does AI ethics differ from ethics in traditional technologies? | Why is ethics crucial in the realm of AI more than ever? | Relate a historical event or invention to the current ethical concerns in AI. | How can understanding the past inform our future ethical decisions in AI? | . Video: Bias Explained (3 min) . Synthesis Questions: . | `How has bias in AI affected real-world decision-making in sectors like finance or healthcare? | In what ways might biased data skew the outcomes of an AI system? | Describe a notable case where AI bias had real-world implications. | How can fairness be quantified and ensured in AI? | Can absolute fairness be achieved, or is it a continuum? | . Video: Data Privacy and AI (7 min) . Article: Social Impact of AI and Data Privacy Issues(8 min) . Synthesis Questions: . How has AI impacted personal privacy in the age of social media? Contrast traditional data breaches with the potential dangers posed by AI-driven breaches. What challenges do global privacy regulations pose to AI developers? How can individuals protect their data in AI-driven applications? Relate the Cambridge Analytica scandal to the importance of privacy in AI. Video: Self-driving Cars: An Ethical Quandary (7 min) . Article: Case Study: Ethical Pitfalls in Healthcare AI (8 min) . Synthesis Questions: . | How do self-driving cars display the ethical challenges posed by AI? | Do you think an increase in self driving vehicles would be beneficial or not? | Relate the lessons from a real-world healthcare AI failure to broader AI ethics. | How can companies ensure they're ethically responsible while innovating? | Do the pros outweigh the cons when it comes to autonomous robots in healthcare? | . Video: The Ethical Boundaries of AI in Warfare (7 min) . Article: The Dual-Use Dilemma in AI Research (7 min - Only Read First Half) . Synthesis Questions: . | How does the potential use of AI in warfare raise ethical red flags? | Where should the line be drawn between research and application in contentious AI areas? | Describe a situation where AI research might unintentionally harm society. | What responsibilities do AI researchers have beyond their immediate work? | Reflect on an AI advancement that can be both beneficial and harmful. | . Video: Cultural Nuances in AI Ethics (6 min) . Synthesis Questions: . | How might Western and Eastern perspectives on AI ethics differ? | Describe a cultural or societal factor that could influence AI ethics in a particular region. | How can companies navigate global ethical standards when deploying AI? | Why is it essential for AI ethics to be globally inclusive? | Reflect on the challenges of implementing a universal ethical framework for AI. | . Task 2: . Create the following small presentation, with the expectation of presenting to a group. Choose an existing AI system or technology, dissect its ethical aspects, unearth potential pitfalls, devise actionable remedies, and craft an impactful presentation. You can use the presentation software of your choice. Example Slide Structure: . Slide 1 - Title Slide . | Title: Your Choice | Your name | Date | . Slide 2 - Introduction . | Brief background on the AI system or technology chosen | Why analyzing ethics is important for this system | Overview of the ethical analysis approach | . Slide 3 - Ethical Analysis . | Details on potential pitfalls, biases, fairness issues | Real-world examples and implications | Frame as risks that need to be addressed | . Slide 4 - Proposed Solutions . | Outline ideas and recommendations to improve ethics | Explain how proposals directly address risks | Emphasize feasibility and impact | End with call to action | . The presentation should focus on thorough analysis of the real-world ethics issues with the chosen AI system and actionable, impactful proposals to address them. ",
    "url": "/pr-preview/pr-48/content/ai_ethics/#literacy--technical-track-content",
    
    "relUrl": "/content/ai_ethics/#literacy--technical-track-content"
  },"2": {
    "doc": "Announcements",
    "title": "Announcements",
    "content": " ",
    "url": "/pr-preview/pr-48/announcements/",
    
    "relUrl": "/announcements/"
  },"3": {
    "doc": "Announcements",
    "title": "Course Website Overhaul",
    "content": "Mar 16 &middot; 0 min read Massive Changes: The course website has been massively overhauled, with content now existing in both technical and literacy tracks, allowing for a much larger range of students within the course. The I2 Grimoire is now created and integrated with the website. Colab notebook links now pull straight from GitHub, allowing for centralization of updates. FInally, the aesthetics of the website with regards to content has been greatly reorganized. This should all contribute to a much more streamlined learning experience! . ",
    "url": "/pr-preview/pr-48/announcements/",
    
    "relUrl": "/announcements/"
  },"4": {
    "doc": "Announcements",
    "title": "Unit 1 Updated",
    "content": "Oct 12 &middot; 0 min read ML Unit Upgrade: The Machine Learning Unit (Unit 1) has gotten an overhaul. Due to Medium articles being locked behind a paywall, some of the items were outdated. In addition, I wanted to give a more in depth explanation as to how ML algorithms are formulated, with the example being basic linear regression. Please reach out to me if there is anything you see issue with. - Varun Ananth . ",
    "url": "/pr-preview/pr-48/announcements/",
    
    "relUrl": "/announcements/"
  },"5": {
    "doc": "Announcements",
    "title": "Migration to Google Colab",
    "content": "Oct 10 &middot; 0 min read Notebooks in repo soon obsolete: For ease-of-use and accessibility, we have decided to migrate the .ipynb files stored in this repo over to Google Colaboratory. This removes the need to set up an environment and install Anaconda on your personal machine. Colab has many libraries pre-installed and they can be easily imported without much hassle. As of now, only the Unit 1 notebook has been migrated due to some pending updates. The links should all point to Colab soon though. Cheers! . ",
    "url": "/pr-preview/pr-48/announcements/",
    
    "relUrl": "/announcements/"
  },"6": {
    "doc": "Announcements",
    "title": "How to use/contribute",
    "content": "Mar 27 &middot; 1 min read How to use: Take a look at the “Schedule” tab to see how UW I2 uses this website/megadoc. You can take our schedule but since we are on a quarter system it has just 10 weeks of content. All you have to do to run a course like this is create a schedule/syllabus like we have, and have someone able to give a lecture each week on the upcoming unit. All learning + projects are contained on this website! . How to contribute: If you wish to add to this repository of knowledge. please consult the wiki tab of this repo: Website Repository Wiki . ",
    "url": "/pr-preview/pr-48/announcements/",
    
    "relUrl": "/announcements/"
  },"7": {
    "doc": "Announcements",
    "title": "Site Creation!",
    "content": "Mar 26 &middot; 2 min read Hello and welcome to the Interactive Intelligence Intro to Neuro/AI Course website! This website is designed as a template that shows you how to run a course such as this, as well as resources to do so. Here is a short story of how this came to be: In the winter of 2022, a group of individuals saw the need for a Neuro/AI club at the University of Washington Seattle (the university did not even have an active ML club at the time). The club, now known as Interactive Intelligence, was formed on the premise of studying and researching on intelligence in systems. Often times this lended itself to philosophical discussions about AI and what AGI would mean for the world. As the club progressed, project groups were formed and within one year the club had presented posters at two conferences and had one paper concerning Reinforcement Learning accepted and published in a journal. Things were picking up steam. As more and more people heard about the club, we had new recruits join. Unfortunately, we had no rigorous methods of education and many people were left to their own devices to learn these difficult Neuro/AI concepts. This led to a lull in motivation from newer members who found the prospect of digesting all this information simply impossible. This is where the Intro course came in. UW I2 members banded together and in just 2 weeks created the framework for the course you see today. It was refined through a pilot course and by the Spring of 2023, we were able to publish our megadoc on this website. The megadoc is over 40 pages of Neuro/AI content on these topics: . | ML . | Linear Regression | SVM | PCA | K-Means Clustering | . | DL . | Neural network “anatomy” | Backpropagation calculus | . | Neuroanatomy . | Neurons | Action potentials | Major brain modules | . | The Visual System . | Primary visual cortex | . | Computer Vision . | Convolutions | Convolutional neural networks | . | Reinforcement Learning . | Key RL vocabulary | Q, V, Bellman Equations | Deep Q Learning | Epsilon greedy explore-exploit | . | Movement . | The cerebellum | . | Language Modeling . | Word Embeddings | Recurrent neural networks | Backpropagation through time | Truncated backpropagation through time | Transformers | Huggingface | . | AI Fairness/Theory . | TBD | . | Pain in RL/Neuroscience/Cognitive Science . | Biological pain in the context of RL | MaxPain Algorithm | . | Networks and Systems of the Brain . | Nature vs. Nurture | Brain Networks | . | . And also: . | Pytorch | Jupyter notebooks | LaTeX | Self-learning skills | . This course is a very basic survey of Neuro/AI and was made to get people excited about intelligence research. We wanted to share this amazing resource with others that wish to use it in their own club. If you need any assistance getting this up and running, please contact the education lead in the “Creators” tab. Happy Learning! . ",
    "url": "/pr-preview/pr-48/announcements/",
    
    "relUrl": "/announcements/"
  },"8": {
    "doc": "Basic Neuroanatomy",
    "title": "Basic Neuroanatomy",
    "content": "Welcome to the first lesson studying the most powerful and intelligent computer known to date – the brain. We will begin by studying what exactly it is. This is called neuroanatomy, and luckily for us, MIT OpenCourseware has a fabulous lecture on exactly that, which we will pair with some nice quick overviews from none other than Mr. Paul Andersen. In addition, we will attempt to tie in topics from the deep learning unit to get you thinking more about NeuroAI. Have a look! . ",
    "url": "/pr-preview/pr-48/content/basic_neuro/",
    
    "relUrl": "/content/basic_neuro/"
  },"9": {
    "doc": "Basic Neuroanatomy",
    "title": "Literacy &amp; Technical Track Content",
    "content": "Task 1: . Watch the videos below, and answer any synthesis questions placed along the way. First, we will begin with Mr. Andersen’s lovely introduction to the structure of the foundation of our biological computation: the neuron! . Video 1: The Neuron! . Synthesis Questions: . | Recall the main parts of a neuron and list their functions. Write 1 sentence for each. | Fill out the following sentence: An action potential travels from the direction of the __, along the __, before reaching the __. | What happens if a neuron becomes unmyelinated? | What is a synapse? What does it do? | Now that you understand the basics of a biological neuron, how is it similar/different to a neuron in a Neural Network? Feel free to review content from Unit 2 if needed. | . Bonus Video: If you are interested in the gritty details of how computation works biologically, I suggest this video as a bonus: The Action Potential (the brain is like a salty banana!) . Next, a crash course on the large modules of the brain before we go even deeper into the amazing functions of the brain. Video 2: The Brain: Structure and Function . Synthesis Questions: . | What distinguishes the forebrain, midbrain, and hindbrain? | What are several parts of the midbrain and what are their functions? | How did we discover what function(s) certain areas of the brain have? | What are the 4 lobes of the brain and their general functions? Write 2 sentences for each. | . Watch and understand this beautiful lecture, then answer the synthesis questions provided below. Video 3: MIT Neuroanatomy Lecture . Synthesis Questions: . | What are the four major parts of the brain? | Summarize the main functions of each of the four major components above, or jot down some details about each | What is a receptive field? | Describe characteristics of a cortical area. Find your favorite cortical area not described in the lecture and describe some things that make it interesting :) | . Congratulations! That was a lot of neuroscience! On to some more creative ways of learning in the project section. Task 2: . Complete the following writing activity. There is no programming for this project. Instead, we have provided a $\\LaTeX$ template for you to fill out. | If you are unaware of what $\\LaTeX$ is, you can read about it here. | . I would recommend taking a look at Overleaf to edit/compile $\\LaTeX$ code. Simply copy the code in the template into a blank Overleaf project and type your answers into the TODO areas. Be sure to hit the “Recompile” button to see your work. Since this is the “project” section of the unit, your responses to the questions we provide should be more complex than your responses to the synthesis questions. GH Link: Unit 3 Template (30 min) . The questions in the template are also written below: . Unfortunately, we have neither brains nor creatures for you to dissect. However, for this project, we will be asking you to use your imagination and newfound biological and artificially-intelligible knowledge to . | Describe several advantages and disadvantages of biological computation with the brain compared to machine learning | Speculate what aspects of the architecture of the brain may cause these advantages or disadvantages, and similarly comment on aspects of machine learning’s architecture | Brainstorm some marvelous schemes for integrating advantages from both ways of computing. Draw, write, scribble etc… When you are done, do a quick google for your best ideas to see if anyone has researched or tried them already! | . Whatever you are able to conjure up, have something to show for it to demonstrate your knowledge about basic neuroanatomy! . ",
    "url": "/pr-preview/pr-48/content/basic_neuro/#literacy--technical-track-content",
    
    "relUrl": "/content/basic_neuro/#literacy--technical-track-content"
  },"10": {
    "doc": "Build a Brain",
    "title": "Unit 11: Building a Brain: Networks and Systems",
    "content": "It would be negligent not to begin by acknowledging the inadequacy of this chapter. The connectivity and wiring of the brain as well as the genetics and epigenetics that comprise it are far from fully understood, and these resources are merely scratching the surface of a profound ocean of literature and undiscovered territory of building the systems of a mind. Nonetheless, we begin with a lecture investigating the genetic and learned nature of human behaviors. Task 1: 10. Development, Nature &amp; Nurture I . Synthesis Questions: . | What is one possible mechanism for building knowledge from parts of the brain present at birth? What kinds of knowledge might be innate and \"precursory\"? . | Why might it be useful for those precursors of knowledge to be innate rather than learned? | Google and find 1-2 other possible rudimentary or innate processes in the brain. Do any machine learning techniques use similar innate predispositions or ingrained knowledge? | . | What is perceptual narrowing? Are there analogous processes, protocols, or side effects in machine learning? What are possible downsides and upsides of the effect? . | What might you wish you could learn faster, and what might be a cost to having neural architectures that support that kind of learning? | . | If humans are uniquely suited to recognizing faces, what might be a useful analogous skill in machine learning which may support more human-like behavior? | . Task 2: Next, briefly skim the questions below then indulge in this scintillating lecture describing brain modules and the discovery of their connected wiring! . Start watching at 8:40, 21. Brain Networks . For your reference, a voxel is a 3D pixel. Think of it as a minecraft block of the brain. Also a term used in computer graphics. Synthesis Questions: . | What is white matter? Why does it matter? | What is a connectivity fingerprint? . | Why might we care about the connectivity similarities of other species and what implications might findings in this research have? | . | Describe three large connections between major regions in the brain and what those regions do, using Google if necessary. | What is the default mode network? What purpose is it hypothesized to serve? . | If you were to build an analog of the DMN in a machine learning network placed in your favorite video game as an environment, what function would you design it to serve? | . | Hypothesize how multiple demand regions might work and why they might be necessary. I don't know the right answer here so go nuts. | . ",
    "url": "/pr-preview/pr-48/addcontent/build_a_brain/#unit-11-building-a-brain-networks-and-systems",
    
    "relUrl": "/addcontent/build_a_brain/#unit-11-building-a-brain-networks-and-systems"
  },"11": {
    "doc": "Build a Brain",
    "title": "Project Spec:",
    "content": "There is no programming for this project. Instead, we have provided a LaTeX template for you to fill out. | If you are unaware of what $\\LaTeX$ is, you can read about it here. | . I would recommend taking a look at Overleaf to edit/compile $\\LaTeX$ code. Simply copy the code in the template into a blank Overleaf project and type your answers into the TODO areas. Be sure to hit the “Recompile” button to see your work. GH Link: Unit 11 Template (40 min) . The questions in the template are also written below: . Ohhh this one’s good. I’m tapping my fingers together like Dr. Evil. You are designing an egg. It will become a lifeform on a new planet. The planet is almost completely covered in water. Small islands made from underwater volcanoes dot the surface. The gravity is stronger on this planet and the biodiversity is lower than on Earth. There is less direct sunlight and fewer living organisms in general. Your task is to design the brain and the phenotypes of a successful organism on this new planet, using some of the neuroscience and machine learning principles you have learned so far. Your designed brain and nervous system will be translated into genetic instructions and inserted into an egg that will be sent to the new planet. Be as specific as you can so your egg doesn’t become a mutant! . If you are stuck, here are some options for getting started . | What do you consider a successful organism? | What kinds of traits would support this success; what kinds of organisms on Earth have these traits? | What parts of the brain support these traits and what kind of machine learning algorithms might also exhibit these abilities? | How might these different traits and abilities need to work together, or connect? | . ",
    "url": "/pr-preview/pr-48/addcontent/build_a_brain/#project-spec",
    
    "relUrl": "/addcontent/build_a_brain/#project-spec"
  },"12": {
    "doc": "Build a Brain",
    "title": "Build a Brain",
    "content": " ",
    "url": "/pr-preview/pr-48/addcontent/build_a_brain/",
    
    "relUrl": "/addcontent/build_a_brain/"
  },"13": {
    "doc": "Deinforcement Learning",
    "title": "Unit 10: Cognitive Science and Psychology of Reward and Pain",
    "content": "Task: This unit is very simple. Read our paper! (1 hr) . Paper: Deinforcement Learning v2 . Post your thoughts/questions if you have any! Be sure to review Unit 6 if you need a refresher on Reinforcement Learning. ",
    "url": "/pr-preview/pr-48/addcontent/cogsci_pain/#unit-10-cognitive-science-and-psychology-of-reward-and-pain",
    
    "relUrl": "/addcontent/cogsci_pain/#unit-10-cognitive-science-and-psychology-of-reward-and-pain"
  },"14": {
    "doc": "Deinforcement Learning",
    "title": "Deinforcement Learning",
    "content": " ",
    "url": "/pr-preview/pr-48/addcontent/cogsci_pain/",
    
    "relUrl": "/addcontent/cogsci_pain/"
  },"15": {
    "doc": "Computer Vision",
    "title": "Computer Vision",
    "content": "Hello and welcome to the Computer Vision section of the I2 course! Here we will approach CV from a deep learning perspective, to connect better with other units. ",
    "url": "/pr-preview/pr-48/content/computer_vision/",
    
    "relUrl": "/content/computer_vision/"
  },"16": {
    "doc": "Computer Vision",
    "title": "Technical Track Content",
    "content": "Task 1: . Navigate to the relevant section of the I2 Grimoire using the link below. Read the textbook and answer all synthesis questions to the best of your ability. Be sure to save these somewhere for future reference. I2 Grimoire: Computer Vision . Task 2: . Solve the coding challenges within the Jupyter notebook linked below (through Colab). If you encounter any issues with the notebook not functioning as described, please let us know! . Please ask questions as you work through this project. Be sure to discuss with others in your group if you have one! Share your answers as you like, the goal is to learn and we’re not holding grades over your head. In this project, you will be implementing a Convolutional Neural Network (CNN)! I would suggest to read up on what CIFAR-10 is. before starting since this is the data you will be working with. Colab Link: Computer Vision Colab Notebook (1 hr) . When you are finished with your code, independently verify that it works and have fun with it! If you add any additional functionality be sure to talk about it with others and give them ideas. Remember that this is all for your learning, so do your best and don’t stress! . Congratulations! You now understand the basics of Convolutional Neural networks! . ",
    "url": "/pr-preview/pr-48/content/computer_vision/#technical-track-content",
    
    "relUrl": "/content/computer_vision/#technical-track-content"
  },"17": {
    "doc": "Computer Vision",
    "title": "Literacy Track Content",
    "content": "Task 1: . Read the article below, and answer any synthesis questions placed along the way. In the deep learning unit, we talked about how deep neural networks work on a very general level. Today, we’re going to talk about a new type of neural network, called a Convolutional Neural Network (CNN). These are neural networks that are specifically designed to process images. While neural networks resemble the way the human brain works, CNNs resemble the way the human vision system works. Often, a CNN is a subsection of a larger neural network: it’s like a group of layers that exists to process images really efficiently. Let’s think back to our discussion of neural networks in unit 2. Recall that we used the MNIST dataset, which contains images of handwritten numbers (here’s a picture to remind you, with credit): . Near the end of the article, we mentioned that as we kept training our neural network, the computer would begin to pick out patterns associated with each number (like ones usually being a straight vertical line, or zeroes being a circle). But how exactly does the computer figure that out? How does the neural network “realize” what a one, a zero, or any other number looks like? . This is where the convolutional layer comes in. A CNN uses its convolutional layers to identify patterns and utilize them to analyze images. A convolutional layer would pick out the features that distinguish one number from the others. Recall the structure of a general neural network. Notice that every single node in the input layer is connected to every single node in the hidden layer. Remember, every node in the input layer corresponds to a pixel in the image. Our pictures of handwritten numbers contain 784 pixels (28 x 28), which means there are 784 nodes in the input layer. This means we have a lot of connections between the input layer and the first hidden layer, and the first hidden layer and the second hidden layer, and so on. The reason the neural network is set up like this is because it assumes that information about every pixel influences every other pixel. But that’s not necessarily true! For example, in each image in the MNIST dataset, the dark pixels tend to be close to other dark pixels, and the light pixels tend to be close to other light pixels. Also, the patterns associated with a given number are not exactly the same every time. Take a look at the image below (credit) and notice how there are slight differences in the way the numbers are written (e.g. the number 7 vs. 7 with a line through it). We need the computer to recognize that these are just variations on the exact same number. CNNs account for both of these things, reducing the number of input nodes and allowing for variations in the pixels when identifying features in an image. Now we’re going to get into how CNNs actually work, using a very simple image of a handwritten number. Take a look at the image below, which shows the number 8. We’ve assigned a numerical value to each pixel, like was discussed in Unit 2. The first thing a CNN does is use filters to identify the locations of features in the image. In our example, the most important feature of an 8 is an ellipse, because an 8 is made of two ellipses stacked on top of each other. So let’s use a filter to identify any ellipses in the image. At first, our filter just contains random numbers—but through backpropagation, it starts to resemble the shape of the feature we’re looking for (an ellipse). Below is an example of what the correct filter would look like. Next, we put the filter over the image and compute the dot product of the filter and the portion of the image that it overlaps. This involves multiplying the value in the filter by the value of the pixel underneath, and adding up all the products. Take a look at the example below. Notice that the feature in the filter (the ellipse) doesn’t perfectly match up with the pixels underneath it, so our dot product ends up being 4. Then, we shift our filter over by one and do the same thing. The distance by which we move our filter is called the stride. Notice that in this next example, the feature in the filter perfectly matches with the pixels underneath, so our dot product is much larger (8). We’ll continue shifting the filter until we’ve covered the entire image (there will probably be a lot of overlap). We keep track of all these dot products in a feature map. The feature map is useful because it tells us the general locations of the feature we’re tracking. Our feature map is a 3 by 3 matrix because we apply the filter nine times overall (you can try shifting the filter and calculating the dot products yourself!). Remember, we said that when the filter perfectly matched the pixels underneath (i.e., there was an ellipse in the image), the dot product was 8. The feature map has two 8s, which tells us that there are two ellipses in the image: in the top middle of the image and in the bottom middle of the image. This fits with what we know an 8 should look like: two ellipses stacked on top of each other! . The entire process we just did, of converting an image into a feature map, is called a convolution. The image we’re using, again, is really simple: it only has one distinguishing feature, which is its ellipses. If our image has multiple features (e.g. multiple lines, angles, edges, curves, etc.), we would use a different feature map for each one, and do convolutions for each feature all at the same time! . Next, we’re going to simplify this information a little bit using a strategy called pooling. Pooling means to reduce our feature map into an even smaller matrix that contains the most important information from each “region” of the image. Our image is a little too simple to pool any further, but below is an example of how that would work (credit). Here, the entire top left corner is simplified to just the largest value, and so on for the other regions. This gives us a simplified understanding of the feature map overall. The example below uses “max pooling,” which means it takes the largest value from each region to represent the region as a whole. There are other types of pooling as well, such as “average pooling,” which takes the average of the region to represent the overall region. We repeat the convolution-pooling cycle until our feature map (or maps, if we have multiple features) is sufficiently small. Finally, we plug our resulting feature maps into a fully connected layer, which is like a regular old neural network. Before, all our features were analyzed independently in different convolutions. Here, we’re putting everything together and using all our collected information to classify our image. We do this by taking all of our small, pooled feature maps, flattening them into a column vector, and treating this column vector as the input layer to a standard neural network, which then predicts what the final image is. Take a look at the image below for an example (credit). This was a lot of information, so please reach out to someone if you’re having trouble with these concepts! Now lets watch the following videos and answer the associated questions. Video 1: How Convolutional Neural Networks work (12 min) . Note: Watch from 13:54 onward to answer the questions below. Before that is mainly review from this article (but you may find it useful to skim through, as it covers helpful math concepts!). Synthesis Questions . | How is backpropagation used in CNNs, and how does it differ from backpropagation in standard neural networks? | What outcomes can a designer achieve from adjusting the hyperparameters or architecture of a CNN? | Can you think of an example of when we can use a CNN on non-image data? | . Video 2: But what is a convolution? (14 min) . Note: Watch up to 13:42 in this video; the rest is beyond the scope of this course. Synthesis Questions . | What is the name for the smaller grid that convolves over a larger image? . | Hint: Starts with a \"k\" | . | What are some examples of what you can do to images if you convolve them with special matrices? | How does Gaussian blur \"work\"? | What is the name for the actual operation that occurs when the smaller grid is overlaid on the larger one? . | When each element of the corresponding pixels are multiplied then summed. | . | Give an example of a 3x3 matrix that would not do anything to the image it convolves over. Why does it not impact the image? . | This is also known as the \"do-nothing\" matrix | . | . Task 2: . Complete the following writing activity. The non-technical project for this unit will involve some writing! Choose 3 of the prompts below and write at least 200 (meaningful!) words on each one! We will not be strictly grading you on correctness or anything like that. This is an opportunity to deeply engage with the material you have just learned about, and creatively connect it to neuroscience! . | How are CNNs inspired by the human visual system? | What are some similarities and differences between CNNs and the human visual system? | How is the pooling layer in CNNs related to the brain’s visual processing? | What ways does the convolutional layer in CNNs resemble the receptive field in the visual system? | Reflecting on you have learned from this unit, what is one thing you found to be most interesting? | What is one concept from this unit that you would like to learn more about and why? | . ",
    "url": "/pr-preview/pr-48/content/computer_vision/#literacy-track-content",
    
    "relUrl": "/content/computer_vision/#literacy-track-content"
  },"18": {
    "doc": "Neuroscience & Creativity",
    "title": "Unit B: Neuroscience of Creativity",
    "content": "Are you curious about the mysterious force of invention, art, mathematics, and more that seems to allow the mind to expand beyond the information it was given to create beautiful new ideas? This is creativity, and with neuroscience, we can begin to dissect it such that we can begin to recreate it. Task 1: Listen or watch the following podcast (also available on Spotify if you prefer) and answer the Synthesis questions! . The Science of Creativity &amp; How to Enhance Creative Innovation - Huberman Lab . ",
    "url": "/pr-preview/pr-48/addcontent/creative_neuro/#unit-b-neuroscience-of-creativity",
    
    "relUrl": "/addcontent/creative_neuro/#unit-b-neuroscience-of-creativity"
  },"19": {
    "doc": "Neuroscience & Creativity",
    "title": "Neuroscience & Creativity",
    "content": " ",
    "url": "/pr-preview/pr-48/addcontent/creative_neuro/",
    
    "relUrl": "/addcontent/creative_neuro/"
  },"20": {
    "doc": "Deep Learning",
    "title": "Deep Learning",
    "content": "Hello and welcome to the Deep Learning section of the I2 course! Like the machine learning unit, we’re going to split our content into literacy and technical understanding. ",
    "url": "/pr-preview/pr-48/content/deep_learning/",
    
    "relUrl": "/content/deep_learning/"
  },"21": {
    "doc": "Deep Learning",
    "title": "Technical Track Content",
    "content": "Task 1: . Navigate to the relevant section of the I2 Grimoire using the link below. Read the textbook and answer all synthesis questions to the best of your ability. Be sure to save these somewhere for future reference. I2 Grimoire: Deep Learning . Task 2: . Solve the coding challenges within the Jupyter notebook linked below (through Colab). If you encounter any issues with the notebook not functioning as described, please let us know! . Please ask questions as you work through this project. Be sure to discuss with others in your group if you have one! Share your answers as you like, the goal is to learn and we’re not holding grades over your head. In this project, you will be implementing a Deep Neural Network (DNN)! I would suggest to read up on what MNIST is before starting since this is the data you will be working with. Colab Link: Deep Learning Colab Template (1 hr) . When you are finished with your code, independently verify that it works and have fun with it! If you add any additional functionality be sure to talk about it with others and give them ideas. Remember that this is all for your learning, so do your best and don’t stress! . Congratulations! You now understand the basics of Deep Neural Network structure, how they learn, and how to create one using Python! . ",
    "url": "/pr-preview/pr-48/content/deep_learning/#technical-track-content",
    
    "relUrl": "/content/deep_learning/#technical-track-content"
  },"22": {
    "doc": "Deep Learning",
    "title": "Literacy Track Content",
    "content": "Task 1: . Read the article below, and answer any synthesis questions placed along the way. Simply put, we use neural networks to make computers process information in a way similar to how the human brain processes information. Human brains use biological neural networks to process information. They send data from neuron to neuron in the form of electrical signals. A neural network attempts to replicate this processing using a computer. First, let’s look at the structure of a neural network. You may have seen an image like this before: . The input layer is where we feed in the information we want our network to process. We give it information in the form of a single column vector. The output layer gives us the probabilities corresponding with our inputs, with one node corresponding to each outcome. For example, suppose we want our neural network to identify pictures of dogs. First, we’d input a picture of a dog (more on how inputs work later!). Our output layer would have two nodes: one representing the probability that the image was a dog, and one representing the probability that it wasn’t. Note that the values in the output nodes always sum up to one! If our neural network was, say 90% sure that the inputted image had a dog, the “yes dog” output node would output 90%, and the “not dog” output node would output 10%. Finally, the hidden layer is where all the processing happens. Going back to our dog example, this is where the computer figures out whether the picture has a dog or not. It does this by identifying common features between all pictures that have dogs and distinguishing features between all pictures that don’t. This hidden layer gets developed using training data. This is input data that’s been labeled with the “right answer”—in our dog analogy, it’s a bunch of images that are labeled “dog” or “not dog.” We feed one of these images into the neural network, let it make a prediction, and then tell it the right answer. This is where the learning happens. The computer uses the right answer to “learn” from its mistakes and adjust the weights and connections between the nodes. It does this via a process called backpropagation, which we’ll learn more about in the rest of the homework. This layer is called a hidden layer because often times, humans can’t understand the math involved in these computations. Remember, we aren’t telling the computer what makes a dog different from a non-dog: it makes these connections itself using math. These connections are so intricate that we humans can’t understand them, in the same way we can’t understand the fine details of how neurons transmit information in the human brain. Like the human brain, we can control the input state, or what information is provided, and we can give feedback on the output state, or what information is spit out. Let’s look at an example. Imagine I want my computer to recognize handwritten numbers and convert them into text. How might we do that? . First of all, we need to give the computer some examples. We’re going to use the MNIST database, which contains thousands of images of handwritten digits, each one labeled with its actual number. Here’s an example (Source): . Let’s define our output layer. We want the output nodes to represent all possible outcomes. So instead of a yes-no output, like in our dog-not dog example, let’s ask the network to output the probability that each digit is represented—one node is the probability of a 0, one is the probability of a 1, and so on. This gives us 10 nodes in our output layer, each corresponding to a digit. Now let’s set up our input layer. As previously stated, the input has to be a single column vector of numbers. How do we convert these images to a vector? . We can assign each pixel in the image to a position in the vector. Our images are all 28x28 pixels, so positions 1-28 can represent the first row of pixels, positions 29-56 can represent the second row, and so on. Take a look at the image below for how this might work in a very simple 4x4 image. The numerical value for each pixel can correspond to the color of the pixel. All the pictures in our dataset are in grayscale, so each pixel will be assigned a number corresponding to how bright or dark it is—0 for totally white pixels, 1 for totally black pixels, and decimals in between based on how light or dark the pixel is. Then, we fill in the vector accordingly. The image below shows how this would work in the previous example—note that because we only have two colors, white and purple, we assign white pixels a 0 and purple pixels a 1. Now that we know how to input our images into the neural network, we can start training! The MNIST database has 60,000 designated training images. We’re going to flatten each one into a vector and feed it into the neural network. Then the neural network will give us an output back. The first several are going to be pretty bad because the computer is still figuring out the connections between different images. But eventually it’ll start to realize that a “1” is usually a long vertical line, and an “8” is usually two ellipses on top of each other. As it starts to make these connections, the network makes better and better predictions. Once we’ve exhausted our training data, and the computer has made all its connections, we can test our network. In addition to training data, the dataset has 10,000 designated testing images. Like the training data, these are also labeled: the difference is that the network doesn’t learn from them. We just use them to verify the accuracy of our network. This was a good introduction. Now lets turn to some amazing videos on the topic of Neural Networks that will deepen your understanding. Watch the following videos and answer the associated questions. Video 1: But what is a neural network? | Chapter 1, Deep learning (20 min) . Synthesis Questions . | What is a neuron (in terms of Neural Networks) and what does its \"activation\" represent? . | Bonus: Research and consider the correlation between a biological neuron and an artificial neuron. How are they similar/different? | . | What is a network layer? How is it connected to other network layers? | How is a picture of a digit decomposed into a network layer? | What does the final layer of a neural network represent? | What are weights? What are biases? Can you describe in English how information is passed from one layer to the next? | A neural network **IS/IS NOT** just a very highly parameterized function (Choose one) | What is the purpose of the sigmoid function? | . Video 2: Gradient descent, how neural networks learn | Chapter 2, Deep learning (20 min) . Synthesis Questions . | Why is there a need for a train/test split for a neural network? Why is it important for a NN to be able to generalize to examples it has not seen? | Describe the Mean Squared Error (MSE) cost function. What does a higher value mean? What does a lower value mean? (For one training example) . | Bonus: Assume you have a binary classifier neural network that outputs the vector [0.25, 0.75] and you are using the MSE Loss function to train the Network. The data label indicates that the output for this training example should have been [0, 1]. What is the MSE Loss for this training example? | . | What is the gradient of a function? What is gradient descent? | What does minimizing the loss function do to the network's performance over time? | Do the hidden layers of a basic NN encode any useful information assuming you use the MSE Loss function? Why or why not? | . Video 3: Neural Networks and Deep Learning | Crash Course AI #3 (12 min) . Synthesis Questions . | Why was ImageNet significant to the development of neural networks? What about AlexNet? | What are some real-world applications of neural networks? What are some ethical considerations associated with them? | . Task 2: . Complete the following writing activity. The non-technical project for this unit will involve some writing! Choose 3 of the prompts below and write at least 200 (meaningful!) words on each one! We will not be strictly grading you on correctness or anything like that. This is an opportunity to deeply engage with the material you have just learned about, and creatively connect it to neuroscience! . | What can we learn from neuroscience to improve the efficiency and performance of artificial neural networks? | What are the ethical implications of using insights from neuroscience to design artificial neural networks? | How are ANNs inspired by the structure and function of neurons in the brain? | What are some common applications of neural networks in real-world scenarios? Feel free to do some research on these! | How do neural networks relate to the broader field of machine learning? What are their strengths and weaknesses compared to other algorithms? | Reflecting on you learning from this unit, what is one thing you found to be most interesting about DNNs? | What is one concept from this unit that you would like to learn more about and why? | . ",
    "url": "/pr-preview/pr-48/content/deep_learning/#literacy-track-content",
    
    "relUrl": "/content/deep_learning/#literacy-track-content"
  },"23": {
    "doc": "Fairness & Theory",
    "title": "Unit 9: Fairness and Theory",
    "content": "Machine learning models are interesting, but they have substantive effects on the world they are deployed in. How can we make these models fairer, safer, less biased, and/or more responsible? Is this even rigorously possible? (Some researchers suggest not!) What is the source of bias? (“Garbage In, Garbage Out” is a stunted answer, and maybe even misleading.) These are all questions which are intimately linked with deep learning theory, a growing field which attempts to explain how neural networks work rather than attempting to advance the SOTA in performance or a similar task. Because of the close relationship between theory and fairness research, we will be exploring them together. After going through this unit, you will be able to reason about deep learning at a very abstract level (a powerful tool for research and experimentation); identify the core theoretical essence of various models and approaches; think critically about what the concepts of ‘bias’, ‘fairness’, ‘robustness’, ‘responsibility’, and ‘fairness’ mean and how we might build models which better embody these values. It is recommended to read the listed papers in order, and to at least skim each one. Theory . | Universal Approximation Theorem. While it’s not necessary to completely understand the proof, make sure you understand at least what the theorem is stating and why it is an interesting result. | Read this introductory article written by Andre (the author of this unit) on the UAT, then this Twitter thread of Yann Lecun blasting it. Then, read Lecun et al.’s paper Learning in High Dimension Always Amounts to Extrapolation. Lastly, read this document of the debate on Twitter. Now think about what your position in this debate is. What is interpolation? What is extrapolation? Do neural networks extrapolate? Is this a meaningful concept at all, and if not, what might be a more meaningful one? Keep thinking about these questions throughout the theory section. | Deep Double Descent: Where Bigger Models and More Data Hurt. A ‘classic’ empirical finding which points towards a weirdness of deep learning models as opposed to less parametrized, classical models. | Are Deep Neural Networks Dramatically Overfitted? A great technical blog post giving more theory on the question of overfitting. | Understanding Deep Learning Requires Rethinking Generalization. Important empirical results and speculative theoretical work. | Methods for Pruning Deep Neural Networks. You can skim this one, but it’s a good coverage of pruning – an empirical method whose success is surprising and is worth thinking about. | The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks. This is our second major theory paper. What explains the results found and answers the questions raised in 2, 3, 4, and 5? The Lottery Ticket Hypothesis is a compelling theory. | Deconstructing Lottery Tickets: Zeros, Signs, and the Supermask. A further investigation into the Lottery Ticket Hypothesis. | What’s Hidden in a Randomly Weighted Neural Network? A fascinating result from the Lottery Ticket Hypothesis. | Neural Tangent Kernel. Choose at least one of these to read. | https://lilianweng.github.io/posts/2022-09-08-ntk/ | https://blog.ml.cmu.edu/2019/10/03/ultra-wide-deep-nets-and-the-neural-tangent-kernel-ntk/ | https://rajatvd.github.io/NTK/ | https://www.inference.vc/neural-tangent-kernels-some-intuition-for-kernel-gradient-descent/ | . | The Modern Mathematics of Deep Learning. A landmark work in developing a mathematical theory of deep learning. Skim sections 2.3, 3.2, 3.3, and 4. Make sure you at least understand the results at a high level. | Language Models (Mostly) Know What They Know. A theoretical method for probing language model knowledge reveals interesting epistemic structures. | Bonus: A Mathematical Framework for Transformer Circuits. Think you know how transformers work? Think again! | . Fairness, Responsibility, Safety . | A Survey on Bias and Fairness in Machine Learning. A good and comprehensive survey of general concerns and approaches to addressing bias in machine learning problems. | On the (im)possibility of fairness. No need to read it too in detail; skimming it and understanding the main result is fine. Argues that different mathematized components of algorithmic fairness are fundamentally incompatible with each other in the ideal. | The Myth in the Methodology: Towards a Recontextualization of Fairness in Machine Learning. We’ve got it all wrong, philosopher Lily Hu shows us. Fairness cannot be mathematized. | What’s sex got to do with fair machine learning? An investigation of gender variables in machine learning models. | What is ‘race’ in algorithmic discrimination on the basis of race? An investigation of race variables in machine learning methods. | Moving beyond “algorithmic bias is a data problem”. Sara Hooker takes on the pervasive idea of GIGO (Garbage In, Garbage Out) suggests that data is the root source of bias. | What Do Compressed Deep Neural Networks Forget? An empirical follow-up from the previous opinion piece. How do different compression methods affect model performance? . | Optional: Characterizing and Mitigating Bias in Compact Models. Related work if you are interested in additional research in this direction. | . | The Curious Case of Common Sense. Our very own professor Yejin Choi reflects on the difficulty of codifying common sense into AI models. | You may be interested in Yejin Choi’s research papers, each of which address different dimensions of common sense reasoning: https://homes.cs.washington.edu/~yejin/ | . | Can Machines learn Morality? The Delphi Experiment. An attempt to train a language model to understand commonsense morality. You can play with the Delphi model at https://delphi.allenai.org/. | Constitutional AI: Harmlessness from AI Feedback. An important proposal for a framework to regulate AI with AI from a set of constitutional principles. | Predictability and Surprise in Large Generative Models. An empirical and theoretical investigation of the difficulties of regulating LLMs. | The Hardware Lottery. Thinking about how AI development is constrained by the hardware available. | Socially situated artificial intelligence enables learning from human interaction. A very interesting paper from our very own professor Ranjay Krishna on how humans can more actively engage with and shape AI models. | On the Opportunities and Risks of Foundation Models. A classic in AI safety. Read the introduction (section 1) and “Society” (section 5) at minimum. | The Dark Side of Techno-Utopianism. An accessible and thoughtful conclusion to this unit: what is our role in tech, and is it as rosy as we think it is? | . Task . Read the GPT-3 paper, the GPT-4 model card, or the LaMDA paper (or another recent large language model paper). Focus on the discussions on safety and fairness. Drawing upon the sources in both the theory and the fairness sections of this unit, criticize the evaluations – identify what is mistaken, what assumptions are made, what is socially problematic, what possible biases may have been unidentified or which lie latent in the design, etc. ",
    "url": "/pr-preview/pr-48/addcontent/fairness_theory/#unit-9-fairness-and-theory",
    
    "relUrl": "/addcontent/fairness_theory/#unit-9-fairness-and-theory"
  },"24": {
    "doc": "Fairness & Theory",
    "title": "Fairness & Theory",
    "content": " ",
    "url": "/pr-preview/pr-48/addcontent/fairness_theory/",
    
    "relUrl": "/addcontent/fairness_theory/"
  },"25": {
    "doc": "Gradient Descent",
    "title": "Unit A: Gradient Descent Deep Dive",
    "content": "A deeper dive into Gradient Descent where you will be implementing backpropagation on your own! This is an involved unit that, while technically not required, will push your understanding of neural networks to the max. Task 1: Watch the following video and implement micrograd as specified: . The spelled-out intro to neural networks and backpropagation: building micrograd . The templates we made for you can be found here. Additionally, please implement the ReLU nonlinearity for the Value class. | (Note: if you’re having a hard time with this, take a look at this code.) | . Implement and train a small neural network using micrograd. The training, validation, and test data will be included in the starter code. - Try to find the best network you can! . You might want to change the learning rate, size of the network, or Note your training, validation, and test loss for your best network. Synthesis Questions: . | In what direction do gradients flow (with regards to loss)? | How do gradients flow through addition? How do they flow through the ReLU function? | What was your best loss for the test dataset? | Was there something that stood out to you? Something that confused you? | What's one resource that was helpful (suggested or found on your own)? | . ",
    "url": "/pr-preview/pr-48/addcontent/gradient_descent/#unit-a-gradient-descent-deep-dive",
    
    "relUrl": "/addcontent/gradient_descent/#unit-a-gradient-descent-deep-dive"
  },"26": {
    "doc": "Gradient Descent",
    "title": "Gradient Descent",
    "content": " ",
    "url": "/pr-preview/pr-48/addcontent/gradient_descent/",
    
    "relUrl": "/addcontent/gradient_descent/"
  },"27": {
    "doc": "Graduates",
    "title": "Graduates",
    "content": "These are the hardworking and dedicated students who have graduated from the course! . ",
    "url": "/pr-preview/pr-48/graduates/",
    
    "relUrl": "/graduates/"
  },"28": {
    "doc": "Graduates",
    "title": "Autumn 2024",
    "content": ". | TODO | . ",
    "url": "/pr-preview/pr-48/graduates/#autumn-2024",
    
    "relUrl": "/graduates/#autumn-2024"
  },"29": {
    "doc": "Graduates",
    "title": "Spring 2024",
    "content": ". | Adam Skoglund | Aditya Shirodkar | Ajit Mallavarapu | Anoushka Dalvi | Anupritaa Parasnis | Brinda Moudgalya | Christopher Tan | Eden McPeek | Elaine Lu | Jeffrey Lee | John Jin | Johnathan Nister | Kaden Pothisuntorn | Kandace Kimball | Maya Falodia | Nathan Zeon | Ping Wang | Ruize Jia | Vaibhav Paranji | . ",
    "url": "/pr-preview/pr-48/graduates/#spring-2024",
    
    "relUrl": "/graduates/#spring-2024"
  },"30": {
    "doc": "Graduates",
    "title": "Autumn 2023",
    "content": ". | Aiden Reeder | Anika Tak | Annabelle Martin | Anthony Xing | Arya Sanjay | Dalton Brockett | Diya Yaga | Helena Zheng | Ian Chiu | Ian Hutchings | Jeffrey Junio | Jessie Sun | John Burnham | Misha Nivota | Mo Young | Muhammad Khairullah | Pushpesh Thakur | Rajat Sengupta | Rasool Isaac Ray | Richie Doan | Samantha Guernsey | Samarth Venkatesh | Sehaj Dhillon | Shravani Bhujbal | Shreya Shaji | Soham Bhosale | Solomon Beall | Timothy Zhong | Yuning Hu | Zijing Wei | . ",
    "url": "/pr-preview/pr-48/graduates/#autumn-2023",
    
    "relUrl": "/graduates/#autumn-2023"
  },"31": {
    "doc": "Graduates",
    "title": "Spring 2023",
    "content": ". | Albert Wang | Angelo Dauz | Ethan Bai | Feier Long | Frankie Reyna | Jay Yu | Justin Dong | Kelland Harrison | Molly Park | Siddharth Thiagarajan | Tyler Ramos | . ",
    "url": "/pr-preview/pr-48/graduates/#spring-2023",
    
    "relUrl": "/graduates/#spring-2023"
  },"32": {
    "doc": "Graduates",
    "title": "Winter 2023",
    "content": ". | Ameya Agrawal | Eric Ye | Frank Li | Greg Baimetov | Gunn Chun | Gunn Kim | Vibhav Peri | . ",
    "url": "/pr-preview/pr-48/graduates/#winter-2023",
    
    "relUrl": "/graduates/#winter-2023"
  },"33": {
    "doc": "Human Brain Characteristics",
    "title": "Unit 12: Human Characteristics of the Brain",
    "content": "Several traits of humans appear to be unique to our species and may be essential in designing an intelligence similar to our own. This chapter is dedicated to the study of these phenomena of our brains. We begin by trying to peel back the layers of humans’ strong social tendencies: . Task 1: Complete the following lecture and synthesis questions. 20. Theory of Mind &amp; Mentalizing . Synthesis Questions: . | Describe the false belief paradigm and what function it serves. | What part of the brain is/are specifically involved in thinking about others' thoughts? Where is it located? What are several close by modules and their functions? | Google the terms TMS, EEG, and DBS. What are several differences and similarities between these cognitive science methods? | . Task 2: Depending on your level of comfort with languge modeling, take a look at the following resources below, and then watch the Attention and Awareness lecture. If you are familiar with Attention in Transformers, try comparing and contrasting to what the lecture says about the brain. If you are not familiar with Attention in Transformers, just learn what you can from the video purely from a neuroscience standpoint. If we have not completed the LM unit yet, Attention in ML may not be the most familiar. If you would like, here are some resources to prime your understanding: . Optional: A very comprehensive and visually helpful intuition for what the attention mechanism actually does: Attention Mechanism In a Nutshell . Optional: If you want to play with the math behind LLMs, this is pretty cool: 3Blue1Brown: Attention in Transformers . Optional: Self Attention Colab Notebook . For a deeper dive, feel free to take a look at the Language Modeling chapter of this document. Now we will dive into the capabilities of the brain and its own beautiful, endogenous attention mechanisms! . 24. Attention and Awareness . Synthesis Questions: . | Describe the brain's ability to multitask? What are some scenarios where parallel processing is feasible and some where it is not? | Describe covert and overt attention. | Describe \"priming the visual cortex\" why it might be useful. | \"You have 10x as many connections going down from cortex, down to the LGN ([lateral geniculate nucleus](https://en.wikipedia.org/wiki/Lateral_geniculate_nucleus))… than going forward. One of the things you're doing is setting up selective filters so that only the stuff you want to process makes it to higher stages.\" Compare this fact to deep learning algorithms. | Describe the role of the Fronto-Parietal Attention Network | If familiar with Attention in ML: Research some machine learning attention mechanisms. Compare and contrast the mechanism and the capabilities of one with what you learned about our biological attention mechanism. | . ",
    "url": "/pr-preview/pr-48/addcontent/human_char_brain/#unit-12-human-characteristics-of-the-brain",
    
    "relUrl": "/addcontent/human_char_brain/#unit-12-human-characteristics-of-the-brain"
  },"34": {
    "doc": "Human Brain Characteristics",
    "title": "Project Spec",
    "content": "Consider, for a moment, the ways in which there are or are not parallels between our current mechanisms of machine learning and the various modules and functions of the brain that we have learned about. In your opinion, are some crucial for intelligence? Which, if any, have we managed to emulate with algorithms? . Now consider attention. The brain seems to block out unwanted information from ever being processed (about minute 8:00, Attention and Awareness). Are there ML algorithms that do this? Should they? What should the function of attention be? Does it depend on the context or is it a fixed algorithm for all contexts? . Write some thoughts (200+ words) on these questions. Then, finally, find one article on Grey Matters that interests you and consider how it relates to the above questions. Provide the link and some thoughts :) . ",
    "url": "/pr-preview/pr-48/addcontent/human_char_brain/#project-spec",
    
    "relUrl": "/addcontent/human_char_brain/#project-spec"
  },"35": {
    "doc": "Human Brain Characteristics",
    "title": "Human Brain Characteristics",
    "content": " ",
    "url": "/pr-preview/pr-48/addcontent/human_char_brain/",
    
    "relUrl": "/addcontent/human_char_brain/"
  },"36": {
    "doc": "Core Content",
    "title": "Core Content",
    "content": "Hello, and welcome to the I2 Neuro/AI Course. Here you can find all sorts of resources designed to help YOU become an amazing Neuro/AI* researcher! . How to use (ignore if following curriculum): . | Take a look at the table of contents and get a sense for what you do/don’t know . | Start from the beginning if you are brand new OR | Pick a topic that looks interesting! | . | For each major topic we have linked Resources, Questions, and sometimes a mini-project! | Be sure to ask questions and share cool things you learn with everyone in your group (if applicable)! | . ",
    "url": "/pr-preview/pr-48/content/",
    
    "relUrl": "/content/"
  },"37": {
    "doc": "Additional Content",
    "title": "Additional Units",
    "content": "Additional units are placed here. If you would like to contribute to these units or add your own NeuroAI unit, please contact us! . ",
    "url": "/pr-preview/pr-48/addcontent/#additional-units",
    
    "relUrl": "/addcontent/#additional-units"
  },"38": {
    "doc": "Additional Content",
    "title": "Additional Content",
    "content": " ",
    "url": "/pr-preview/pr-48/addcontent/",
    
    "relUrl": "/addcontent/"
  },"39": {
    "doc": "I2 Course",
    "title": "I2 Intro Neuro/AI Course",
    "content": ". ",
    "url": "/pr-preview/pr-48/#i2-intro-neuroai-course",
    
    "relUrl": "/#i2-intro-neuroai-course"
  },"40": {
    "doc": "I2 Course",
    "title": "If you’re looking to join Spring 2025",
    "content": "Please follow the following links! . Course Application (non-competitive) . I2 Discord . Hello! Welcome to the Introduction to Neuro/AI Interactive Intelligence (i2) crash course (now opencourseware)! Here’s the link to our course textbook, the I2 Grimoire. We’ll be referencing it throughout the course, so be sure to check it out. Please remember: . | We are all trying to learn, and learn at different speeds. | This course is somewhat of a commitment. You will get out what you put in | There are no grades! This is all for your learning alone. | Contact any mentor at any point if you have any questions. Seriously, we are here to help &lt;3 | Be helpful, be kind, and have fun! | . What basics you will learn (a more detailed list can be found in the announcements): . | ML | DL | Neuroanatomy | Computer Vision | Reinforcement Learning | Movement | Language Modeling | AI Fairness/Theory | Pain in RL/Neuroscience/Cognitive Science | More about the brain | . And also: . | Pytorch | Jupyter notebooks | LaTeX | Self-learning skills | . ",
    "url": "/pr-preview/pr-48/#if-youre-looking-to-join-spring-2025",
    
    "relUrl": "/#if-youre-looking-to-join-spring-2025"
  },"41": {
    "doc": "I2 Course",
    "title": "I2 Course",
    "content": " ",
    "url": "/pr-preview/pr-48/",
    
    "relUrl": "/"
  },"42": {
    "doc": "Language Modeling",
    "title": "Language Modeling",
    "content": "Welcome to the Language Modeling section of the I2 Course! Here you will learn about the core concepts underlying textual GenAI tools that took the world by storm. Hopefully you can reason about these models better after learning more about how they work! . ",
    "url": "/pr-preview/pr-48/content/language_modeling/",
    
    "relUrl": "/content/language_modeling/"
  },"43": {
    "doc": "Language Modeling",
    "title": "Technical Track Content",
    "content": "Task 1: . Navigate to the relevant section of the I2 Grimoire using the link below. Read the textbook and answer all synthesis questions to the best of your ability. Be sure to save these somewhere for future reference. I2 Grimoire: Language Modeling . Task 2: . Solve the coding challenges within the Jupyter notebook linked below (through Colab). If you encounter any issues with the notebook not functioning as described, please let us know! . Please ask questions as you work through this project. Be sure to discuss with others in your group if you have one! Share your answers as you like, the goal is to learn and we’re not holding grades over your head. There are 2 parts (.ipynb files) to this unit. Try to finish both. This technical project is likely to be harder than anything you have done in this course before, so be patient with it and reach out if you need support! In the first part, you wll be learning how to work with the HuggingFace API. Colab Link: Language Modeling Colab Notebook Part 1 (1 hr) . Now navigate to the application portion of this project (Part 2 below), where you are given a dataset and asked to train an LLM of your choice to emulate Shakespeare! Be sure to reference your the above notebook to figure out how to do this. Colab Link: Language Modeling Colab Notebook Part 2 (1 hr) . When you are finished with your code, independently verify that it works and have fun with it! If you add any additional functionality be sure to talk about it with others and give them ideas. Remember that this is all for your learning, so do your best and don’t stress! . Congratulations! You now understand the basics of HuggingFace and Language Modeling! . ",
    "url": "/pr-preview/pr-48/content/language_modeling/#technical-track-content",
    
    "relUrl": "/content/language_modeling/#technical-track-content"
  },"44": {
    "doc": "Language Modeling",
    "title": "Literacy Track Content",
    "content": "Task 1: . Read the article below, and answer any synthesis questions placed along the way. This article will cover the idea of language modeling and how computers process human language. Put simply, the goal of language modeling is to predict the next word in a sentence using information about the definitions and grammatical rules of particular words as well as the contexts in which they appear. For example consider this sentence: . I want to cook an omelet, so I went to the store to buy some ___ . What comes next in this sentence? Chances are, you said “eggs.” There are plenty of “correct” answers—maybe you were out of salt and pepper—but it’s the most likely answer. Based on the sentence, we know that whatever comes next should be a noun phrase, and it’s probably related to the omelet we’re going to cook, and it’s something you can buy in a store. Given all that information, we conclude that we can fill in the blank with “eggs.” The goal of language modeling is to do something similar—that is, predict the next word in these sentences using probabilistic information about the sentence. There are two main types of language models: statistical language models and neural language models. Statistical language models use statistics and probability directly to predict the likely next word in a sentence of phrase. They generally get these statistics from a sample set of data. Based on this data, the model can identify patterns in the text and come up with predictions. Statistical language models usually take the form of an n-gram model. This model predicts the probability of a word in a sequence given the n previous words in the sequence. For example, a unigram predicts the probability of a word given the immediate previous word; a bigram predicts the probability given the two previous words; a trigram uses the three previous words, and so on. However, statistical language models have their limitations. For one, they will struggle with new words or phrases that don’t appear often in the original set of data (for example, if the phrase “time complexity” rarely appears in the original data, the model may struggle to predict that the word “complexity” can follow the word “time”). In addition, because these models look back at a fixed number of words, they can struggle to track and consider the long-term effects of a word on a phrase. This is where the other type of model, neural language models, come in. Neural language models use neural networks to predict the next word in a sequence. These models are able to handle more complex and diverse sets of training data and are better at handling context clues and long-term effects of words. We’ll continue to discuss neural language models in greater detail through these videos. Specifically, we’ll look at two types of neural language models: recurrent neural networks and transformers. Watch the following videos! . Video 1: Illustrated Guide to Recurrent Neural Networks: Understanding the Intuition (10 min) . Synthesis Questions . | How does an RNN interact with a feed-forward neural network? What role does the RNN play in this process? | Describe the vanishing gradient problem in your own words. Does it relate to the drawbacks of statistical language models? | The video describes a few solutions to the short-term memory of RNNs. What changes do they make to address the problem? | . Video 2: Transformers, explained: Understand the model behind GPT, BERT, and T5 (9 min) . Synthesis Questions . | What are some of the limitations of previous NLP models, and how did transformers address these? | Describe the ideas of positional encoding and attention in your own words. | Like the “server” example at 6:50 in the video, create two sentences that can be disambiguated using self-attention. | . Optional: Natural Language Processing: Crash Course AI #7 (13 min) . Great resource if you’re still having trouble with NLP! . Task 2: . Complete the following writing activity. The non-technical project for this unit will involve some writing! Choose 3 of the prompts below and write at least 200 (meaningful!) words on each one! We will not be strictly grading you on correctness or anything like that. This is an opportunity to deeply engage with the material you have just learned about, and creatively connect it to neuroscience! . | What ethical considerations arise when developing language models that are inspired by neural processes involved in language? | To what extent do models used in language processing reflect the actual neural networks involved with language tasks in the brain? | How can insights from neuroscience be leveraged to enhance the design and development of language models? | Reflecting on you learning from this unit, what is the one thing you found to be most interesting? | What is one concept from this unit that you would like to learn more about and why? | . ",
    "url": "/pr-preview/pr-48/content/language_modeling/#literacy-track-content",
    
    "relUrl": "/content/language_modeling/#literacy-track-content"
  },"45": {
    "doc": "Machine Learning",
    "title": "Machine Learning",
    "content": "Hello and welcome to the Machine Learning section of the I2 course! Our content will be split into two categories: literacy and technical tracks. These topics are fundamental to the entire rest of our course, so please don’t hesitate to reach out to the course staff if you have any questions! . ",
    "url": "/pr-preview/pr-48/content/machine_learning/",
    
    "relUrl": "/content/machine_learning/"
  },"46": {
    "doc": "Machine Learning",
    "title": "Technical Track Content",
    "content": "Task 1: . Navigate to the relevant section of the I2 Grimoire using the link below. Read the textbook and answer all synthesis questions to the best of your ability. Be sure to save these somewhere for future reference. I2 Grimoire: Machine Learning . Task 2: . Solve the coding challenges within the Jupyter notebook linked below (through Colab). If you encounter any issues with the notebook not functioning as described, please let us know! . Please ask questions as you work through this project. Be sure to discuss with others in your group if you have one! Share your answers as you like, the goal is to learn and we’re not holding grades over your head. This project will be going over k-means clustering and PCA (unsupervised ML). We will be using the Scikit-Learn library. Check out this handy image that gives popular sk-learn clustering algorithms and their usages: . Also this image visualizing the clustering algorithms: . Read up on k-means clustering in the provided link (Images provided above also contained here). Feel free to check out the other algorithms as well: SK-Learn Clustering . Now, follow the instructions on this Jupyter notebook (hosted on Google Colab) to implement some of the things we talked about! Be sure to save a local copy of the template so you can edit it. Colab Link: Machine Learning Colab Template (30 min) . When you are finished with your code, independently verify that it works and have fun with it! You could try this method on different datasets, such as this one for example. If you add any additional functionality be sure to talk about it with others and give them ideas. Remember that this is all for your learning, so do your best and don’t stress! . Congratulations! You now understand the basics of Clustering and PCA! . ",
    "url": "/pr-preview/pr-48/content/machine_learning/#technical-track-content",
    
    "relUrl": "/content/machine_learning/#technical-track-content"
  },"47": {
    "doc": "Machine Learning",
    "title": "Literacy Track Content",
    "content": "Task 1: . Read the article below, and answer any synthesis questions placed along the way. This article is going to cover what machine learning is at a conceptual level. The general idea behind machine learning is that a machine uses known information to make predictions about unknown information—much like humans. For a long time, we used computer programming to manually give computers instructions on how to do things. But there are a lot of things that we may want computers to do that are far too advanced to manually instruct them on. The goal of machine learning, then, is to get computers to “learn” how to do tasks so that we don’t have to give it explicit instructions. To better understand this, let’s look at an example. Imagine we want our computer to identify pictures of cats and pictures of pigs. Our computer has never seen a pig or a cat before, so we have to give it some information to help it get started. Let’s feed our computer the following images. We’ll label the pictures of cats “cat” and the pictures of pigs “pig,” so the computer knows which is which. Now the computer has to figure out what makes the cat pictures different from the pig pictures. What does it notice? Well, all the cats are furry and all the pigs are pink. So the computer comes up with the following system: . | if the picture has a furry, non-pink animal, it’s a cat | if the picture has a non-furry, pink animal, it’s a pig | otherwise the computer isn’t sure | . Okay, let’s see how it does! We give the computer these three pictures and ask it to classify them as “cat” or “pig.” . The computer classifies the first animal, which is furry and not pink, as a cat—perfect! But it classifies the second, which is not furry and pink, as a pig, and the third, which is furry and not pink, as a cat. Now we have to correct our computer. We let it know that it was right about the first image, but the other two were wrong. Here’s where the crucial part of machine learning comes in: the computer looks at the images again and learns why it was wrong. It realizes that not all cats are furry and not all pigs are pink. Maybe it also realizes that all the cats we provided have long tails, and all the pigs have long snouts. Whatever the case, the computer learns how to better classify the animals based on the data we provided. It learns which features are crucial and which features are optional in its decision, and the more data we provide, the more it refines its processes and produces accurate predictions. This occurs over many, many, many trials, until it finally begins to make perfect predictions. This is the very general idea of how machine learning works. But what does it mean for a computer to “learn”? How does a machine “learn” anything, the way humans learn? For that matter, how can the computer tell that the pictures of cats have fur in them, or that the pictures of pigs contain long snouts? . These are exactly the questions that this course aims to answer. We’ll learn how humans learn, how machines learn, and how our understanding of one allows us to develop our understanding of the other. We’ll also learn how humans interpret images and pictures, and how we can use that information to get computers to do the same thing. Synthesis Questions . | What are the limitations of early “if this, then that” logic? | Why do we need a teach-build cycle to get our machine to learn? | Why does this teach-build-teach-build cycle work? How do the \"bots\" get better over time? | Why is it so important for companies to use a good dataset to teach their bots? | . TODO: Add more to the literacy article . Task 2: . Complete the following writing activity. The non-technical project for this unit will involve some writing! Choose 3 of the prompts below and write at least 200 (meaningful!) words on each one! We will not be strictly grading you on correctness or anything like that. This is an opportunity to deeply engage with the material you have just learned about, and creatively connect it to neuroscience! . | TODO: Create prompts based off literacy article | . ",
    "url": "/pr-preview/pr-48/content/machine_learning/#literacy-track-content",
    
    "relUrl": "/content/machine_learning/#literacy-track-content"
  },"48": {
    "doc": "Movement",
    "title": "Unit 13: Intro to Movement",
    "content": "We are now going to be learning about how your brain makes you act and move in your environment. We start by investigating the cerebellum. This will tie into Reinforcement Learning (RL), so pay attention! . First, a few useful vocab words: . Afferent: Conducting towards something . Efferent: Conducting away from something . Task 1: Read the sections entitled “Feed forward control systems” and “The cerebellum may be a feedforward control system” from the notes here to get a sense for the purpose of the cerebellum. Cerebellum – The University of Texas Medical School . Then, watch the following brief videos, take notes if you’d like! . 2-Minute Neuroscience: Cerebellum . 19.3 Cerebellar Information Flow . Synthesis Questions: . | Explain the difference between mossy fibers and climbing fibers and their respective functions. | Which cells or fibers may be responsible for sending error signals to the cerebellum? | What is the function of a Purkinje cell? To what do they output? What do they look like? Why might they look like this? | What are the primary input sources of the cerebellum? Where do these signals originate? | . For more depth on these topics, here are some more fabulous resources. Bonus Videos: . 19.4 Cerebellar Circuits . 19.5 Afferent Tracts to the Cerebellum . ",
    "url": "/pr-preview/pr-48/addcontent/movement/#unit-13-intro-to-movement",
    
    "relUrl": "/addcontent/movement/#unit-13-intro-to-movement"
  },"49": {
    "doc": "Movement",
    "title": "Project Spec",
    "content": "There is no project for this unit yet. We hope to make one soon! . ",
    "url": "/pr-preview/pr-48/addcontent/movement/#project-spec",
    
    "relUrl": "/addcontent/movement/#project-spec"
  },"50": {
    "doc": "Movement",
    "title": "Movement",
    "content": " ",
    "url": "/pr-preview/pr-48/addcontent/movement/",
    
    "relUrl": "/addcontent/movement/"
  },"51": {
    "doc": "Reinforcement Learning",
    "title": "Reinforcement Learning",
    "content": "Welcome to the Reinforcement Learning section of the I2 Course! The topics in this unit should get you really thinking about NeuroAI. Be sure to ask lots of questions! . ",
    "url": "/pr-preview/pr-48/content/reinforcement_learning/",
    
    "relUrl": "/content/reinforcement_learning/"
  },"52": {
    "doc": "Reinforcement Learning",
    "title": "Technical Track Content",
    "content": "Task 1: . Navigate to the relevant section of the I2 Grimoire using the link below. Read the textbook and answer all synthesis questions to the best of your ability. Be sure to save these somewhere for future reference. I2 Grimoire: Reinforcement Learning . Task 2: . Solve the coding challenges within the Jupyter notebook linked below (through Colab). If you encounter any issues with the notebook not functioning as described, please let us know! . Please ask questions as you work through this project. Be sure to discuss with others in your group if you have one! Share your answers as you like, the goal is to learn and we’re not holding grades over your head. In this project, you will be implementing parts of a simple Q-Learning algorithm for a “cartpole” environment. Colab Link: Reinforcement Learning Colab Notebook (1.5 hr) . When you are finished with your code, independently verify that it works and have fun with it! If you add any additional functionality be sure to talk about it with others and give them ideas. Remember that this is all for your learning, so do your best and don’t stress! . Congratulations! You now understand the (incredibly basic) basics of Deep RL! . ",
    "url": "/pr-preview/pr-48/content/reinforcement_learning/#technical-track-content",
    
    "relUrl": "/content/reinforcement_learning/#technical-track-content"
  },"53": {
    "doc": "Reinforcement Learning",
    "title": "Literacy Track Content",
    "content": "Task 1: . Read the article below, and answer any synthesis questions placed along the way. Welcome to one of the most important units in this course—and one of the most challenging! Like all our articles, the goal of this article is to give you an intuitive understanding of reinforcement learning so that you can recognize it in daily life and apply it to technical projects. Reinforcement learning is the study of how a free object, or agent, moves around and accomplishes tasks in an environment, either real or simulated. The very general idea involves rewarding the object for desirable actions (i.e. reinforcing that behavior) and punishing it for undesirable actions. For example, suppose we’re teaching a computer how to play chess against a human. In this case, the agent would be the computer and the environment would be the chess game (i.e. the opponent, board, and pieces). The computer starts by taking an action–in other words, it does something. In this case, say the computer captures one of the human opponent’s pawns. Now the environment (the chess game) looks different from before the computer took its action; the computer has changed the state of the environment. The state of the environment is favorable—we’re glad the computer took this action, and we want to reinforce it (we want it to keep taking actions like this). So we give the computer a reward that’s proportional to how desirable the action was. In this case, the reward is pretty moderate—capturing a pawn is good, but it’s not one of the best moves the computer can make. If the computer had captured the opponent’s queen, for example, we’d give it more of a reward because that’s a more desirable action. Suppose the computer takes a different action: instead of capturing a pawn, it knocks over the entire board. Again, our environment is in a new state as a result of this action. Unfortunately, this new state is very bad for the computer because there’s no way it can win the game now. So we want to punish this action and make sure the computer avoids it in the future. We can do this by giving it a negative reward to indicate that it’s an undesirable action. The computer decides what steps to take using something called a policy. A computer uses a policy to decide what its next step should be. For example, maybe the computer’s policy is to maximize its rewards. Then, every single action it takes is the action that produces the highest reward. This helps it avoid undesirable actions, like knocking over the board, because they have such low rewards. This isn’t always the best policy, though. We said earlier that capturing the opponent’s queen is a very high-reward action. Suppose the computer is in a position where it can capture its opponent’s queen, but in doing so leaves its king vulnerable. In this case, maybe taking the highest-reward action isn’t the best way to go. We would have to use a different policy in our decision-making. Deep reinforcement learning combines deep learning and reinforcement learning. Its goal is to get the computer to learn to do something, and it teaches the computer using the principles of RL. Take a look at the short video below, which tries to teach a robot to walk using deep reinforcement learning (don’t worry, you’ll have fewer Synthesis Questions to make up for the extra video!). Video 1: AI Learns to Walk (deep reinforcement learning) (9 min) . Notice that the robot wasn’t given any directions. It was given a target, and every action it took was rewarded or punished, but it ultimately had to learn the correct sequence of actions that would allow it to walk. If we apply this to our chess example, the target might be to win the game by capturing the opponent’s king. We won’t tell the computer how to do that, but every time it takes an action we can reward or punish it. That way, it starts to learn the correct sequence of actions that it needs to take in order to win the game. Also, like in the video, we can put our chess computer in different environments to force it to learn new actions. For example, we can start it out in an environment where its opponent is a three-year-old. As the computer gets better, we can put it in new environments with more and more advanced opponents to force it to learn new skills, in the same way the robot in the video became better at walking by crossing more and more difficult terrain. Now let’s watch some videos on RL. Video 1: Reinforcement Learning: Crash Course AI #9 (12 min) . Synthesis Questions . | When does it make sense to use reinforcement learning vs. other methods of machine learning to accomplish a task? | How do the agent, action, and environment interact in reinforcement learning? | Give an example of two different policies in a reinforcement learning environment that’s NOT the cookie-jar example from the video (but you can use the chess game, the walking robot, or something you come up with yourself!). | . Video 2: Reinforcement Learning from scratch (8 min) . Synthesis Questions . | What is the purpose of a sigmoid function, and what does its value tell us? What about an error function? | Describe the idea of gradient descent and how we use it in reinforcement learning. | . Task 2: . Complete the following writing activity. The non-technical project for this unit will involve some writing! Choose 3 of the prompts below and write at least 200 (meaningful!) words on each one! We will not be strictly grading you on correctness or anything like that. This is an opportunity to deeply engage with the material you have just learned about, and creatively connect it to neuroscience! . | Can you provide examples of experimental evidence linking reinforcement learning algorithms to observed synaptic changes in the brain? | How do human neural systems encode reward signals and how does this relate to the concept of rewards in reinforcement learning models? | What ethical considerations should be taken into account when developing interventions based on neuroscientific findings, and how can accountability be established for the potential impacts of such interventions? | Reflecting on you have learned from this unit, what is one thing you found to be most interesting? | What is one concept from this unit that you would like to learn more about and why? | . ",
    "url": "/pr-preview/pr-48/content/reinforcement_learning/#literacy-track-content",
    
    "relUrl": "/content/reinforcement_learning/#literacy-track-content"
  },"54": {
    "doc": "Schedule",
    "title": "Schedule",
    "content": " ",
    "url": "/pr-preview/pr-48/schedule/",
    
    "relUrl": "/schedule/"
  },"55": {
    "doc": "Schedule",
    "title": "Week 0: Course Overview, Prerequisite Knowledge",
    "content": "Purpose . | Gen acquainted with the course | Learn some of the pre-reqs necessary (Python) | Learn some of the pre-reqs necessary (calculus, linear algebra) | . Resources . Python Resources: . | CS50x Intro to Python Course | CS231n notes on Python, Numpy, and Jupyter Notebooks | . Math Resources: . | Linear Algebra Review and Reference (Just Unit 1) | Vector Basics | Hyperplane Definition | Hyperplane Math | Partial Derivatives (Mathematical) | Partial Derivatives (Graphical) | . Assignment . IMPORTANT!: If you already know a topic, DO NOT waste your time re-doing it. This week is just to refresh your mind . That being said, if you are unfamiliar with most of the items here, focus on Python and be sure to ask lots of questions! . Python Assignments: . | Complete units in the CS50x Intro to Python Course as needed (If you are confident, feel free to skip a section). I recommend: . | 0: Functions, Variables | 1: Conditionals | 2: Loops | 4: Libraries | 9: Et Cetera | . | Read through CS231n Notes, focusing on: . | Containers | Numpy | MatPlotLib | . | . Math Assignments: . | Read/Watch provided resources to learn/refresh your math knowledge. | If you are already familiar with the concepts listed above, feel free to skip them. I would, however, reccomend you explore linear algebra in high dimensional spaces (specifically hyperplanes) and revisit partial derivatives. | . Summary Questions . | What topics did you learn this week (Python or math)? | . ",
    "url": "/pr-preview/pr-48/schedule/#week-0-course-overview-prerequisite-knowledge",
    
    "relUrl": "/schedule/#week-0-course-overview-prerequisite-knowledge"
  },"56": {
    "doc": "Schedule",
    "title": "Week 1: Introduction to Machine Learning",
    "content": "Purpose . An introduction to the foundation of modern AI! . | Introduction to Machine Learning (ML) | Math behind Linear Regression, SVM, PCA | Basic Unsupervised Clustering | . Resources . | Megadoc Unit 1 | . Assignment . | Complete Unit 1 in the megadoc (synthesis questions included) | Either Scikit-Learn ML Technical-Project (in megadoc) | Or Non-Technical Writing Project (bottom of megadoc) | . Summary Questions . | Synthesis questions in the megadoc | . ",
    "url": "/pr-preview/pr-48/schedule/#week-1-introduction-to-machine-learning",
    
    "relUrl": "/schedule/#week-1-introduction-to-machine-learning"
  },"57": {
    "doc": "Schedule",
    "title": "Week 2: Basic Neuroanatomy",
    "content": "Purpose . Welcome to a beginner’s introduction to neuroscience! We will . | Learn several basic regions of the brain | Learn fundamentals of the neuron and biological computation -Begin to hypothesize about the parallels and divergences of machine learning and the brain | . Resources . | Megadoc Unit 3 | . Assignment . | Complete Unit 3 in the megadoc (synthesis questions included) | Basic Neuroanatomy Project (LaTeX template in github) | . Summary Questions . | Synthesis questions in the megadoc | . ",
    "url": "/pr-preview/pr-48/schedule/#week-2-basic-neuroanatomy",
    
    "relUrl": "/schedule/#week-2-basic-neuroanatomy"
  },"58": {
    "doc": "Schedule",
    "title": "Week 3: Introduction to Neural Networks",
    "content": "Purpose . Our first foray into more complex networks and how they learn. | Introduction to Deep Learning (DL) | Introduction to Neural Networks | Introduction to Backpropagation | . Resources . | Megadoc Unit 2 | CS231n Notes on Neural Networks. See Module 1: Neural Networks - great written resource for the basics. | . Assignment . | Complete Unit 2 in the megadoc (synthesis questions included) | Basic MNIST Classifier (in megadoc/github) | . Summary Questions . | Synthesis questions in the megadoc | . ",
    "url": "/pr-preview/pr-48/schedule/#week-3-introduction-to-neural-networks",
    
    "relUrl": "/schedule/#week-3-introduction-to-neural-networks"
  },"59": {
    "doc": "Schedule",
    "title": "Week 4: Convolutional Neural Networks",
    "content": "Purpose . | Deep Learning for Vision | Learn about Convolutional Neural Networks | . Resources . | Megadoc Unit 4 | . Assignment . | Complete Unit 4 in the megadoc (synthesis questions included) | ConvNet Project (in megadoc/github) | . Summary Questions . | Synthesis questions in the megadoc | . ",
    "url": "/pr-preview/pr-48/schedule/#week-4-convolutional-neural-networks",
    
    "relUrl": "/schedule/#week-4-convolutional-neural-networks"
  },"60": {
    "doc": "Schedule",
    "title": "Week 5: The Visual System",
    "content": "Purpose . This week we take a small break from computation and return to the brain, specifically your insanely complex and elegant visual system! We will . | Learn the basic anatomical and functional regions of the visual system | Compare biological solutions to visual tasks with computational solutions | . Resources . | Megadoc Unit 5 | . ",
    "url": "/pr-preview/pr-48/schedule/#week-5-the-visual-system",
    
    "relUrl": "/schedule/#week-5-the-visual-system"
  },"61": {
    "doc": "Schedule",
    "title": "Week 6: Reinforcement Learning",
    "content": "Purpose . | Go over basics of RL | Learn about Deep Q Learning | . Resources . | Megadoc Unit 6 | Spinning Up | . Assignment . | Complete Unit 6 in the megadoc (synthesis questions included) | . Summary Questions . | Synthesis questions in the megadoc | What’s one resource that was helpful (suggested or found on your own)? | . ",
    "url": "/pr-preview/pr-48/schedule/#week-6-reinforcement-learning",
    
    "relUrl": "/schedule/#week-6-reinforcement-learning"
  },"62": {
    "doc": "Schedule",
    "title": "Week 7: AI Ethics",
    "content": "Purpose . | Learn about ethics in AI and think about how ethical AI is developed. | . Resources . | Megadoc Unit 7 | . Assignment . | Create a slideshow, details in the megadoc | . Summary Questions . | Synthesis questions in the megadoc | . ",
    "url": "/pr-preview/pr-48/schedule/#week-7-ai-ethics",
    
    "relUrl": "/schedule/#week-7-ai-ethics"
  },"63": {
    "doc": "Schedule",
    "title": "Week 8: Language Modeling",
    "content": "Purpose . | Learn about word embeddings | Learn about Recurrent Neural Networks | Learn about Transformers | Learn about fine-tuning foundation models like GPT | Gain a basic intuition about transformer and language models | . Resources . | Megadoc Unit 8 | . Assignment . | Complete Unit 8 in the megadoc (synthesis questions included) | HuggingFace Project Part 1 (in megadoc) | HuggingFace Project Part 2 (in megadoc) | . Summary Questions . | Synthesis questions in the megadoc | . ",
    "url": "/pr-preview/pr-48/schedule/#week-8-language-modeling",
    
    "relUrl": "/schedule/#week-8-language-modeling"
  },"64": {
    "doc": "Schedule",
    "title": "Week 9: Certificates + Unit 11",
    "content": "Purpose . | Certificates! | Celebrate your good work | Introduce Unit 11 as a fun side quest :) | . Resources . | Megadoc Unit 11 | . ",
    "url": "/pr-preview/pr-48/schedule/#week-9-certificates-unit-11",
    
    "relUrl": "/schedule/#week-9-certificates-unit-11"
  },"65": {
    "doc": "Course Staff",
    "title": "Current Course Staff",
    "content": "Here are the awesome people who made this course possible. Feel free to contact us if you have any issues! . ",
    "url": "/pr-preview/pr-48/staff/#current-course-staff",
    
    "relUrl": "/staff/#current-course-staff"
  },"66": {
    "doc": "Course Staff",
    "title": "Education Leads",
    "content": "Arya Sanjay . aryas1@cs.washington.edu . Hey, I’m Arya, one of the Education Leads of the I2 Intro Course! I took the intro course myself because I was interested in ML and ethics, and wanted to learn more, but didn’t know where to start. I really enjoyed the intro course, and since I love teaching, I was a TA for it. Now, I’m excited to co-lead it and work with the rest of leadership to make this the best quarter yet! I’m a CS student at UW, and outside of school, I like exploring new food spots, music, and trying new things. Misha Nivota . mnivota@uw.edu . Hey, I’m Misha, one of the Education Leads for the I2 Intro Course! I am a CS student at UW focused on machine learning and its applications in neuroscience. I became part of the I2 leadership because I really enjoy teaching and helping other students recognize their potential. Through my roles in the Intro Course and the Data Science Initiative, I aim to help more students learn practical skills in ML, AI, and neuroscience, and feel more confident in these subjects. Outside of college, I am a classical Indian dancer and write poetry. I love Bollywood (movies and music), playing ultimate frisbee, and traveling. ",
    "url": "/pr-preview/pr-48/staff/#education-leads",
    
    "relUrl": "/staff/#education-leads"
  },"67": {
    "doc": "Course Staff",
    "title": "Previous Course Staff",
    "content": " ",
    "url": "/pr-preview/pr-48/staff/#previous-course-staff",
    
    "relUrl": "/staff/#previous-course-staff"
  },"68": {
    "doc": "Course Staff",
    "title": "The Creators",
    "content": "Carter Swartout . swartout@uw.edu . Hi, I’m Carter! I’m a CS student studying deep learning, primarily NLP. I’ve always had a childlike wonder with “intelligent computers” and I’m delighted I get to improve them with I2. Outside of school I love reading, biking, and being confused by puzzles! . Chaytan Inman . chaytan@uw.edu . I’m Chaytan. I guess the first thing to know about me is that I love rain, trees, fungi, and plants, and they’re what made me want to form this team. I think that technology has enabled humans to destroy ourselves and organisms around us, but I’m hoping that the right technology can also enable us to reevaluate how we think and act. To me this team is an environment about experimenting and discovering those technologies: codifying generally intelligent computation and environmental understanding through environmental interaction. Varun Ananth . varunananth1@gmail.com . Hey there! My name is Varun. I have been working on this course for a while and with the help of some amazing people, it came together. I really believe in the power of education and teaching and how it can shape lives. I attribute my successes today to my teachers, peer or adult. With this course I aim to spark interest for Neuro/AI in college students around the world. My specialty within DL is Reinforcement Learning, and I hope to be able to continue research in that field. Apart from nerdy stuff, I enjoy guitar, skateboarding, and videogames. So basically more nerdy stuff. ",
    "url": "/pr-preview/pr-48/staff/#the-creators",
    
    "relUrl": "/staff/#the-creators"
  },"69": {
    "doc": "Course Staff",
    "title": "Previous Education Leads",
    "content": "Ameya Agrawal . aameya16@cs.washington.edu . Hey there, I’m Ameya! I took the intro course myself the first time it was run and absolutely loved it, so I decided to TA for it, and now I’m leading it! I am fortunate to be surrounded by intelligent, dedicated i2 leadership who share a common passion for Neuro/AI and are always happy to help. I really enjoyed this course as it provided me with a great starting point to further explore Neuro/AI and I hope it does the same for you. Outside of i2, I’m a junior in CS at UW, and I absolutely love solving puzzles, playing video games and am always down for a game of pool! . Vibhav Peri . vperi@uw.edu . Hey, I’m Vibhav! I’m currently a junior here at UW in CS. I had been interested in learning ML since I came to the university, but was completely overwhelmed by where to start. The intro course was exactly what I needed! I liked the course enough to TA it the following quarter, and now I’m thrilled to be leading it with Ameya! In my free time I enjoy running and videogames among many other nerdy things. ",
    "url": "/pr-preview/pr-48/staff/#previous-education-leads",
    
    "relUrl": "/staff/#previous-education-leads"
  },"70": {
    "doc": "Course Staff",
    "title": "Autumn 2024 Teaching Assistants",
    "content": "Adam Skoglund . ajskog@uw.edu . Hello! I’m Adam, and I am a current third year student studying Informatics: Data Science and minoring in Statistics. Outside of education, I like games, music, and movies! . Ankit Gowda . agowda@cs.washington.edu . Hi! I’m Ankit, and I am a current second year studying Computer Science with an interest in computational biology and things of that nature. Outside of academics, I really enjoy nature, hiking, skiing, and playing tennis. I look forward to meeting everyone! . Anthony Xing . aazing51@uw.edu . Hello! I’m a 3rd-year double majoring in CS and MATH. I am interested in and would like to learn more about many things! . Anupritaa Parasnis . aparas2@uw.edu . Hey, I’m Anupritaa! I’m a sophomore at UW intending to major in Computer Science or ACMS. I really enjoyed taking the Intro Course and learning about the interconnections between neuroscience and AI, so I decided to become a TA. Outside of school, I like reading, working out and playing piano! . Jeffrey Lee . jlee622@uw.edu . Hello! I’m an intended Computer Science major with an interest in machine learning. In my spare time, I like to go to the gym, go on walks, and eat food. I really enjoyed taking the I2 course so I decided to TA for it! . Prayug Sigdel . prayug@uw.edu . Hi, I’m Prayug! I’m currently a sophomore at UW studying computer science. In my free time, I like going to the gym, watching football, and listening to music. ",
    "url": "/pr-preview/pr-48/staff/#autumn-2024-teaching-assistants",
    
    "relUrl": "/staff/#autumn-2024-teaching-assistants"
  },"71": {
    "doc": "Course Staff",
    "title": "Spring 2024 Teaching Assistants",
    "content": "Arya Sanjay . aryas1@cs.washington.edu . Hey, I’m Arya. I really enjoyed the intro course due to my interest in the intersection of ethics and applied machine learning, and since I’m passionate about teaching, I wanted to TA! I’m a CS student at UW, and outside of school, I like exploring new food spots, reading, and trying new things. Jeffrey Junio . jeffrj3@uw.edu . I’m Jeffrey J, a second year, and I’m interested in I2 because of AI &amp; ML, as I plan to use it to eventually take over the world. Other than that, I’m still learning, and am also interested in how it can make education more accessible and personalized. Outside of I2, I have a lot of other interests that change semi-frequently. Right now, I’m into cardistry/magic and Roblox game development. Pushpesh Thakur . pthakur@uw.edu . Hi, I’m Pushpesh! I’m majoring in CS and am interested in AI. I took the i2 intro course and gained a lot of foundational knowledge about AI because of it. In my spare time, I love to play the piano and pretty much any sport (watching sports is an also a hobby). Shey Gao . shengg6@uw.edu . Hi I’m Shey! I’m a junior majoring in computer science, and I’m interested in how AI can contribute to healthcare. I found the I2 Intro Neuro/AI course to be a good starting point for developing interest and exploring more outside of class. One more cool thing I want to explore is freestyle skiing, feel free to reach out if you’re interested as well! . Shravani Bhujbal . sbhujb21@uw.edu . Hi, I am Shravani, and I am a Computer Science major at UW. I enjoyed the Intro course because it gave me a basic knowledge of many subfields in AI. It was really interesting exploring the overlaps of neuroscience and AI. Outside academics, I enjoy traveling, watching movies, and Sudoku. Soham Bhosale . sohamb5@uw.edu . Hey, I’m Soham! I am a freshman majoring in computer science and very interested in AI and its applications in the medical field as well as AI ethics. I really enjoyed exploring and learning about these topics in the I2 Intro Course and that is why I wanted to TA for it. Outside of school, I like traveling, reading and playing tennis! . ",
    "url": "/pr-preview/pr-48/staff/#spring-2024-teaching-assistants",
    
    "relUrl": "/staff/#spring-2024-teaching-assistants"
  },"72": {
    "doc": "Course Staff",
    "title": "Autumn 2023 Teaching Assistants",
    "content": "Eric Ye . ericy4@uw.edu . Hello, I’m Eric, and I joined this club mostly because I found the idea of intelligence really interesting. Is it something that is special and unique, or is it something that could be recreated? I’m leaning towards the latter due to the impressive recent advancements in AI. In my spare time, I enjoy reading and hiking, and I occasionally play tennis. Frank Li . angli23@uw.edu . Hey, this is Frank. I’m a CS junior with a preference for AI and systems. I like learning and fiddling with complex stuff that I don’t understand. In my free time I like to play FPS with my friends while screaming, code some useless things, and read about new tech. Jay Yu . hjyu@cs.washington.edu . Hi, my name is Hongjian /xoŋtɕiɛn/, you can call me Jay for simplicity. I gained a lot from I2’s intro course and hope to help you learn as I did. I major in linguistics and cs. In my spare time I listen to a ton of j-pop and classical. Justin Dong . justindong231@gmail.com . Hi, my name is Justin. I joined I2 to explore an interest in artificial intelligence and machine learning, and being apart of the intro course last year helped me do just that. My hobbies include volleyball, video games, and looking mysterious in libraries. Kelland Harrison . knyo@uw.edu . My name is Kelland. I read a lot of sci-fi as a kid, so I’ve been thinking about AI for a while. I2 has been a great place for me to explore these ideas, and I hope to give you the same experience. I also like electronic music and german poetry. ",
    "url": "/pr-preview/pr-48/staff/#autumn-2023-teaching-assistants",
    
    "relUrl": "/staff/#autumn-2023-teaching-assistants"
  },"73": {
    "doc": "Course Staff",
    "title": "Course Staff",
    "content": " ",
    "url": "/pr-preview/pr-48/staff/",
    
    "relUrl": "/staff/"
  },"74": {
    "doc": "Visual System",
    "title": "Intro to the Visual System",
    "content": "Welcome to the visual system. Before we dive into how computer scientists have hacked together mathematical filters and matrix multiplication to process visual information and extract meaningful output, we will take a hard look at how your eyes and neurons process a continuous bombardment of photons. ",
    "url": "/pr-preview/pr-48/content/visual_system/#intro-to-the-visual-system",
    
    "relUrl": "/content/visual_system/#intro-to-the-visual-system"
  },"75": {
    "doc": "Visual System",
    "title": "Literacy &amp; Technical Track Content",
    "content": "Task 1: . Watch the videos below, and answer any synthesis questions placed along the way. First, some vocab. Dorsal: Upper or back side of something (like a dorsal fin on an orca!) . Ventral: Underside or underbelly of something . Receptive Field: An input that produces the biggest response in some area or neuron is said to be its receptive field . Watch the following videos and answer the questions! You know the drill. The first one will teach us about the physiology of processing light, the complex first layer of our own biological neural network. Video 1: Vision: Crash Course Anatomy &amp; Physiology # 18 . Synthesis Questions: . | Where in the brain do signals from the retina go before reaching the visual cortex? | What are some differences between rods and cones? | Describe the phenomena of retinal neurons that \"get tired\". Do you think there are analogous processes in deep learning or convolutional neural networks? | . The next video will describe the path of information flow through the visual cortex and some core properties of the structure of this process. Video 2: Perception: 3.2 Primary Visual Cortex . Synthesis Questions: . | What wavelengths of light can humans detect? Why might we only be able to detect such a narrow band of light wavelengths? What would be an advantage and downside of processing more? | What is V1 in the visual cortex? What are those cells most sensitive to? | What is the fovea best at detecting? | Describe the retinotopic nature of the visual cortex (7:58) in your own words. Hypothesize whether convolutional neural networks might be organized as \"retinotopic\". | Describe cortical magnification and the causes of the trade-off between acuity and sensitivity. What are several reasons we can't see details from extremely far away, as for example, hawks can? | Brains are constrained by space, which as we have seen with vision, drives trade-offs in our processing. Do neural networks have analogous constraints? What are the effects of this? | Brains are constrained by space, which as we have seen with vision, drives trade-offs in our processing. Do neural networks have analogous constraints? What are the effects of this? | . This final video gives a swift overview of many functional modules of visual processing. This is a great time to start thinking about how all this vision processing compares to our methods of processing information with neural networks! . Video 3: Perception: 3.3 Functional Areas, Pathways, and Modules . Synthesis Questions: . | Describe at least 5 functional parts of the visual system | Explain the hierarchical model of the visual system | What is the \"what\" stream? What does it do? | What is the \"where\" stream? What does it do? | What is a region that processes faces? What inputs does it receive? What other regions is it near? | . This last video is optional but it’s highly recommended that you watch it. This video does a good job at synthesizing all 3 videos and goes more in-depth into certain mechanisms: Visual Processing and the Visual Cortex . Here’s some questions to think about as you watch the video: . | What direction does light go versus information in the retina? | What cells are in the retina? | How do rod photoreceptors adapt to light and dark? | How does each hemisphere receive information from the contralateral visual field? | What is the blind spot? | . Task 2: . Complete the following writing activity. Imagine you got a little too into neural networks and decided to replace your eyes with convolutional neural networks. You may use any sensors, hardware, brain computer interfaces, fungi, wires, Von Neumann computing, neuromorphic computing, or robots that you like (that seem vaguely feasible). How would you replace the algorithms run by the visual cortex with algorithms like those of convolution neural networks? Be creative and let your imagination run free! . Draw your system in detail and write a short paragraph on the following: . | Why did you make the design decisions you made? | What would be the advantages of your system? | What would be the disadvantages? | What hardware did you use to implement this? In your opinion, is it possible to use the existing biological nervous system to run computation algorithms like CNNs? Why? | . ",
    "url": "/pr-preview/pr-48/content/visual_system/#literacy--technical-track-content",
    
    "relUrl": "/content/visual_system/#literacy--technical-track-content"
  },"76": {
    "doc": "Visual System",
    "title": "Visual System",
    "content": " ",
    "url": "/pr-preview/pr-48/content/visual_system/",
    
    "relUrl": "/content/visual_system/"
  }
}
