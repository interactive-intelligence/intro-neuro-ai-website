{"0": {
    "doc": "Announcements",
    "title": "Announcements",
    "content": " ",
    "url": "/pr-preview/pr-36/announcements/",
    
    "relUrl": "/announcements/"
  },"1": {
    "doc": "Announcements",
    "title": "Unit 1 Updated",
    "content": "Oct 12 &middot; 0 min read ML Unit Upgrade: The Machine Learning Unit (Unit 1) has gotten an overhaul. Due to Medium articles being locked behind a paywall, some of the items were outdated. In addition, I wanted to give a more in depth explanation as to how ML algorithms are formulated, with the example being basic linear regression. Please reach out to me if there is anything you see issue with. - Varun Ananth . ",
    "url": "/pr-preview/pr-36/announcements/",
    
    "relUrl": "/announcements/"
  },"2": {
    "doc": "Announcements",
    "title": "Migration to Google Colab",
    "content": "Oct 10 &middot; 0 min read Notebooks in repo soon obsolete: For ease-of-use and accessibility, we have decided to migrate the .ipynb files stored in this repo over to Google Colaboratory. This removes the need to set up an environment and install Anaconda on your personal machine. Colab has many libraries pre-installed and they can be easily imported without much hassle. As of now, only the Unit 1 notebook has been migrated due to some pending updates. The links should all point to Colab soon though. Cheers! . ",
    "url": "/pr-preview/pr-36/announcements/",
    
    "relUrl": "/announcements/"
  },"3": {
    "doc": "Announcements",
    "title": "How to use/contribute",
    "content": "Mar 27 &middot; 1 min read How to use: Take a look at the “Schedule” tab to see how UW I2 uses this website/megadoc. You can take our schedule but since we are on a quarter system it has just 10 weeks of content. All you have to do to run a course like this is create a schedule/syllabus like we have, and have someone able to give a lecture each week on the upcoming unit. All learning + projects are contained on this website! . How to contribute: If you wish to add to this repository of knowledge. please consult the wiki tab of this repo: Website Repository Wiki . ",
    "url": "/pr-preview/pr-36/announcements/",
    
    "relUrl": "/announcements/"
  },"4": {
    "doc": "Announcements",
    "title": "Site Creation!",
    "content": "Mar 26 &middot; 2 min read Hello and welcome to the Interactive Intelligence Intro to Neuro/AI Course website! This website is designed as a template that shows you how to run a course such as this, as well as resources to do so. Here is a short story of how this came to be: In the winter of 2022, a group of individuals saw the need for a Neuro/AI club at the University of Washington Seattle (the university did not even have an active ML club at the time). The club, now known as Interactive Intelligence, was formed on the premise of studying and researching on intelligence in systems. Often times this lended itself to philosophical discussions about AI and what AGI would mean for the world. As the club progressed, project groups were formed and within one year the club had presented posters at two conferences and had one paper concerning Reinforcement Learning accepted and published in a journal. Things were picking up steam. As more and more people heard about the club, we had new recruits join. Unfortunately, we had no rigorous methods of education and many people were left to their own devices to learn these difficult Neuro/AI concepts. This led to a lull in motivation from newer members who found the prospect of digesting all this information simply impossible. This is where the Intro course came in. UW I2 members banded together and in just 2 weeks created the framework for the course you see today. It was refined through a pilot course and by the Spring of 2023, we were able to publish our megadoc on this website. The megadoc is over 40 pages of Neuro/AI content on these topics: . | ML . | Linear Regression | SVM | PCA | K-Means Clustering | . | DL . | Neural network “anatomy” | Backpropagation calculus | . | Neuroanatomy . | Neurons | Action potentials | Major brain modules | . | The Visual System . | Primary visual cortex | . | Computer Vision . | Convolutions | Convolutional neural networks | . | Reinforcement Learning . | Key RL vocabulary | Q, V, Bellman Equations | Deep Q Learning | Epsilon greedy explore-exploit | . | Movement . | The cerebellum | . | Language Modeling . | Word Embeddings | Recurrent neural networks | Backpropagation through time | Truncated backpropagation through time | Transformers | Huggingface | . | AI Fairness/Theory . | TBD | . | Pain in RL/Neuroscience/Cognitive Science . | Biological pain in the context of RL | MaxPain Algorithm | . | Networks and Systems of the Brain . | Nature vs. Nurture | Brain Networks | . | . And also: . | Pytorch | Jupyter notebooks | LaTeX | Self-learning skills | . This course is a very basic survey of Neuro/AI and was made to get people excited about intelligence research. We wanted to share this amazing resource with others that wish to use it in their own club. If you need any assistance getting this up and running, please contact the education lead in the “Creators” tab. Happy Learning! . ",
    "url": "/pr-preview/pr-36/announcements/",
    
    "relUrl": "/announcements/"
  },"5": {
    "doc": "Graduates",
    "title": "Graduates",
    "content": "These are the hardworking and dedicated students who have graduated from the course! . ",
    "url": "/pr-preview/pr-36/graduates/",
    
    "relUrl": "/graduates/"
  },"6": {
    "doc": "Graduates",
    "title": "Spring 2024",
    "content": "Adam Skoglund . Aditya Shirodkar . Ajit Mallavarapu . Anoushka Dalvi . Anupritaa Parasnis . Brinda Moudgalya . Christopher Tan . Eden McPeek . Elaine Lu . Jeffrey Lee . John Jin . Johnathan Nister . Kaden Pothisuntorn . Kandace Kimball . Maya Falodia . Nathan Zeon . Ping Wang . Ruize Jia . Vaibhav Paranji . ",
    "url": "/pr-preview/pr-36/graduates/#spring-2024",
    
    "relUrl": "/graduates/#spring-2024"
  },"7": {
    "doc": "Graduates",
    "title": "Autumn 2023",
    "content": "Aiden Reeder . Anika Tak . Annabelle Martin . Anthony Xing . Arya Sanjay . Dalton Brockett . Diya Yaga . Helena Zheng . Ian Chiu . Ian Hutchings . Jeffrey Junio . Jessie Sun . John Burnham . Misha Nivota . Mo Young . Muhammad Khairullah . Pushpesh Thakur . Rajat Sengupta . Rasool Isaac Ray . Richie Doan . Samantha Guernsey . Samarth Venkatesh . Sehaj Dhillon . Shravani Bhujbal . Shreya Shaji . Soham Bhosale . Solomon Beall . Timothy Zhong . Yuning Hu . Zijing Wei . ",
    "url": "/pr-preview/pr-36/graduates/#autumn-2023",
    
    "relUrl": "/graduates/#autumn-2023"
  },"8": {
    "doc": "Graduates",
    "title": "Spring 2023",
    "content": "Albert Wang . hw233@uw.edu . Angelo Dauz . gelo@uw.edu . Ethan Bai . ebai2022@cs.washington.edu . Great way to get a foot into the AI/ML door and learn some cool neuroscience along the way . Feier Long . feier513@uw.edu . It was an inspiring community where you get to learn and talk about cool things with intelligence, the brain, and possibly any combination in between. Frankie Reyna . frankier@uw.edu . Jay Yu . hjyu@cs.washington.edu . I2’s intro provides all you need to quickstart a deep learning / neroscience project! . Justin Dong . justindong231@gmail.com . Kelland Harrison . kellandnharrison@gmail.com . Molly Park . mollysypark@gmail.com . With all the buzz surrounding AI these days, it was super interesting to learn about the connection between neuroscience concepts and computational models. Looking forward to exploring these connections further in the coming years! . Siddharth Thiagarajan . sid04@uw.edu . Tyler Ramos . tylerramos4401@gmail.com . ",
    "url": "/pr-preview/pr-36/graduates/#spring-2023",
    
    "relUrl": "/graduates/#spring-2023"
  },"9": {
    "doc": "Graduates",
    "title": "Winter 2023",
    "content": "Ameya Agrawal . aameya16@uw.edu . I2’s intro course was the perfect balance of hands-on projects and theory! I learned a lot throughout this course, and felt much more confident in my knowledge and understanding of both machine learning and neuroscience (and how they are connected)! . Eric Ye . ericy4@uw.edu . Frank Li . angli23@uw.edu . Greg Baimetov . gregory.baimetov@gmail.com . Gunn Chun . kimkun17@uw.edu . The most interesting course I took, dense with information yet still approachable. Gunn Kim . kimkun17@uw.edu . Vibhav Peri . vibhavperi@gmail.com . The course introduced me to complex topics I was never willing to tackle on my own. This was the gateway that gave me knowledge and experience in a field I’ve been interested in for a while. ",
    "url": "/pr-preview/pr-36/graduates/#winter-2023",
    
    "relUrl": "/graduates/#winter-2023"
  },"10": {
    "doc": "Megadoc",
    "title": "Megadoc",
    "content": "Hello, and welcome to the i2 Neuro/AI Megadoc. Here you can find all sorts of resources designed to help YOU become an amazing Neuro/AI* researcher! . How to use (ignore if following curriculum): . | Take a look at the table of contents and get a sense for what you do/don’t know . | Start from the beginning if you are brand new OR | Pick a topic that looks interesting! | . | For each major topic we have linked Resources, Questions, and sometimes a mini-project that will take you to our project repo! | Be sure to ask questions and share cool things you learn with everyone in your group (if applicable)! | . This document assumes you have a basic understanding of Python, calculus, and linear algebra. Be sure to refresh concepts that you don’t know instead of continuing on without understanding. ",
    "url": "/pr-preview/pr-36/megadoc/",
    
    "relUrl": "/megadoc/"
  },"11": {
    "doc": "I2 Course",
    "title": "I2 Intro Neuro/AI Course",
    "content": ". ",
    "url": "/pr-preview/pr-36/#i2-intro-neuroai-course",
    
    "relUrl": "/#i2-intro-neuroai-course"
  },"12": {
    "doc": "I2 Course",
    "title": "If you’re looking to join Autumn 2024",
    "content": "Please follow the following links! . Course Application (non-competitive) . I2 Discord . Hello! Welcome to the Introduction to Neuro/AI Interactive Intelligence (i2) crash course (now opencourseware)! . Please remember: . | We are all trying to learn, and learn at different speeds. | This course is somewhat of a commitment. You will get out what you put in | There are no grades! This is all for your learning alone. | Contact any mentor at any point if you have any questions. Seriously, we are here to help &lt;3 | Be helpful, be kind, and have fun! | . What basics you will learn (a more detailed list can be found in the announcements): . | ML | DL | Neuroanatomy | Computer Vision | Reinforcement Learning | Movement | Language Modeling | AI Fairness/Theory | Pain in RL/Neuroscience/Cognitive Science | More about the brain | . And also: . | Pytorch | Jupyter notebooks | LaTeX | Self-learning skills | . ",
    "url": "/pr-preview/pr-36/#if-youre-looking-to-join-autumn-2024",
    
    "relUrl": "/#if-youre-looking-to-join-autumn-2024"
  },"13": {
    "doc": "I2 Course",
    "title": "If you wish to contrubute, check out the wiki tab!",
    "content": " ",
    "url": "/pr-preview/pr-36/#if-you-wish-to-contrubute-check-out-the-wiki-tab",
    
    "relUrl": "/#if-you-wish-to-contrubute-check-out-the-wiki-tab"
  },"14": {
    "doc": "I2 Course",
    "title": "Also please check out the i2 Labs Website and register your team!",
    "content": " ",
    "url": "/pr-preview/pr-36/#also-please-check-out-the-i2-labs-website-and-register-your-team",
    
    "relUrl": "/#also-please-check-out-the-i2-labs-website-and-register-your-team"
  },"15": {
    "doc": "I2 Course",
    "title": "I2 Course",
    "content": " ",
    "url": "/pr-preview/pr-36/",
    
    "relUrl": "/"
  },"16": {
    "doc": "Schedule",
    "title": "Schedule",
    "content": " ",
    "url": "/pr-preview/pr-36/schedule/",
    
    "relUrl": "/schedule/"
  },"17": {
    "doc": "Schedule",
    "title": "Week 0: Course Overview, Prerequisite Knowledge",
    "content": "Purpose . | Gen acquainted with the course | Learn some of the pre-reqs necessary (Python) | Learn some of the pre-reqs necessary (calculus, linear algebra) | . Resources . Python Resources: . | CS50x Intro to Python Course | CS231n notes on Python, Numpy, and Jupyter Notebooks | . Math Resources: . | Linear Algebra Review and Reference (Just Unit 1) | Vector Basics | Hyperplane Definition | Hyperplane Math | Partial Derivatives (Mathematical) | Partial Derivatives (Graphical) | . Assignment . IMPORTANT!: If you already know a topic, DO NOT waste your time re-doing it. This week is just to refresh your mind . That being said, if you are unfamiliar with most of the items here, focus on Python and be sure to ask lots of questions! . Python Assignments: . | Complete units in the CS50x Intro to Python Course as needed (If you are confident, feel free to skip a section). I recommend: . | 0: Functions, Variables | 1: Conditionals | 2: Loops | 4: Libraries | 9: Et Cetera | . | Read through CS231n Notes, focusing on: . | Containers | Numpy | MatPlotLib | . | . Math Assignments: . | Read/Watch provided resources to learn/refresh your math knowledge. | If you are already familiar with the concepts listed above, feel free to skip them. I would, however, reccomend you explore linear algebra in high dimensional spaces (specifically hyperplanes) and revisit partial derivatives. | . Summary Questions . | What topics did you learn this week (Python or math)? | . ",
    "url": "/pr-preview/pr-36/schedule/#week-0-course-overview-prerequisite-knowledge",
    
    "relUrl": "/schedule/#week-0-course-overview-prerequisite-knowledge"
  },"18": {
    "doc": "Schedule",
    "title": "Week 1: Introduction to Machine Learning",
    "content": "Purpose . An introduction to the foundation of modern AI! . | Introduction to Machine Learning (ML) | Math behind Linear Regression, SVM, PCA | Basic Unsupervised Clustering | . Resources . | Megadoc Unit 1 | . Assignment . | Complete Unit 1 in the megadoc (synthesis questions included) | Either Scikit-Learn ML Technical-Project (in megadoc) | Or Non-Technical Writing Project (bottom of megadoc) | . Summary Questions . | Synthesis questions in the megadoc | . ",
    "url": "/pr-preview/pr-36/schedule/#week-1-introduction-to-machine-learning",
    
    "relUrl": "/schedule/#week-1-introduction-to-machine-learning"
  },"19": {
    "doc": "Schedule",
    "title": "Week 2: Introduction to Neural Networks",
    "content": "Purpose . Our first foray into more complex networks and how they learn. | Introduction to Deep Learning (DL) | Introduction to Neural Networks | Introduction to Backpropagation | . Resources . | Megadoc Unit 2 | CS231n Notes on Neural Networks. See Module 1: Neural Networks - great written resource for the basics. | . Assignment . | Complete Unit 2 in the megadoc (synthesis questions included) | Basic MNIST Classifier (in megadoc/github) | . Summary Questions . | Synthesis questions in the megadoc | . ",
    "url": "/pr-preview/pr-36/schedule/#week-2-introduction-to-neural-networks",
    
    "relUrl": "/schedule/#week-2-introduction-to-neural-networks"
  },"20": {
    "doc": "Schedule",
    "title": "Week 3: Basic Neuroanatomy",
    "content": "Purpose . Welcome to a beginner’s introduction to neuroscience! We will . | Learn several basic regions of the brain | Learn fundamentals of the neuron and biological computation -Begin to hypothesize about the parallels and divergences of machine learning and the brain | . Resources . | Megadoc Unit 3 | . Assignment . | Complete Unit 3 in the megadoc (synthesis questions included) | Basic Neuroanatomy Project (LaTeX template in github) | . Summary Questions . | Synthesis questions in the megadoc | . ",
    "url": "/pr-preview/pr-36/schedule/#week-3-basic-neuroanatomy",
    
    "relUrl": "/schedule/#week-3-basic-neuroanatomy"
  },"21": {
    "doc": "Schedule",
    "title": "Week 4: Convolutional Neural Networks",
    "content": "Purpose . | Deep Learning for Vision | Learn about Convolutional Neural Networks | . Resources . | Megadoc Unit 4 | . Assignment . | Complete Unit 4 in the megadoc (synthesis questions included) | ConvNet Project (in megadoc/github) | . Summary Questions . | Synthesis questions in the megadoc | . ",
    "url": "/pr-preview/pr-36/schedule/#week-4-convolutional-neural-networks",
    
    "relUrl": "/schedule/#week-4-convolutional-neural-networks"
  },"22": {
    "doc": "Schedule",
    "title": "Week 5: The Visual System",
    "content": "Purpose . This week we take a small break from computation and return to the brain, specifically your insanely complex and elegant visual system! We will . | Learn the basic anatomical and functional regions of the visual system | Compare biological solutions to visual tasks with computational solutions | . Resources . | Megadoc Unit 5 | . ",
    "url": "/pr-preview/pr-36/schedule/#week-5-the-visual-system",
    
    "relUrl": "/schedule/#week-5-the-visual-system"
  },"23": {
    "doc": "Schedule",
    "title": "Week 6: Reinforcement Learning",
    "content": "Purpose . | Go over basics of RL | Learn about Deep Q Learning | . Resources . | Megadoc Unit 6 | Spinning Up | . Assignment . | Complete Unit 6 in the megadoc (synthesis questions included) | . Summary Questions . | Synthesis questions in the megadoc | What’s one resource that was helpful (suggested or found on your own)? | . ",
    "url": "/pr-preview/pr-36/schedule/#week-6-reinforcement-learning",
    
    "relUrl": "/schedule/#week-6-reinforcement-learning"
  },"24": {
    "doc": "Schedule",
    "title": "Week 7: AI Ethics",
    "content": "Purpose . | Learn about ethics in AI and think about how ethical AI is developed. | . Resources . | Megadoc Unit 7 | . Assignment . | Create a slideshow, details in the megadoc | . Summary Questions . | Synthesis questions in the megadoc | . ",
    "url": "/pr-preview/pr-36/schedule/#week-7-ai-ethics",
    
    "relUrl": "/schedule/#week-7-ai-ethics"
  },"25": {
    "doc": "Schedule",
    "title": "Week 8: Language Modeling",
    "content": "Purpose . | Learn about word embeddings | Learn about Recurrent Neural Networks | Learn about Transformers | Learn about fine-tuning foundation models like GPT | Gain a basic intuition about transformer and language models | . Resources . | Megadoc Unit 8 | . Assignment . | Complete Unit 8 in the megadoc (synthesis questions included) | HuggingFace Project Part 1 (in megadoc) | HuggingFace Project Part 2 (in megadoc) | . Summary Questions . | Synthesis questions in the megadoc | . ",
    "url": "/pr-preview/pr-36/schedule/#week-8-language-modeling",
    
    "relUrl": "/schedule/#week-8-language-modeling"
  },"26": {
    "doc": "Schedule",
    "title": "Week 9: Certificates + Unit 11",
    "content": "Purpose . | Certificates! | Celebrate your good work | Introduce Unit 11 as a fun side quest :) | . Resources . | Megadoc Unit 11 | . ",
    "url": "/pr-preview/pr-36/schedule/#week-9-certificates-unit-11",
    
    "relUrl": "/schedule/#week-9-certificates-unit-11"
  },"27": {
    "doc": "Course Staff",
    "title": "Course Staff",
    "content": "Here are the awesome people who made the course + website. Feel free to contact us if you have any issues! . ",
    "url": "/pr-preview/pr-36/staff/",
    
    "relUrl": "/staff/"
  },"28": {
    "doc": "Course Staff",
    "title": "Education Leads",
    "content": "Ameya Agrawal . aameya16@cs.washington.edu . Hey there, I’m Ameya! I took the intro course myself the first time it was run and absolutely loved it, so I decided to TA for it, and now I’m leading it! I am fortunate to be surrounded by intelligent, dedicated i2 leadership who share a common passion for Neuro/AI and are always happy to help. I really enjoyed this course as it provided me with a great starting point to further explore Neuro/AI and I hope it does the same for you. Outside of i2, I’m a junior in CS at UW, and I absolutely love solving puzzles, playing video games and am always down for a game of pool! . Vibhav Peri . vperi@uw.edu . Hey, I’m Vibhav! I’m currently a junior here at UW in CS. I had been interested in learning ML since I came to the university, but was completely overwhelmed by where to start. The intro course was exactly what I needed! I liked the course enough to TA it the following quarter, and now I’m thrilled to be leading it with Ameya! In my free time I enjoy running and videogames among many other nerdy things. ",
    "url": "/pr-preview/pr-36/staff/#education-leads",
    
    "relUrl": "/staff/#education-leads"
  },"29": {
    "doc": "Course Staff",
    "title": "The Creators",
    "content": "Carter Swartout . swartout@uw.edu . Hi, I’m Carter! I’m a CS student studying deep learning, primarily NLP. I’ve always had a childlike wonder with “intelligent computers” and I’m delighted I get to improve them with I2. Outside of school I love reading, biking, and being confused by puzzles! . Chaytan Inman . chaytan@uw.edu . I’m Chaytan. I guess the first thing to know about me is that I love rain, trees, fungi, and plants, and they’re what made me want to form this team. I think that technology has enabled humans to destroy ourselves and organisms around us, but I’m hoping that the right technology can also enable us to reevaluate how we think and act. To me this team is an environment about experimenting and discovering those technologies: codifying generally intelligent computation and environmental understanding through environmental interaction. Varun Ananth . varunananth1@gmail.com . Hey there! My name is Varun. I have been working on this course for a while and with the help of some amazing people, it came together. I really believe in the power of education and teaching and how it can shape lives. I attribute my successes today to my teachers, peer or adult. With this course I aim to spark interest for Neuro/AI in college students around the world. My specialty within DL is Reinforcement Learning, and I hope to be able to continue research in that field. Apart from nerdy stuff, I enjoy guitar, skateboarding, and videogames. So basically more nerdy stuff. ",
    "url": "/pr-preview/pr-36/staff/#the-creators",
    
    "relUrl": "/staff/#the-creators"
  },"30": {
    "doc": "Course Staff",
    "title": "Autumn 2024 Teaching Assistants",
    "content": "Anthony Xing . aazing51@uw.edu . Hello! I’m a 3rd-year double majoring in CS and MATH. I am interested in and would like to learn more about many things! . Anupritaa Parasnis . aparas2@uw.edu . Hey, I’m Anupritaa! I’m a sophomore at UW intending to major in Computer Science or ACMS. I really enjoyed taking the Intro Course and learning about the interconnections between neuroscience and AI, so I decided to become a TA. Outside of school, I like reading, working out and playing piano! . Jeffrey Lee . jlee622@uw.edu . Hello! I’m an intended Computer Science major with an interest in machine learning. In my spare time, I like to go to the gym, go on walks, and eat food. I really enjoyed taking the I2 course so I decided to TA for it! . Prayug Sigdel . prayug@uw.edu . Hi, I’m Prayug! I’m currently a sophomore at UW studying computer science. In my free time, I like going to the gym, watching football, and listening to music. ",
    "url": "/pr-preview/pr-36/staff/#autumn-2024-teaching-assistants",
    
    "relUrl": "/staff/#autumn-2024-teaching-assistants"
  },"31": {
    "doc": "Course Staff",
    "title": "Spring 2024 Teaching Assistants",
    "content": "Arya Sanjay . aryas1@cs.washington.edu . Hey, I’m Arya. I really enjoyed the intro course due to my interest in the intersection of ethics and applied machine learning, and since I’m passionate about teaching, I wanted to TA! I’m a CS student at UW, and outside of school, I like exploring new food spots, reading, and trying new things. Jeffrey Junio . jeffrj3@uw.edu . I’m Jeffrey J, a second year, and I’m interested in I2 because of AI &amp; ML, as I plan to use it to eventually take over the world. Other than that, I’m still learning, and am also interested in how it can make education more accessible and personalized. Outside of I2, I have a lot of other interests that change semi-frequently. Right now, I’m into cardistry/magic and Roblox game development. Pushpesh Thakur . pthakur@uw.edu . Hi, I’m Pushpesh! I’m majoring in CS and am interested in AI. I took the i2 intro course and gained a lot of foundational knowledge about AI because of it. In my spare time, I love to play the piano and pretty much any sport (watching sports is an also a hobby). Shey Gao . shengg6@uw.edu . Hi I’m Shey! I’m a junior majoring in computer science, and I’m interested in how AI can contribute to healthcare. I found the I2 Intro Neuro/AI course to be a good starting point for developing interest and exploring more outside of class. One more cool thing I want to explore is freestyle skiing, feel free to reach out if you’re interested as well! . Shravani Bhujbal . sbhujb21@uw.edu . Hi, I am Shravani, and I am a Computer Science major at UW. I enjoyed the Intro course because it gave me a basic knowledge of many subfields in AI. It was really interesting exploring the overlaps of neuroscience and AI. Outside academics, I enjoy traveling, watching movies, and Sudoku. Soham Bhosale . sohamb5@uw.edu . Hey, I’m Soham! I am a freshman majoring in computer science and very interested in AI and its applications in the medical field as well as AI ethics. I really enjoyed exploring and learning about these topics in the I2 Intro Course and that is why I wanted to TA for it. Outside of school, I like traveling, reading and playing tennis! . ",
    "url": "/pr-preview/pr-36/staff/#spring-2024-teaching-assistants",
    
    "relUrl": "/staff/#spring-2024-teaching-assistants"
  },"32": {
    "doc": "Course Staff",
    "title": "Fall 2023 Teaching Assistants",
    "content": "Eric Ye . ericy4@uw.edu . Hello, I’m Eric, and I joined this club mostly because I found the idea of intelligence really interesting. Is it something that is special and unique, or is it something that could be recreated? I’m leaning towards the latter due to the impressive recent advancements in AI. In my spare time, I enjoy reading and hiking, and I occasionally play tennis. Frank Li . angli23@uw.edu . Hey, this is Frank. I’m a CS junior with a preference for AI and systems. I like learning and fiddling with complex stuff that I don’t understand. In my free time I like to play FPS with my friends while screaming, code some useless things, and read about new tech. Jay Yu . hjyu@cs.washington.edu . Hi, my name is Hongjian /xoŋtɕiɛn/, you can call me Jay for simplicity. I gained a lot from I2’s intro course and hope to help you learn as I did. I major in linguistics and cs. In my spare time I listen to a ton of j-pop and classical. Justin Dong . justindong231@gmail.com . Hi, my name is Justin. I joined I2 to explore an interest in artificial intelligence and machine learning, and being apart of the intro course last year helped me do just that. My hobbies include volleyball, video games, and looking mysterious in libraries. Kelland Harrison . knyo@uw.edu . My name is Kelland. I read a lot of sci-fi as a kid, so I’ve been thinking about AI for a while. I2 has been a great place for me to explore these ideas, and I hope to give you the same experience. I also like electronic music and german poetry. ",
    "url": "/pr-preview/pr-36/staff/#fall-2023-teaching-assistants",
    
    "relUrl": "/staff/#fall-2023-teaching-assistants"
  },"33": {
    "doc": "Unit 01 Technical Article",
    "title": "Unit 1: Technical Article",
    "content": " ",
    "url": "/pr-preview/pr-36/megadoc/unit-01-tech-article/#unit-1-technical-article",
    
    "relUrl": "/megadoc/unit-01-tech-article/#unit-1-technical-article"
  },"34": {
    "doc": "Unit 01 Technical Article",
    "title": "Unit 01 Technical Article",
    "content": " ",
    "url": "/pr-preview/pr-36/megadoc/unit-01-tech-article/",
    
    "relUrl": "/megadoc/unit-01-tech-article/"
  },"35": {
    "doc": "Unit 01",
    "title": "Unit 1: The (machine learning) Basics",
    "content": "Hello and welcome to the Basics section of the I2 megadoc! Our content will be split into two categories: literacy and technical understanding. These topics are fundamental to the entire rest of our course, so please don’t hesitate to reach out to the course staff if you have any questions! . Task 1: Read either the literacy article “Back to Basics” or the technical article linked below to get an intuitive understanding of machine learning. This is required. Unit 01 Technical Article .   Task 2: Go through the text and videos in your respective article and answer the provided synthesis questions. Submit your answers to your intro course TA. Make sure to indicate in your submission or file name which article (technical or literacy) you read and which questions you’re answering. Link to this task . Task 3: Complete either the technical project or the non-technical project. Submit your work to the intro course TA. Link to this task . ",
    "url": "/pr-preview/pr-36/megadoc/unit-01/#unit-1-the-machine-learning-basics",
    
    "relUrl": "/megadoc/unit-01/#unit-1-the-machine-learning-basics"
  },"36": {
    "doc": "Unit 01",
    "title": "Back to Basics: Machine Learning",
    "content": "This article is going to cover what machine learning is at a conceptual level. The general idea behind machine learning is that a machine uses known information to make predictions about unknown information—much like humans. For a long time, we used computer programming to manually give computers instructions on how to do things. But there are a lot of things that we may want computers to do that are far too advanced to manually instruct them on. The goal of machine learning, then, is to get computers to “learn” how to do tasks so that we don’t have to give it explicit instructions. To better understand this, let’s look at an example. Imagine we want our computer to identify pictures of cats and pictures of pigs. Our computer has never seen a pig or a cat before, so we have to give it some information to help it get started. Let’s feed our computer the following images. We’ll label the pictures of cats “cat” and the pictures of pigs “pig,” so the computer knows which is which. Now the computer has to figure out what makes the cat pictures different from the pig pictures. What does it notice? Well, all the cats are furry and all the pigs are pink. So the computer comes up with the following system: . | if the picture has a furry, non-pink animal, it’s a cat | if the picture has a non-furry, pink animal, it’s a pig | otherwise the computer isn’t sure | . Okay, let’s see how it does! We give the computer these three pictures and ask it to classify them as “cat” or “pig.” . The computer classifies the first animal, which is furry and not pink, as a cat—perfect! But it classifies the second, which is not furry and pink, as a pig, and the third, which is furry and not pink, as a cat. Now we have to correct our computer. We let it know that it was right about the first image, but the other two were wrong. Here’s where the crucial part of machine learning comes in: the computer looks at the images again and learns why it was wrong. It realizes that not all cats are furry and not all pigs are pink. Maybe it also realizes that all the cats we provided have long tails, and all the pigs have long snouts. Whatever the case, the computer learns how to better classify the animals based on the data we provided. It learns which features are crucial and which features are optional in its decision, and the more data we provide, the more it refines its processes and produces accurate predictions. This occurs over many, many, many trials, until it finally begins to make perfect predictions. This is the very general idea of how machine learning works. But what does it mean for a computer to “learn”? How does a machine “learn” anything, the way humans learn? For that matter, how can the computer tell that the pictures of cats have fur in them, or that the pictures of pigs contain long snouts? . These are exactly the questions that this course aims to answer. We’ll learn how humans learn, how machines learn, and how our understanding of one allows us to develop our understanding of the other. We’ll also learn how humans interpret images and pictures, and how we can use that information to get computers to do the same thing. For now, though, check out the rest of the homework and the synthesis questions provided. ",
    "url": "/pr-preview/pr-36/megadoc/unit-01/#back-to-basics-machine-learning",
    
    "relUrl": "/megadoc/unit-01/#back-to-basics-machine-learning"
  },"37": {
    "doc": "Unit 01",
    "title": "Unit 1 Synthesis Questions",
    "content": "Video 1: How AIs, like ChatGPT, Learn (9 min) . This first video describes how exactly a machine “learns”—we’ll talk about this even more in Unit 2! . Synthesis Questions: . | What are the limitations of early “if this, then that” logic? | Why do we need a teach-build cycle to get our machine to learn? | Why does this teach-build-teach-build cycle work? How do the “bots” get better over time? | Why is it so important for companies to use a good dataset to teach their bots? | . Article 1: (this is the same article from later in this megadoc!) . The next article is math-heavy, but very useful for understanding how ML works. Reach out to a TA if you have any questions–this can be tough! . Linear Regression . The two main tasks that statistical ML attempts to solve are the classification task and regression task. Classification is the task of bucketing a set of items $S$ into $k$ categories. We will explore classification more in Unit 2. Regression is the task of predicting the value of one variable (usually called the responding variable), given the values of other feature variables. For example, predicting a person’s weight based on their height. The weight is the responding variable/label ($y$) and the height is the feature variable ($x$). You can also have the case with multiple dependent variables. You could be attempting to predict the cost of a house depending on its square footage ($x_1$), location ($x_2$), number of floors ($x_3$) and other things ($x_n$). Each of these $x$ items is called a feature. Let’s start with the case of one responding variable and one feature. Below is a plot with some data, and lines that could be the “best fit” for the data. Which line is the best fit? . Obviously it is line B. But how do you know that? You will probably say that it is due to how close the dots are to the line (in comparison to the other lines). We can formalize this “goodness of fit” with a Sum of Squared Errors calculation (SSE). Sum of Squared Errors and Least Squares . To calculate this, simply compare the distance from the ACTUAL y-values/labels ($y_1$, $y_2$,…,$y_n$) to the PREDICTED y values ($\\hat{y}_1$, $\\hat{y}_2$,…,$\\hat{y}_n$), and square the differences to account for negatives (absolute value cannot be used easily due to it not being differentiable everywhere. This becomes important later). The equation is: \\(SSE = \\sum_{i} (y_i - \\hat{y}_i)^2\\) . Intuitively, you can see that if $y$ and $\\hat{y}$ are closer, the SSE will be smaller. Therefore we want to minimize the SSE. Doing this is called **Least Squares (LS)** regression. Now we turn attention to $\\hat{y}$ (the hat decorator just means that it is predicted, not a ground truth). How is it calculated? We all know the $y = mx + b$ formula for a line. $m$ is the slope and $b$ is the intercept. However, the equation looks different when we have many features (many $x$). \\(\\hat{y} = b + w_1x_1 + w_2x_2 +...+w_nx_n\\) The $x$ subscript here represents different features within 1 datapoint. The $b$ term is the intercept and the $w$ terms are the slopes on different dimensions. You can just think of them as coefficients for each feature. We can rewrite this long form sum as a dot product. \\[\\hat{y}_i = x_i^Tw + b\\] NOTE: The $x$ subscript here represents 1 datapoint now instead of 1 feature (remember we have many dots on the graph). Here is a visual diagram of why this an equivalence. This is where some linear algebra intuition may come in handy. Dealing with the $b$-term . To make this even easier for us, we can remove the $b$ term from the equation by appending a $b$ and $1$ to $w$ and $x_i^T$ respectively. Now we have that: . \\[\\hat{y}_i = x_i^Tw\\] With the $b$ term implicitly encoded. Plugging this back into the SSE equation: . \\[SSE = \\sum_{i} (y_i - x_i^Tw)^2\\] $x$ and $y$ are provided by the data. We cannot change them. The $w$ vector, however, has parameters ($w_1$, $w_2$,…,$w_n$) that we can learn to fit the data! . This is Machine Learning! . Make sure you understand the setup so far, because we are going into some calculus now. Solving for w . We want to find the parameters ($w$, and $b$ implicitly) that minimize the SSE. In other words, what values of $w$, $b$ will make it so that the SSE equation evaluates to the smallest number possible. This notates as $\\arg\\min$. \\[\\hat{w}_{LS}=\\underset{w}{\\operatorname{\\arg\\min}}\\sum_{i} (y_i - x_i^Tw)^2\\] To solve for the left hand side of this equation, you would take the derivative of the equation $\\sum_{i} (y_i - x_i^Tw)^2$ with respect to $w$, set it equal to zero, and solve for the $w$ term. Once you write $w$ in terms of $x$ and $y$, it is the solution to the optimization problem we defined above. Just to clarify: the value we are solving for is the vector of weights or coefficients that minimize the SSE in the Least Squares (LS) formulation of linear regression (which is what we are doing). \\[\\frac{\\partial}{\\partial w}\\sum_{i} (y_i - x_i^Tw)^2 = 0\\] The derivation is difficult (and it is very easy to mess up) so we won’t try and make you learn/memorize it. However, if you are curious, here is a whiteboard example. We ultimately get that: . \\[\\hat{w}_{LS} = (X^TX)^{-1}X^Ty\\] Where $X$ is a matrix created from stacking all $x_i$ examples on top of one another, and $y$ is a vector of all of the $y_i$ labels stacked. Below is a visual to help you understand: . Awesome! You now have a weight vector that you can multiply by a new set of features to predict the $y$ for that set of features! If you want to, you can easily code this up in numpy with a dummy dataset to prove to yourself that the simple equation I showed you previously works! The best part about this closed form solution is that this is the mathematically best set of weights that solves this problem. A problem where all minima are global minima is called convex. The main takeaway here is the intuition behind setting up a machine learning problem: . | Create a model with parameters | Find an objective function to minimize that uses the model | Derive and solve if a closed form solution exists | . In some cases a closed form solution will not exist. There are ways around this, one of them being Gradient Descent (Unit 2). However, this is beyond the scope of this unit and a whole class could be taught on these concepts. If you wish to dive deeper, take the ML class offered by your university! . Synthesis Questions: . | What is a feature in this context? | What are the significance of the w terms within the modified y = mx + b equation described in the article? | What is SSE? . | How is it calculated? | What can it tell you about the values you chose for w? | If you modify the $w_1$ term and the SSE goes up, was that a good modification? | . | How is the bias term implicitly encoded? | Write out the linear regression formula when you wish to estimate the impact of age, height, and weight of someone on their marital status. | Hint: How many x terms will there be? How many features? | . | . ",
    "url": "/pr-preview/pr-36/megadoc/unit-01/#unit-1-synthesis-questions",
    
    "relUrl": "/megadoc/unit-01/#unit-1-synthesis-questions"
  },"38": {
    "doc": "Unit 01",
    "title": "Unit 1 Project Specs",
    "content": "Non-Technical Project Spec: . The non-technical project for this unit will involve some writing! Choose 3 of the prompts below and write at least 200 (meaningful!) words on each one! We will not be strictly grading you on correctness or anything like that. This is an opportunity to deeply engage with the material you have just learned about, and creatively connect it to neuroscience! . | What might be some applications of principle component analysis (PCA) in neuroscience research? Explain your ideas. | What might be some advantages and disadvantages of applying machine learning to neuroscience? | What are the ethical implications of using machine learning in neuroscience research? | What might be some applications of support vector machines (SVM) in neuroscience? Be creative! | Reflecting on your learning from this unit, what is one thing you found to be most interesting? Something that | What is one concept from this unit that you would like to learn more about and why? | . Be sure to submit your work through google drive using the submission form! We would prefer that you upload it to your own Drive first, then use the submission form dropbox to connect that file to your submission! . Technical Project Spec: . The project for this “Basics” section will have you finish a code template through Google Colab. Please ask questions as you work through this project. Be sure to discuss with others in your group if you have one! Share your answers as you like, the goal is to learn and we’re not holding grades over your head. This project will be going over k-means clustering (unsupervised ML). We will be using the Scikit-Learn library. A few general helpful tips (if applicable): . | Be sure to appropriately make a copy of the Colab template before starting to save your progress! | Renaming your copy to something that contains your name is a good idea, it will make it easier for us to review your submissions. | Leave comments to cement your understanding. Link syntax to ideas. | . Check out this handy image that gives popular sk-learn clustering algorithms and their usages: . Also this image visualizing the clustering algorithms: . Read up on k-means clustering in the provided link (Images provided above also contained here). Feel free to check out the other algorithms as well: SK-Learn Clustering . Now, follow the instructions on this Jupyter notebook (hosted on Google Colab) to implement some of the things we talked about! The notebook contains a link to the answers for this project. To use it, you will need to import the ‘.ipynb’ file to a new Colab project yourself. It is highly recommended that you only use this to check your answers after you are done completing the project yourself. This is a trust-based system! . Colab Link: Unit 1 Colab Template (30 min) . When you are finished with your code, independently verify that it works and have fun with it! You could try this method on different datasets, such as this one for example. If you add any additional functionality be sure to talk about it with others and give them ideas. Remember that this is all for your learning, so do your best and don’t stress! . Congratulations! You now understand the basics of Clustering and PCA! . Download Unit 01 Technical Article (PDF) . ",
    "url": "/pr-preview/pr-36/megadoc/unit-01/#unit-1-project-specs",
    
    "relUrl": "/megadoc/unit-01/#unit-1-project-specs"
  },"39": {
    "doc": "Unit 01",
    "title": "Unit 01",
    "content": " ",
    "url": "/pr-preview/pr-36/megadoc/unit-01/",
    
    "relUrl": "/megadoc/unit-01/"
  },"40": {
    "doc": "Unit 02 Technical Article",
    "title": "Unit 2: Technical Article",
    "content": " ",
    "url": "/pr-preview/pr-36/megadoc/unit-02-tech-article/#unit-2-technical-article",
    
    "relUrl": "/megadoc/unit-02-tech-article/#unit-2-technical-article"
  },"41": {
    "doc": "Unit 02 Technical Article",
    "title": "Unit 02 Technical Article",
    "content": " ",
    "url": "/pr-preview/pr-36/megadoc/unit-02-tech-article/",
    
    "relUrl": "/megadoc/unit-02-tech-article/"
  },"42": {
    "doc": "Unit 02",
    "title": "Unit 2: The (deep learning) Basics",
    "content": "Hello and welcome to the Basics section of the I2 megadoc! Like last week, we’re going to split our content into literacy and technical understanding. Task 1: Read either the literacy article “Back to Basics” or the technical article linked below to get an intuitive understanding of neural networks. This is required. Unit 02 Technical Article .   . Task 2: Go through the following videos/articles and answer the provided synthesis questions. Submit your answers to your intro course TA. Link to this task . Task 3: Complete either the technical project or the non-technical project. Submit your work to the intro course TA. Link to this task . ",
    "url": "/pr-preview/pr-36/megadoc/unit-02/#unit-2-the-deep-learning-basics",
    
    "relUrl": "/megadoc/unit-02/#unit-2-the-deep-learning-basics"
  },"43": {
    "doc": "Unit 02",
    "title": "Back to Basics: Neural Networks",
    "content": "Simply put, we use neural networks to make computers process information in a way similar to how the human brain processes information. Human brains use biological neural networks to process information. They send data from neuron to neuron in the form of electrical signals. A neural network attempts to replicate this processing using a computer. First, let’s look at the structure of a neural network. You may have seen an image like this before: . The input layer is where we feed in the information we want our network to process. We give it information in the form of a single column vector. The output layer gives us the probabilities corresponding with our inputs, with one node corresponding to each outcome. For example, suppose we want our neural network to identify pictures of dogs. First, we’d input a picture of a dog (more on how inputs work later!). Our output layer would have two nodes: one representing the probability that the image was a dog, and one representing the probability that it wasn’t. Note that the values in the output nodes always sum up to one! If our neural network was, say 90% sure that the inputted image had a dog, the “yes dog” output node would output 90%, and the “not dog” output node would output 10%. Finally, the hidden layer is where all the processing happens. Going back to our dog example, this is where the computer figures out whether the picture has a dog or not. It does this by identifying common features between all pictures that have dogs and distinguishing features between all pictures that don’t. This hidden layer gets developed using training data. This is input data that’s been labeled with the “right answer”—in our dog analogy, it’s a bunch of images that are labeled “dog” or “not dog.” We feed one of these images into the neural network, let it make a prediction, and then tell it the right answer. This is where the learning happens. The computer uses the right answer to “learn” from its mistakes and adjust the weights and connections between the nodes. It does this via a process called backpropagation, which we’ll learn more about in the rest of the homework. This layer is called a hidden layer because often times, humans can’t understand the math involved in these computations. Remember, we aren’t telling the computer what makes a dog different from a non-dog: it makes these connections itself using math. These connections are so intricate that we humans can’t understand them, in the same way we can’t understand the fine details of how neurons transmit information in the human brain. Like the human brain, we can control the input state, or what information is provided, and we can give feedback on the output state, or what information is spit out. Let’s look at an example. Imagine I want my computer to recognize handwritten numbers and convert them into text. How might we do that? . First of all, we need to give the computer some examples. We’re going to use the MNIST database, which contains thousands of images of handwritten digits, each one labeled with its actual number. Here’s an example (credit): . Let’s define our output layer. We want the output nodes to represent all possible outcomes. So instead of a yes-no output, like in our dog-not dog example, let’s ask the network to output the probability that each digit is represented—one node is the probability of a 0, one is the probability of a 1, and so on. This gives us 10 nodes in our output layer, each corresponding to a digit. Now let’s set up our input layer. As previously stated, the input has to be a single column vector of numbers. How do we convert these images to a vector? . We can assign each pixel in the image to a position in the vector. Our images are all 28x28 pixels, so positions 1-28 can represent the first row of pixels, positions 29-56 can represent the second row, and so on. Take a look at the image below for how this might work in a very simple 4x4 image. The numerical value for each pixel can correspond to the color of the pixel. All the pictures in our dataset are in grayscale, so each pixel will be assigned a number corresponding to how bright or dark it is—0 for totally white pixels, 1 for totally black pixels, and decimals in between based on how light or dark the pixel is. Then, we fill in the vector accordingly. The image below shows how this would work in the previous example—note that because we only have two colors, white and purple, we assign white pixels a 0 and purple pixels a 1. Now that we know how to input our images into the neural network, we can start training! The MNIST database has 60,000 designated training images. We’re going to flatten each one into a vector and feed it into the neural network. Then the neural network will give us an output back. The first several are going to be pretty bad because the computer is still figuring out the connections between different images. But eventually it’ll start to realize that a “1” is usually a long vertical line, and an “8” is usually two ellipses on top of each other. As it starts to make these connections, the network makes better and better predictions. Once we’ve exhausted our training data, and the computer has made all its connections, we can test our network. In addition to training data, the dataset has 10,000 designated testing images. Like the training data, these are also labeled: the difference is that the network doesn’t learn from them. We just use them to verify the accuracy of our network. In the rest of your homework, you’ll learn more about the mathematical aspects of neural networks. You’ll even get to build a neural network yourself! . ",
    "url": "/pr-preview/pr-36/megadoc/unit-02/#back-to-basics-neural-networks",
    
    "relUrl": "/megadoc/unit-02/#back-to-basics-neural-networks"
  },"44": {
    "doc": "Unit 02",
    "title": "Unit 2 Synthesis Questions",
    "content": "Video 1: Neural Networks and Deep Learning | Crash Course AI #3 (12 min) . Synthesis Questions . | Why was ImageNet significant to the development of neural networks? What about AlexNet? | What are some real-world applications of neural networks? What are some ethical considerations associated with them? | . Video 2: But what is a neural network? | Chapter 1, Deep learning (20 min) . Synthesis Questions . | What is a neuron (in terms of Neural Networks) and what does its “activation” represent? . | Bonus: Research and consider the correlation between a biological neuron and an artificial neuron. How are they similar/different? | . | What is a network layer? How is it connected to other network layers? | How is a picture of a digit decomposed into a network layer? | What does the final layer of a neural network represent? | What are weights? What are biases? Can you describe in English how information is passed from one layer to the next? | A neural network IS/IS NOT just a very highly parameterized function (Choose one) | What is the purpose of the sigmoid function? | . ",
    "url": "/pr-preview/pr-36/megadoc/unit-02/#unit-2-synthesis-questions",
    
    "relUrl": "/megadoc/unit-02/#unit-2-synthesis-questions"
  },"45": {
    "doc": "Unit 02",
    "title": "Unit 2 Project Specs",
    "content": "Homework Help: if you’re having trouble with the technical homework, or just want to try a slightly easier version, try following along with this video! It references the Crash Course video from the synthesis questions, so make sure you watch that first. Reach out to a TA if you have any questions! . How to make an AI read your handwriting (LAB): Crash Course AI #5 . Non-Technical Project Spec: . The non-technical project for this unit will involve some writing! Choose 3 of the prompts below and write at least 200 (meaningful!) words on each one! We will not be strictly grading you on correctness or anything like that. This is an opportunity to deeply engage with the material you have just learned about, and creatively connect it to neuroscience! . | What can we learn from neuroscience to improve the efficiency and performance of artificial neural networks? | What are the ethical implications of using insights from neuroscience to design artificial neural networks? | How are ANNs inspired by the structure and function of neurons in the brain? | What are some common applications of neural networks in real-world scenarios? Feel free to do some research on these! | How do neural networks relate to the broader field of machine learning? What are their strengths and weaknesses compared to other algorithms? | Reflecting on you learning from this unit, what is one thing you found to be most interesting about DNNs? | What is one concept from this unit that you would like to learn more about and why? | . Be sure to submit your work through google drive using the submission form! We would prefer that you upload it to your own Drive first, then use the submission form dropbox to connect that file to your submission! . Technical Project Spec: . The project for this “Basics” section will have you finish a code template through Google Colab. Please ask questions as you work through this project. Be sure to discuss with others in your group if you have one! Share your answers as you like, the goal is to learn and we’re not holding grades over your head. In this project, you will be implementing a Deep Neural Network (DNN)! . A few general helpful tips (if applicable): . | Be sure to appropriately make a copy of the Colab template before starting to save your progress! | Renaming your copy to something that contains your name is a good idea, it will make it easier for us to review your submissions. | Leave comments to cement your understanding. Link syntax to ideas. | Read up on what MNIST is. | . Now, follow the instructions on this Jupyter notebook to implement some of the things we talked about. There is an “answers” link at the bottom of the notebook that you can use if stuck. You will need to download the ‘.ipynb’ found in that directory and open it either locally or in a new colab project yourself. Ask around if you are unable to get it working! . Colab Link: Unit 2 Notebook (1 hr) . When you are finished with your code, independently verify that it works and have fun with it! If you add any additional functionality be sure to talk about it with others and give them ideas. Remember that this is all for your learning, so do your best and don’t stress! . Congratulations! You now understand the basics of Deep Neural Network structure, how they learn, and how to create one using Python! . ",
    "url": "/pr-preview/pr-36/megadoc/unit-02/#unit-2-project-specs",
    
    "relUrl": "/megadoc/unit-02/#unit-2-project-specs"
  },"46": {
    "doc": "Unit 02",
    "title": "Unit 02",
    "content": " ",
    "url": "/pr-preview/pr-36/megadoc/unit-02/",
    
    "relUrl": "/megadoc/unit-02/"
  },"47": {
    "doc": "Unit 03",
    "title": "Unit 3: Basic Neuroanatomy",
    "content": "Welcome to the first lesson studying the most powerful and intelligent computer known to date – the brain. We will begin by studying what exactly it is. This is called neuroanatomy, and luckily for us, MIT OpenCourseware has a fabulous lecture on exactly that, which we will pair with some nice quick overviews from none other than Mr. Paul Andersen. In addition, we will attempt to tie in topics from Unit 2 (Deep Learning) to get you thinking more about NeuroAI. Have a look! . Task 1: First, we will begin with Mr. Andersen’s lovely introduction to the structure of the foundation of our biological computation: the neuron! . The Neuron! . Synthesis Questions: . | Recall the main parts of a neuron and list their functions. Write 1 sentence for each. | Fill out the following sentence: An action potential travels from the direction of the __, along the __, before reaching the __. | What happens if a neuron becomes unmyelinated? | What is a synapse? What does it do? | Now that you understand the basics of a biological neuron, how is it similar/different to a neuron in a Neural Network? Feel free to review content from Unit 2 if needed. | . Bonus Video: If you are interested in the gritty details of how computation works biologically, I suggest this video as a bonus: The Action Potential (the brain is like a salty banana!) . Task 2: Next, a crash course on the large modules of the brain before we go even deeper into the amazing functions of the brain. The Brain: Structure and Function . Synthesis Questions: . | What distinguishes the forebrain, midbrain, and hindbrain? | What are several parts of the midbrain and what are their functions? | How did we discover what function(s) certain areas of the brain have? | What are the 4 lobes of the brain and their general functions? Write 2 sentences for each. | . Task 3: Watch and understand this beautiful lecture, then answer the synthesis questions provided below. MIT Neuroanatomy Lecture . Synthesis Questions: . | What are the four major parts of the brain? | Summarize the main functions of each of the four major components above, or jot down some details about each | What is a receptive field? | Describe characteristics of a cortical area. Find your favorite cortical area not described in the lecture and describe some things that make it interesting :) | . Congratulations! That was a lot of neuroscience! On to some more creative ways of learning in the project section. ",
    "url": "/pr-preview/pr-36/megadoc/unit-03/#unit-3-basic-neuroanatomy",
    
    "relUrl": "/megadoc/unit-03/#unit-3-basic-neuroanatomy"
  },"48": {
    "doc": "Unit 03",
    "title": "Project Spec:",
    "content": "There is no programming for this project. Instead, we have provided a $\\LaTeX$ template for you to fill out. | If you are unaware of what $\\LaTeX$ is, you can read about it here. | . I would recommend taking a look at Overleaf to edit/compile $\\LaTeX$ code. Simply copy the code in the template into a blank Overleaf project and type your answers into the TODO areas. Be sure to hit the “Recompile” button to see your work. GH Link: Unit 3 Template (30 min) . The questions in the template are also written below: . Unfortunately, we have neither brains nor creatures for you to dissect. However, for this project, we will be asking you to use your imagination and newfound biological and artificially-intelligible knowledge to . | Describe several advantages and disadvantages of biological computation with the brain compared to machine learning | Speculate what aspects of the architecture of the brain may cause these advantages or disadvantages, and similarly comment on aspects of machine learning’s architecture | Brainstorm some marvelous schemes for integrating advantages from both ways of computing. Draw, write, scribble etc… When you are done, do a quick google for your best ideas to see if anyone has researched or tried them already! | . Whatever you are able to conjure up, have something to show for it to demonstrate your knowledge about basic neuroanatomy! . ",
    "url": "/pr-preview/pr-36/megadoc/unit-03/#project-spec",
    
    "relUrl": "/megadoc/unit-03/#project-spec"
  },"49": {
    "doc": "Unit 03",
    "title": "Unit 03",
    "content": " ",
    "url": "/pr-preview/pr-36/megadoc/unit-03/",
    
    "relUrl": "/megadoc/unit-03/"
  },"50": {
    "doc": "Unit 04 Technical Article",
    "title": "Unit 4: Technical Article",
    "content": " ",
    "url": "/pr-preview/pr-36/megadoc/unit-04-tech-article/#unit-4-technical-article",
    
    "relUrl": "/megadoc/unit-04-tech-article/#unit-4-technical-article"
  },"51": {
    "doc": "Unit 04 Technical Article",
    "title": "Unit 04 Technical Article",
    "content": " ",
    "url": "/pr-preview/pr-36/megadoc/unit-04-tech-article/",
    
    "relUrl": "/megadoc/unit-04-tech-article/"
  },"52": {
    "doc": "Unit 04",
    "title": "Unit 4: Computer Vision",
    "content": "Hello and welcome to the Basics section of the I2 megadoc! . Task 1: Read either the literacy article “Back to Basics” or the technical article linked below to get an intuitive understanding of computer vision. This is required. Unit 04 Technical Article .   . Task 2: Go through the following videos/articles and answer the provided synthesis questions. Submit your answers to your intro course TA. Link to this task . Task 3: Complete either the technical project or the non-technical project. Submit your work to the intro course TA. Link to this task . ",
    "url": "/pr-preview/pr-36/megadoc/unit-04/#unit-4-computer-vision",
    
    "relUrl": "/megadoc/unit-04/#unit-4-computer-vision"
  },"53": {
    "doc": "Unit 04",
    "title": "Back to Basics: Computer Vision",
    "content": "In Week 2, we talked about how deep neural networks work on a very general level. Today, we’re going to talk about a new type of neural network, called a Convolutional Neural Network (CNN). These are neural networks that are specifically designed to process images. While neural networks resemble the way the human brain works, CNNs resemble the way the human vision system works. Often, a CNN is a subsection of a larger neural network: it’s like a group of layers that exists to process images really efficiently. Let’s think back to our discussion of neural networks in unit 2. Recall that we used the MNIST dataset, which contains images of handwritten numbers (here’s a picture to remind you, with credit): . Near the end of the article, we mentioned that as we kept training our neural network, the computer would begin to pick out patterns associated with each number (like ones usually being a straight vertical line, or zeroes being a circle). But how exactly does the computer figure that out? How does the neural network “realize” what a one, a zero, or any other number looks like? . This is where the convolutional layer comes in. A CNN uses its convolutional layers to identify patterns and utilize them to analyze images. A convolutional layer would pick out the features that distinguish one number from the others. Recall the structure of a general neural network. Notice that every single node in the input layer is connected to every single node in the hidden layer. Remember, every node in the input layer corresponds to a pixel in the image. Our pictures of handwritten numbers contain 784 pixels (28 x 28), which means there are 784 nodes in the input layer. This means we have a lot of connections between the input layer and the first hidden layer, and the first hidden layer and the second hidden layer, and so on. The reason the neural network is set up like this is because it assumes that information about every pixel influences every other pixel. But that’s not necessarily true! For example, in each image in the MNIST dataset, the dark pixels tend to be close to other dark pixels, and the light pixels tend to be close to other light pixels. Also, the patterns associated with a given number are not exactly the same every time. Take a look at the image below (credit) and notice how there are slight differences in the way the numbers are written (e.g. the number 7 vs. 7 with a line through it). We need the computer to recognize that these are just variations on the exact same number. CNNs account for both of these things, reducing the number of input nodes and allowing for variations in the pixels when identifying features in an image. Now we’re going to get into how CNNs actually work, using a very simple image of a handwritten number. Take a look at the image below, which shows the number 8. We’ve assigned a numerical value to each pixel, like was discussed in Unit 2. The first thing a CNN does is use filters to identify the locations of features in the image. In our example, the most important feature of an 8 is an ellipse, because an 8 is made of two ellipses stacked on top of each other. So let’s use a filter to identify any ellipses in the image. At first, our filter just contains random numbers—but through backpropagation, it starts to resemble the shape of the feature we’re looking for (an ellipse). Below is an example of what the correct filter would look like. Next, we put the filter over the image and compute the dot product of the filter and the portion of the image that it overlaps. This involves multiplying the value in the filter by the value of the pixel underneath, and adding up all the products. Take a look at the example below. Notice that the feature in the filter (the ellipse) doesn’t perfectly match up with the pixels underneath it, so our dot product ends up being 4. Then, we shift our filter over by one and do the same thing. The distance by which we move our filter is called the stride. Notice that in this next example, the feature in the filter perfectly matches with the pixels underneath, so our dot product is much larger (8). We’ll continue shifting the filter until we’ve covered the entire image (there will probably be a lot of overlap). We keep track of all these dot products in a feature map. The feature map is useful because it tells us the general locations of the feature we’re tracking. Our feature map is a 3 by 3 matrix because we apply the filter nine times overall (you can try shifting the filter and calculating the dot products yourself!). Remember, we said that when the filter perfectly matched the pixels underneath (i.e., there was an ellipse in the image), the dot product was 8. The feature map has two 8s, which tells us that there are two ellipses in the image: in the top middle of the image and in the bottom middle of the image. This fits with what we know an 8 should look like: two ellipses stacked on top of each other! . The entire process we just did, of converting an image into a feature map, is called a convolution. The image we’re using, again, is really simple: it only has one distinguishing feature, which is its ellipses. If our image has multiple features (e.g. multiple lines, angles, edges, curves, etc.), we would use a different feature map for each one, and do convolutions for each feature all at the same time! . Next, we’re going to simplify this information a little bit using a strategy called pooling. Pooling means to reduce our feature map into an even smaller matrix that contains the most important information from each “region” of the image. Our image is a little too simple to pool any further, but below is an example of how that would work (credit). Here, the entire top left corner is simplified to just the largest value, and so on for the other regions. This gives us a simplified understanding of the feature map overall. The example below uses “max pooling,” which means it takes the largest value from each region to represent the region as a whole. There are other types of pooling as well, such as “average pooling,” which takes the average of the region to represent the overall region. We repeat the convolution-pooling cycle until our feature map (or maps, if we have multiple features) is sufficiently small. Finally, we plug our resulting feature maps into a fully connected layer, which is like a regular old neural network. Before, all our features were analyzed independently in different convolutions. Here, we’re putting everything together and using all our collected information to classify our image. We do this by taking all of our small, pooled feature maps, flattening them into a column vector, and treating this column vector as the input layer to a standard neural network, which then predicts what the final image is. Take a look at the image below for an example (credit). This was a lot of information, so please reach out to a TA if you’re having trouble with these concepts or with the homework! Since this article was very abstract and conceptual, the homework is going to be much more technically focused. ",
    "url": "/pr-preview/pr-36/megadoc/unit-04/#back-to-basics-computer-vision",
    
    "relUrl": "/megadoc/unit-04/#back-to-basics-computer-vision"
  },"54": {
    "doc": "Unit 04",
    "title": "Unit 4 Synthesis Questions",
    "content": "Video 1: How Convolutional Neural Networks work (12 min) . Note: Watch from 13:54 onward to answer the questions below. Before that is mainly review from this article (but you may find it useful to skim through, as it covers helpful math concepts!). Synthesis Questions . | How is backpropagation used in CNNs, and how does it differ from backpropagation in standard neural networks? | What outcomes can a designer achieve from adjusting the hyperparameters or architecture of a CNN? | Can you think of an example of when we can use a CNN on non-image data? | . Video 2: But what is a convolution? (14 min) . Note: Watch up to 13:42 in this video; the rest is beyond the scope of this course. Synthesis Questions . | What is the name for the smaller grid that convolves over a larger image? . | Hint: Starts with a “k” | . | What are some examples of what you can do to images if you convolve them with special matrices? | How does Gaussian blur “work”? | What is the name for the actual operation that occurs when the smaller grid is overlaid on the larger one? . | When each element of the corresponding pixels are multiplied then summed. | . | Give an example of a 3x3 matrix that would not do anything to the image it convolves over. Why does it not impact the image? . | This is also known as the “do-nothing” matrix | . | . ",
    "url": "/pr-preview/pr-36/megadoc/unit-04/#unit-4-synthesis-questions",
    
    "relUrl": "/megadoc/unit-04/#unit-4-synthesis-questions"
  },"55": {
    "doc": "Unit 04",
    "title": "Unit 4 Project Specs",
    "content": "Non-Technical Project Spec: . The non-technical project for this unit will involve some writing! Choose 3 of the prompts below and write at least 200 (meaningful!) words on each one! We will not be strictly grading you on correctness or anything like that. This is an opportunity to deeply engage with the material you have just learned about, and creatively connect it to neuroscience! . | How are CNNs inspired by the human visual system? | What are some similarities and differences between CNNs and the human visual system? | How is the pooling layer in CNNs related to the brain’s visual processing? | What ways does the convolutional layer in CNNs resemble the receptive field in the visual system? | Reflecting on you have learned from this unit, what is one thing you found to be most interesting? | What is one concept from this unit that you would like to learn more about and why? | . Be sure to submit your work through google drive using the submission form! We would prefer that you upload it to your own Drive first, then use the submission form dropbox to connect that file to your submission! . Technical Project Spec: . The project for this “Computer Vision” section will be following the tutorial/Jupyter Notebook below. Please ask questions in the discord as you work through this project. Be sure to discuss with others in your group! . A few general helpful tips (if applicable): . | Be sure to appropriately make a copy of the Colab template before starting to save your progress! | Renaming your copy to something that contains your name is a good idea, it will make it easier for us to review your submissions. | Leave comments to cement your understanding. Link syntax to ideas. | Read up on what CIFAR-10 is. | . Now, follow the instructions on this Jupyter notebook to implement some of the things we talked about. There is an “answers” link at the bottom of the notebook that you can use if stuck. You will need to download the ‘.ipynb’ found in that directory and open it either locally or in a new colab project yourself. Ask around if you are unable to get it working! . Colab Link: Unit 4 Notebook (1 hr) . When you are finished with your code, independently verify that it works and have fun with it! If you add any additional functionality be sure to talk about it with others and give them ideas. Remember that this is all for your learning, so do your best and don’t stress! . Congratulations! You now understand the basics of Convolutional Neural networks! . ",
    "url": "/pr-preview/pr-36/megadoc/unit-04/#unit-4-project-specs",
    
    "relUrl": "/megadoc/unit-04/#unit-4-project-specs"
  },"56": {
    "doc": "Unit 04",
    "title": "Unit 04",
    "content": " ",
    "url": "/pr-preview/pr-36/megadoc/unit-04/",
    
    "relUrl": "/megadoc/unit-04/"
  },"57": {
    "doc": "Unit 05",
    "title": "Unit 5: Intro to the Visual System",
    "content": "Welcome to the visual system. Before we dive into how computer scientists have hacked together mathematical filters and matrix multiplication to process visual information and extract meaningful output, we will take a hard look at how your eyes and neurons process a continuous bombardment of photons. First, some vocab. Dorsal: Upper or back side of something (like a dorsal fin on an orca!) . Ventral: Underside or underbelly of something . Receptive Field: An input that produces the biggest response in some area or neuron is said to be its receptive field . Task 1: Watch the following videos and answer the questions! You know the drill. The first one will teach us about the physiology of processing light, the complex first layer of our own biological neural network. Vision: Crash Course Anatomy &amp; Physiology # 18 . Synthesis Questions: . | Where in the brain do signals from the retina go before reaching the visual cortex? | What are some differences between rods and cones? | Describe the phenomena of retinal neurons that \"get tired\". Do you think there are analogous processes in deep learning or convolutional neural networks? | . The next video will describe the path of information flow through the visual cortex and some core properties of the structure of this process. Perception: 3.2 Primary Visual Cortex . Synthesis Questions: . | What wavelengths of light can humans detect? Why might we only be able to detect such a narrow band of light wavelengths? What would be an advantage and downside of processing more? | What is V1 in the visual cortex? What are those cells most sensitive to? | What is the fovea best at detecting? | Describe the retinotopic nature of the visual cortex (7:58) in your own words. Hypothesize whether convolutional neural networks might be organized as \"retinotopic\". | Describe cortical magnification and the causes of the trade-off between acuity and sensitivity. What are several reasons we can't see details from extremely far away, as for example, hawks can? | Brains are constrained by space, which as we have seen with vision, drives trade-offs in our processing. Do neural networks have analogous constraints? What are the effects of this? | Brains are constrained by space, which as we have seen with vision, drives trade-offs in our processing. Do neural networks have analogous constraints? What are the effects of this? | . This final video gives a swift overview of many functional modules of visual processing. This is a great time to start thinking about how all this vision processing compares to our methods of processing information with neural networks! We will learn even more in the next Unit on convolutional neural networks too :) . Perception: 3.3 Functional Areas, Pathways, and Modules . Synthesis Questions: . | Describe at least 5 functional parts of the visual system | Explain the hierarchical model of the visual system | What is the \"what\" stream? What does it do? | What is the \"where\" stream? What does it do? | What is a region that processes faces? What inputs does it receive? What other regions is it near? | . This last video is optional but it’s highly recommended that you watch it. This video does a good job at synthesizing all 3 videos and goes more in-depth into certain mechanisms: Visual Processing and the Visual Cortex . Here’s some questions to think about as you watch the video: . | What direction does light go versus information in the retina? | What cells are in the retina? | How do rod photoreceptors adapt to light and dark? | How does each hemisphere receive information from the contralateral visual field? | What is the blind spot? | . ",
    "url": "/pr-preview/pr-36/megadoc/unit-05/#unit-5-intro-to-the-visual-system",
    
    "relUrl": "/megadoc/unit-05/#unit-5-intro-to-the-visual-system"
  },"58": {
    "doc": "Unit 05",
    "title": "Project Spec:",
    "content": "There is no technical project for this unit. We have provided a scenario and instructions below: . Imagine you got a little too into neural networks and decided to replace your eyes with convolutional neural networks. You may use any sensors, hardware, brain computer interfaces, fungi, wires, Von Neumann computing, neuromorphic computing, or robots that you like (that seem vaguely feasible). How would you replace the algorithms run by the visual cortex with algorithms like those of convolution neural networks? Be creative and let your imagination run free! . Draw your system in detail and write a short paragraph on the following: . | Why did you make the design decisions you made? | What would be the advantages of your system? | What would be the disadvantages? | What hardware did you use to implement this? In your opinion, is it possible to use the existing biological nervous system to run computation algorithms like CNNs? Why? | . Be sure to submit your work through google drive using the submission form! We would prefer that you upload it to your own Drive first, then use the submission form dropbox to connect that file to your submission! You can submit a pdf or a simple Google Doc, whichever you prefer! . ",
    "url": "/pr-preview/pr-36/megadoc/unit-05/#project-spec",
    
    "relUrl": "/megadoc/unit-05/#project-spec"
  },"59": {
    "doc": "Unit 05",
    "title": "Unit 05",
    "content": " ",
    "url": "/pr-preview/pr-36/megadoc/unit-05/",
    
    "relUrl": "/megadoc/unit-05/"
  },"60": {
    "doc": "Unit 06",
    "title": "Unit 6: Reinforcement Learning",
    "content": "Hello and welcome to the Basics section of the I2 megadoc! . Task 1: Read either the literacy article “Back to Basics” or the technical article linked below to get an intuitive understanding of reinforcement learning. This is required. Unit 06 Technical Article .   . Task 2: Go through the following videos/articles and answer the provided synthesis questions. Submit your answers to your intro course TA. Link to this task . Task 3: Complete either the technical project or the non-technical project. Submit your work to the intro course TA. Link to this task . ",
    "url": "/pr-preview/pr-36/megadoc/unit-06/#unit-6-reinforcement-learning",
    
    "relUrl": "/megadoc/unit-06/#unit-6-reinforcement-learning"
  },"61": {
    "doc": "Unit 06",
    "title": "Back to Basics: Reinforcement Learning",
    "content": "Welcome to one of the most important units in this course—and one of the most challenging! Like all our articles, the goal of this article is to give you an intuitive understanding of reinforcement learning so that you can recognize it in daily life and apply it to technical projects. Reinforcement learning is the study of how a free object, or agent, moves around and accomplishes tasks in an environment, either real or simulated. The very general idea involves rewarding the object for desirable actions (i.e. reinforcing that behavior) and punishing it for undesirable actions. For example, suppose we’re teaching a computer how to play chess against a human. In this case, the agent would be the computer and the environment would be the chess game (i.e. the opponent, board, and pieces). The computer starts by taking an action–in other words, it does something. In this case, say the computer captures one of the human opponent’s pawns. Now the environment (the chess game) looks different from before the computer took its action; the computer has changed the state of the environment. The state of the environment is favorable—we’re glad the computer took this action, and we want to reinforce it (we want it to keep taking actions like this). So we give the computer a reward that’s proportional to how desirable the action was. In this case, the reward is pretty moderate—capturing a pawn is good, but it’s not one of the best moves the computer can make. If the computer had captured the opponent’s queen, for example, we’d give it more of a reward because that’s a more desirable action. Suppose the computer takes a different action: instead of capturing a pawn, it knocks over the entire board. Again, our environment is in a new state as a result of this action. Unfortunately, this new state is very bad for the computer because there’s no way it can win the game now. So we want to punish this action and make sure the computer avoids it in the future. We can do this by giving it a negative reward to indicate that it’s an undesirable action. The computer decides what steps to take using something called a policy. A computer uses a policy to decide what its next step should be. For example, maybe the computer’s policy is to maximize its rewards. Then, every single action it takes is the action that produces the highest reward. This helps it avoid undesirable actions, like knocking over the board, because they have such low rewards. This isn’t always the best policy, though. We said earlier that capturing the opponent’s queen is a very high-reward action. Suppose the computer is in a position where it can capture its opponent’s queen, but in doing so leaves its king vulnerable. In this case, maybe taking the highest-reward action isn’t the best way to go. We would have to use a different policy in our decision-making. Deep reinforcement learning combines deep learning and reinforcement learning. Its goal is to get the computer to learn to do something, and it teaches the computer using the principles of RL. Take a look at the short video below, which tries to teach a robot to walk using deep reinforcement learning (don’t worry, you’ll have fewer Synthesis Questions to make up for the extra video!). AI Learns to Walk (deep reinforcement learning) (9 min) . Notice that the robot wasn’t given any directions. It was given a target, and every action it took was rewarded or punished, but it ultimately had to learn the correct sequence of actions that would allow it to walk. If we apply this to our chess example, the target might be to win the game by capturing the opponent’s king. We won’t tell the computer how to do that, but every time it takes an action we can reward or punish it. That way, it starts to learn the correct sequence of actions that it needs to take in order to win the game. Also, like in the video, we can put our chess computer in different environments to force it to learn new actions. For example, we can start it out in an environment where its opponent is a three-year-old. As the computer gets better, we can put it in new environments with more and more advanced opponents to force it to learn new skills, in the same way the robot in the video became better at walking by crossing more and more difficult terrain. ",
    "url": "/pr-preview/pr-36/megadoc/unit-06/#back-to-basics-reinforcement-learning",
    
    "relUrl": "/megadoc/unit-06/#back-to-basics-reinforcement-learning"
  },"62": {
    "doc": "Unit 06",
    "title": "Unit 6 Synthesis Questions",
    "content": "Video 1: Reinforcement Learning: Crash Course AI #9 (12 min) . Synthesis Questions . | When does it make sense to use reinforcement learning vs. other methods of machine learning to accomplish a task? | How do the agent, action, and environment interact in reinforcement learning? | Give an example of two different policies in a reinforcement learning environment that’s NOT the cookie-jar example from the video (but you can use the chess game, the walking robot, or something you come up with yourself!). | . Video 2: Reinforcement Learning from scratch (8 min) . Synthesis Questions . | What is the purpose of a sigmoid function, and what does its value tell us? What about an error function? | Describe the idea of gradient descent and how we use it in reinforcement learning. | . ",
    "url": "/pr-preview/pr-36/megadoc/unit-06/#unit-6-synthesis-questions",
    
    "relUrl": "/megadoc/unit-06/#unit-6-synthesis-questions"
  },"63": {
    "doc": "Unit 06",
    "title": "Unit 6 Project Specs",
    "content": "Non-Technical Project Spec: . The non-technical project for this unit will involve some writing! Choose 3 of the prompts below and write at least 200 (meaningful!) words on each one! We will not be strictly grading you on correctness or anything like that. This is an opportunity to deeply engage with the material you have just learned about, and creatively connect it to neuroscience! . | Can you provide examples of experimental evidence linking reinforcement learning algorithms to observed synaptic changes in the brain? | How do human neural systems encode reward signals and how does this relate to the concept of rewards in reinforcement learning models? | What ethical considerations should be taken into account when developing interventions based on neuroscientific findings, and how can accountability be established for the potential impacts of such interventions? | Reflecting on you have learned from this unit, what is one thing you found to be most interesting? | What is one concept from this unit that you would like to learn more about and why? | . Be sure to submit your work through google drive using the submission form! We would prefer that you upload it to your own Drive first, then use the submission form dropbox to connect that file to your submission! . Technical Project Spec: . The project for this “Reinforcement Learning” section will be following the tutorial/Jupyter Notebook below. Please ask questions in the discord as you work through this project. Be sure to discuss with others in your group! . A few general helpful tips (if applicable): . | Be sure to appropriately make a copy of the Colab template before starting to save your progress! | Renaming your copy to something that contains your name is a good idea, it will make it easier for us to review your submissions. | Type most of the code out yourself instead of just copying from the tutorial. | Leave comments to cement your understanding. Link syntax to ideas. | . Now, follow the instructions on this Jupyter notebook to implement some of the things we talked about. There is an “answers” link at the bottom of the notebook that you can use if stuck. You will need to download the ‘.ipynb’ found in that directory and open it either locally or in a new colab project yourself. Ask around if you are unable to get it working! . Colab Link: Unit 6 Notebook (1.5 hr) . When you are finished with your code, independently verify that it works and have fun with it! If you add any additional functionality be sure to talk about it with others and give them ideas. Remember that this is all for your learning, so do your best and don’t stress! . Congratulations! You now understand the (incredibly basic) basics of Deep RL! . ",
    "url": "/pr-preview/pr-36/megadoc/unit-06/#unit-6-project-specs",
    
    "relUrl": "/megadoc/unit-06/#unit-6-project-specs"
  },"64": {
    "doc": "Unit 06",
    "title": "Unit 06",
    "content": " ",
    "url": "/pr-preview/pr-36/megadoc/unit-06/",
    
    "relUrl": "/megadoc/unit-06/"
  },"65": {
    "doc": "Unit 07",
    "title": "Unit 7: AI Ethics",
    "content": " ",
    "url": "/pr-preview/pr-36/megadoc/unit-07/#unit-7-ai-ethics",
    
    "relUrl": "/megadoc/unit-07/#unit-7-ai-ethics"
  },"66": {
    "doc": "Unit 07",
    "title": "AI Ethics Course Section in I2",
    "content": "Welcome to the AI Ethics section of the I2 course! In this pivotal module, we’ll journey through the ethical maze of AI, grounding our understanding in real-world applications and dilemmas. ",
    "url": "/pr-preview/pr-36/megadoc/unit-07/#ai-ethics-course-section-in-i2",
    
    "relUrl": "/megadoc/unit-07/#ai-ethics-course-section-in-i2"
  },"67": {
    "doc": "Unit 07",
    "title": "Part 1: Understanding AI Ethics – Principles and Foundations",
    "content": "Introduction to AI Ethics . Task 1: Engage with the materials below and reflect on the synthesis questions. | Video: Introduction to AI Ethics (7 min) | Article: Principles of AI Ethics (3 min) | . Synthesis Questions: . | How have the core principles of AI ethics evolved over time? | In what ways does AI ethics differ from ethics in traditional technologies? | Why is ethics crucial in the realm of AI more than ever? | Relate a historical event or invention to the current ethical concerns in AI. | How can understanding the past inform our future ethical decisions in AI? | . ",
    "url": "/pr-preview/pr-36/megadoc/unit-07/#part-1-understanding-ai-ethics--principles-and-foundations",
    
    "relUrl": "/megadoc/unit-07/#part-1-understanding-ai-ethics--principles-and-foundations"
  },"68": {
    "doc": "Unit 07",
    "title": "Part 2: Key Ethical Issues in AI - From Bias to Accountability",
    "content": "Bias and Fairness in AI . Task 2: Dive into these resources and ponder the synthesis questions. | Video: Bias Explained (3 min) | . Synthesis Questions: . | How has bias in AI affected real-world decision-making in sectors like finance or healthcare? | In what ways might biased data skew the outcomes of an AI system? | Describe a notable case where AI bias had real-world implications. | How can fairness be quantified and ensured in AI? | Can absolute fairness be achieved, or is it a continuum? | . AI, Privacy, and Security . Task 3: Engage with the videos and answer the synthesis questions. | Video: Data Privacy and AI (7 min) | Article: Social Impact of AI and Data Privacy Issues(8 min) | . Synthesis Questions: . | How has AI impacted personal privacy in the age of social media? | Contrast traditional data breaches with the potential dangers posed by AI-driven breaches. | What challenges do global privacy regulations pose to AI developers? | How can individuals protect their data in AI-driven applications? | Relate the Cambridge Analytica scandal to the importance of privacy in AI. | . ",
    "url": "/pr-preview/pr-36/megadoc/unit-07/#part-2-key-ethical-issues-in-ai---from-bias-to-accountability",
    
    "relUrl": "/megadoc/unit-07/#part-2-key-ethical-issues-in-ai---from-bias-to-accountability"
  },"69": {
    "doc": "Unit 07",
    "title": "Part 3: Ethical Dilemmas and Real-World Applications",
    "content": "AI Ethics Dilemma Case Study . Task 4: Delve into these materials and reflect deeply on the synthesis questions. | Video: Self-driving Cars: An Ethical Quandary (7 min) | Article: Case Study: Ethical Pitfalls in Healthcare AI (8 min) | . Synthesis Questions: . | How do self-driving cars display the ethical challenges posed by AI? | Do you think an increase in self driving vehicles would be beneficial or not? | Relate the lessons from a real-world healthcare AI failure to broader AI ethics. | How can companies ensure they’re ethically responsible while innovating? | Do the pros outweigh the cons when it comes to autonomous robots in healthcare? | . ",
    "url": "/pr-preview/pr-36/megadoc/unit-07/#part-3-ethical-dilemmas-and-real-world-applications",
    
    "relUrl": "/megadoc/unit-07/#part-3-ethical-dilemmas-and-real-world-applications"
  },"70": {
    "doc": "Unit 07",
    "title": "Part 4: Special Topics in AI Ethics",
    "content": "Ethics in AI Research and Application . Task 5: Explore these articles and mull over the synthesis questions. | Video: The Ethical Boundaries of AI in Warfare (7 min) | Article: The Dual-Use Dilemma in AI Research (7 min - Only Read First Half) | . Synthesis Questions: . | How does the potential use of AI in warfare raise ethical red flags? | Where should the line be drawn between research and application in contentious AI areas? | Describe a situation where AI research might unintentionally harm society. | What responsibilities do AI researchers have beyond their immediate work? | Reflect on an AI advancement that can be both beneficial and harmful. | . Global Perspectives on AI Ethics . Task 6: Dive into this rich content and think critically about the synthesis questions. | Video: Cultural Nuances in AI Ethics (6 min) | . Synthesis Questions: . | How might Western and Eastern perspectives on AI ethics differ? | Describe a cultural or societal factor that could influence AI ethics in a particular region. | How can companies navigate global ethical standards when deploying AI? | Why is it essential for AI ethics to be globally inclusive? | Reflect on the challenges of implementing a universal ethical framework for AI. | . ",
    "url": "/pr-preview/pr-36/megadoc/unit-07/#part-4-special-topics-in-ai-ethics",
    
    "relUrl": "/megadoc/unit-07/#part-4-special-topics-in-ai-ethics"
  },"71": {
    "doc": "Unit 07",
    "title": "Final Project: Real-world AI Ethics Analysis and Proposal",
    "content": "Project Spec: Choose an existing AI system or technology, dissect its ethical aspects, unearth potential pitfalls, devise actionable remedies, and craft an impactful presentation. Slide 1 - Title Slide . | Title: Your Choice | Your name | Date | . Slide 2 - I . | Introduction | Brief background on the AI system or technology chosen | Why analyzing ethics is important for this system | Overview of the ethical analysis approach | . Slide 3 - Ethical Analysis . | Details on potential pitfalls, biases, fairness issues | Real-world examples and implications | Frame as risks that need to be addressed | . Slide 4 - Proposed Solutions . | Outline ideas and recommendations to improve ethics | Explain how proposals directly address risks Emphasize feasibility and impact | End with call to action | . The presentation should focus on thorough analysis of the real-world ethics issues with the chosen AI system and actionable, impactful proposals to address them. Be sure to submit your work through google drive using the submission form! We would prefer that you upload it to your own Drive first, then use the submission form dropbox to connect that file to your submission! . ",
    "url": "/pr-preview/pr-36/megadoc/unit-07/#final-project-real-world-ai-ethics-analysis-and-proposal",
    
    "relUrl": "/megadoc/unit-07/#final-project-real-world-ai-ethics-analysis-and-proposal"
  },"72": {
    "doc": "Unit 07",
    "title": "Unit 07",
    "content": " ",
    "url": "/pr-preview/pr-36/megadoc/unit-07/",
    
    "relUrl": "/megadoc/unit-07/"
  },"73": {
    "doc": "Unit 08",
    "title": "Unit 8: Language Modeling",
    "content": " ",
    "url": "/pr-preview/pr-36/megadoc/unit-08/#unit-8-language-modeling",
    
    "relUrl": "/megadoc/unit-08/#unit-8-language-modeling"
  },"74": {
    "doc": "Unit 08",
    "title": "Intro",
    "content": "Language modeling has become ubiquitous in our society, used in chatbots, content moderation, translation, and more. In this unit, we will explore natural language processing (NLP), discussing common model architectures, their applications, and training methods. ",
    "url": "/pr-preview/pr-36/megadoc/unit-08/#intro",
    
    "relUrl": "/megadoc/unit-08/#intro"
  },"75": {
    "doc": "Unit 08",
    "title": "NLP Tasks",
    "content": "NLP encompasses various tasks, each with specific architectures and applications: . | Text Generation: Models like ChatGPT, autocomplete systems. | Sequence-to-Sequence: Language translation models. | Sequence-to-Vector: Hate speech detection (text classification). | Word2Vec: Mapping words to nearby vectors. | Word Embeddings: Identifying similarities between words. | . These tasks are crucial in NLP, employing different algorithms for solutions. Our focus will be on text generation and word embeddings, but we will also touch on other tasks. ",
    "url": "/pr-preview/pr-36/megadoc/unit-08/#nlp-tasks",
    
    "relUrl": "/megadoc/unit-08/#nlp-tasks"
  },"76": {
    "doc": "Unit 08",
    "title": "Text Generation",
    "content": "Text generation involves creating new text by framing it as a classification problem: predicting the next word in a given text sequence. Example: . | pass 1: . | model input: the quick brown fox | model prediction: jumps | . | pass 2: . | model input: the quick brown fox jumps | model prediction: over | . | pass 3: . | model input: the quick brown fox jumps over | model prediction: the | . | … | . By appending the prediction to the given sequence, we get a new base sequence for predicting the next token. This iterative process allows generating arbitrary-length sequences. Such models are autoregressive, using previous outputs as inputs for subsequent predictions. This means the model can generate as much text as desired, limited only by computational resources and the coherence of the content. Self-supervised learning in NLP utilizes the natural structure of language, where examples for learning are implicit in the text itself. In this approach, a sentence or a passage serves as both the input and the label, with certain parts masked or predicted by the model. For instance, in the sentence “The cat sat on the ___”, the blank can be used as a prediction target, teaching the model the context and structure of language. This method enables models to learn from large amounts of unlabeled text, grasping grammar, syntax, and context naturally. ",
    "url": "/pr-preview/pr-36/megadoc/unit-08/#text-generation",
    
    "relUrl": "/megadoc/unit-08/#text-generation"
  },"77": {
    "doc": "Unit 08",
    "title": "Word Embeddings and Tokenization",
    "content": "Tokenization and Embeddings are vital in NLP as models inherently process numerical data. Tokenization converts text into manageable units (like words or characters), which are then transformed into numbers. This allows models to interpret and process language data. Embeddings take this further by converting these tokens into vectors of real numbers, capturing semantic meanings. For example, in word embeddings, words with similar meanings are closer in the vector space, enabling the model to understand relationships and nuances in language. These techniques are crucial for handling the complexity and variability of human language in computational models. Please read this article on word embeddings and answer the following questions: . Synthesis questions: . | What is a word embedding? How long are they usually? | How does training a network to recognize the validity of 5-grams result in a Word-to-Vector \"map\"? | Pretend you are a word embedder. Give examples (2-3 for each) of words in the same family as: . | King | Button | Pain | Water Bottle | . | What is the explanation given for the emergence of the \"male-female difference vector\"? | What is pre training/transfer learning/multi-task learning? | . ",
    "url": "/pr-preview/pr-36/megadoc/unit-08/#word-embeddings-and-tokenization",
    
    "relUrl": "/megadoc/unit-08/#word-embeddings-and-tokenization"
  },"78": {
    "doc": "Unit 08",
    "title": "Feed-Forward Network",
    "content": "A simple model for text generation could be a feed-forward network. As feed-forward networks always need a constant input size, it uses a specified context length to determine how many previous words to consider when predicting the next one. When the input is shorter than the context length, we use padding tokens (&lt;PAD&gt;) to fill the gap. Example: . Context length = 4 . | “the quick brown fox” . | Input: the, quick, brown, fox | Output: jumps | . | “an apple a day keeps the doctor” . | Input: day, keeps, the, doctor | Output: away | . | “ignorance is” . | Input: &lt;PAD&gt;, &lt;PAD&gt;, ignorance, is | Output: bliss | . | . However, feed-forward networks have limitations: . | Fixed context length: Cannot consider words beyond a certain range. | Fixed input size: Requires padding for shorter inputs. | Difficulty in capturing word relationships: Not optimized for understanding the connections between words. | . ",
    "url": "/pr-preview/pr-36/megadoc/unit-08/#feed-forward-network",
    
    "relUrl": "/megadoc/unit-08/#feed-forward-network"
  },"79": {
    "doc": "Unit 08",
    "title": "Recurrent Neural Networks (RNNs)",
    "content": "RNNs maintain an internal hidden state updated at each token. This hidden state represents all that the model has seen so far. RNNs solve many of the problems experienced by feed-forward networks by allowing variable-length sequences and “sharing” parameters, improving efficiency. They operate with the following weights and biases: . | $W_{xh}$: Converts a token to the hidden state. | $W_{hh}$: Converts a previous hidden state to the next hidden state. | $b_h$: Bias for moving to the next hidden state. | $W_{ho}$: Predicts the next token from the current hidden state. | $b_o$: Bias for the output prediction. | . At each time step (this means for each token) the RNN does two things: . | Update the internal hidden state from $H_{t-1}$ to $H_t$ . | This is done using the formula: $H_t = \\text{tanh}(X_tW_{xh} + H_{t-1}W_{hh} + b_h)$ | . | Predict the output token at time $T$ . | This is done using: $O_t = H_tW_{ho} + b_o$ | If the task for the RNN is not text generation, this can be omitted | . | . There always needs to be a preceding hidden state, so before any token is processed the hidden state is initialized (often to zero). Example: . Let’s run the RNN on a demo sentence, i, love . | Initialize the hidden state to zeros $H_{-1} = 0$ | Repeatedly update the hidden state and generate next-token probabilities . | $t=0$, &lt;START&gt; (we need a special start token to tell the model to begin) . | Update hidden state: $H_0 = \\text{tanh}(X_\\text{&lt;START&gt;}W_{xh} + H_{-1}W_{hh} + b_h)$ | Generate next-token probabilities (target is i): $O_1 = H_0W_{ho} + b_o$ | . | $t=1$, i . | Update hidden state: $H_1 = \\text{tanh}(X_\\text{love}W_{xh} + H_0W_{hh} + b_h)$ | Generate next-token probabilities (target is love): $O_2 = H_1W_{ho} + b_o$ | . | $t=2$, love . | Update hidden state: $H_2 = \\text{tanh}(X_\\text{love}W_{xh} + H_1W_{hh} + b_h)$ | Generate next-token probabilities (unknown target!): $O_3 = H_2W_{ho} + b_o$ | If we want to continue generating, predict next word $X_3$ from $O_2$ | . | $t=3$, $X_3$ (autoregressive - we’re inputting our previous outputs!) . | Update hidden state: $H_3 = \\text{tanh}(X_3W_{xh} + H_3W_{hh} + b_h)$ | Generate next-token probabilities: $O_4 = H_3W_{ho} + b_o$ | . | … | . | . Advantages of RNNs: . | Efficient parameter sharing across time steps. | Handling variable sequence lengths without padding. | Capturing dependencies over time through the internal hidden state. | Enhanced ability to model sequential data, reflecting the natural flow of language. | . Disadvantages of RNNs: . | Tendency to forget early tokens due to continual updates of the hidden state. | Unstable gradients, leading to training challenges. | Difficulty in parallel processing, impacting training efficiency. | . Please read (or skim) the following article on RNNs and answer the synthesis questions: . Synthesis questions: . | What happens to the memory vector as we move through time? | What is the memory vector initialized to? | Why might unstable gradients occur? | . ",
    "url": "/pr-preview/pr-36/megadoc/unit-08/#recurrent-neural-networks-rnns",
    
    "relUrl": "/megadoc/unit-08/#recurrent-neural-networks-rnns"
  },"80": {
    "doc": "Unit 08",
    "title": "Transformers",
    "content": "Transformers represent the cutting-edge in NLP, known for their self-attention mechanisms and scalability. Unlike previous architectures, Transformers do not process text sequentially. Instead, they use self-attention to weigh the importance of each token in the context of others, regardless of their position. This allows for a more nuanced understanding of text, capturing long-range dependencies effectively. Their architecture enables parallel processing of tokens, significantly enhancing training speed. Advantages: . | Excellent at capturing relationships between tokens, crucial for complex language understanding. | Highly scalable and parallelizable, allowing for efficient processing of large datasets. | . Disadvantages: . | Require significant computational resources, making them expensive to train. | Complex models that are often less interpretable, making it hard to understand decision-making processes. | . Take a look at some (or all) of the following resources for how transformer/GPT models work. You might need to find external resources as well: . | GPT in 60 lines of NumPy | Let’s build GPT: from scratch, in code, spelled out. | The Annotated Transformer | An Intuitive Explanation of GPT Models, written by Carter Swartout of I2 | . Please answer the following synthesis questions: . Synthesis Questions: . | What do the probabilities that GPT outputs represent, and what is greedy decoding? | Describe masked self-attention in your own words (not including the vector math) | How does self-attention allow tokens to have relationships with each other? | What are the big blocks that make up the GPT architecture? | Why are positional encodings necessary? | . ",
    "url": "/pr-preview/pr-36/megadoc/unit-08/#transformers",
    
    "relUrl": "/megadoc/unit-08/#transformers"
  },"81": {
    "doc": "Unit 08",
    "title": "Technical Project Spec:",
    "content": "The project for this “Language Modeling” section will be following the tutorial/Jupyter Notebook below. Please ask questions in the discord as you work through this project. Be sure to discuss with others in your group! . A few general helpful tips (if applicable): . | Be sure to appropriately make a copy of the Colab template before starting to save your progress! | Renaming your copy to something that contains your name is a good idea, it will make it easier for us to review your submissions. | Type most of the code out yourself instead of just copying from the tutorial. | Leave comments to cement your understanding. Link syntax to ideas. | . Now, follow the instructions on this Jupyter notebook to implement some of the things we talked about. There is an “answers” link at the bottom of the notebook that you can use if stuck. You will need to download the ‘.ipynb’ found in that directory and open it either locally or in a new colab project yourself. Ask around if you are unable to get it working! . There are 2 parts (.ipynb files) to this unit. Try to finish both. This technical project is likely to be harder than anything you have done in this course before, so be patient with it and reach out if you need support! . Colab Link: Unit 8 Notebook Part 1 (1 hr) . Now navigate to the application portion of this project (Part 2 below), where you are given a dataset and asked to train an LLM of your choice to emulate Shakespeare! Be sure to reference your Unit 8 Notebook Part 1 to figure out how to do this. Colab Link: Unit 8 Notebook Part 2 (1 hr) . When you are finished with your code, independently verify that it works and have fun with it! If you add any additional functionality be sure to talk about it with others and give them ideas. Congratulations! You now understand the basics of Language Modeling! . ",
    "url": "/pr-preview/pr-36/megadoc/unit-08/#technical-project-spec",
    
    "relUrl": "/megadoc/unit-08/#technical-project-spec"
  },"82": {
    "doc": "Unit 08",
    "title": "Non-Technical Project Spec:",
    "content": "The non-technical project for this unit will involve some writing! Choose 3 of the prompts below and write at least 200 (meaningful!) words on each one! We will not be strictly grading you on correctness or anything like that. This is an opportunity to deeply engage with the material you have just learned about, and creatively connect it to neuroscience! . | What ethical considerations arise when developing language models that are inspired by neural processes involved in language? | To what extent do models used in language processing reflect the actual neural networks involved with language tasks in the brain? | How can insights from neuroscience be leveraged to enhance the design and development of language models? | Reflecting on you learning from this unit, what is the one thing you found to be most interesting? | What is one concept from this unit that you would like to learn more about and why? | . Be sure to submit your work through google drive using the submission form! We would prefer that you upload it to your own Drive first, then use the submission form dropbox to connect that file to your submission! . ",
    "url": "/pr-preview/pr-36/megadoc/unit-08/#non-technical-project-spec",
    
    "relUrl": "/megadoc/unit-08/#non-technical-project-spec"
  },"83": {
    "doc": "Unit 08",
    "title": "Unit 08",
    "content": " ",
    "url": "/pr-preview/pr-36/megadoc/unit-08/",
    
    "relUrl": "/megadoc/unit-08/"
  },"84": {
    "doc": "Unit 09",
    "title": "Unit 9: Fairness and Theory",
    "content": "Machine learning models are interesting, but they have substantive effects on the world they are deployed in. How can we make these models fairer, safer, less biased, and/or more responsible? Is this even rigorously possible? (Some researchers suggest not!) What is the source of bias? (“Garbage In, Garbage Out” is a stunted answer, and maybe even misleading.) These are all questions which are intimately linked with deep learning theory, a growing field which attempts to explain how neural networks work rather than attempting to advance the SOTA in performance or a similar task. Because of the close relationship between theory and fairness research, we will be exploring them together. After going through this unit, you will be able to reason about deep learning at a very abstract level (a powerful tool for research and experimentation); identify the core theoretical essence of various models and approaches; think critically about what the concepts of ‘bias’, ‘fairness’, ‘robustness’, ‘responsibility’, and ‘fairness’ mean and how we might build models which better embody these values. It is recommended to read the listed papers in order, and to at least skim each one. Theory . | Universal Approximation Theorem. While it’s not necessary to completely understand the proof, make sure you understand at least what the theorem is stating and why it is an interesting result. | Read this introductory article written by Andre (the author of this unit) on the UAT, then this Twitter thread of Yann Lecun blasting it. Then, read Lecun et al.’s paper Learning in High Dimension Always Amounts to Extrapolation. Lastly, read this document of the debate on Twitter. Now think about what your position in this debate is. What is interpolation? What is extrapolation? Do neural networks extrapolate? Is this a meaningful concept at all, and if not, what might be a more meaningful one? Keep thinking about these questions throughout the theory section. | Deep Double Descent: Where Bigger Models and More Data Hurt. A ‘classic’ empirical finding which points towards a weirdness of deep learning models as opposed to less parametrized, classical models. | Are Deep Neural Networks Dramatically Overfitted? A great technical blog post giving more theory on the question of overfitting. | Understanding Deep Learning Requires Rethinking Generalization. Important empirical results and speculative theoretical work. | Methods for Pruning Deep Neural Networks. You can skim this one, but it’s a good coverage of pruning – an empirical method whose success is surprising and is worth thinking about. | The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks. This is our second major theory paper. What explains the results found and answers the questions raised in 2, 3, 4, and 5? The Lottery Ticket Hypothesis is a compelling theory. | Deconstructing Lottery Tickets: Zeros, Signs, and the Supermask. A further investigation into the Lottery Ticket Hypothesis. | What’s Hidden in a Randomly Weighted Neural Network? A fascinating result from the Lottery Ticket Hypothesis. | Neural Tangent Kernel. Choose at least one of these to read. | https://lilianweng.github.io/posts/2022-09-08-ntk/ | https://blog.ml.cmu.edu/2019/10/03/ultra-wide-deep-nets-and-the-neural-tangent-kernel-ntk/ | https://rajatvd.github.io/NTK/ | https://www.inference.vc/neural-tangent-kernels-some-intuition-for-kernel-gradient-descent/ | . | The Modern Mathematics of Deep Learning. A landmark work in developing a mathematical theory of deep learning. Skim sections 2.3, 3.2, 3.3, and 4. Make sure you at least understand the results at a high level. | Language Models (Mostly) Know What They Know. A theoretical method for probing language model knowledge reveals interesting epistemic structures. | Bonus: A Mathematical Framework for Transformer Circuits. Think you know how transformers work? Think again! | . Fairness, Responsibility, Safety . | A Survey on Bias and Fairness in Machine Learning. A good and comprehensive survey of general concerns and approaches to addressing bias in machine learning problems. | On the (im)possibility of fairness. No need to read it too in detail; skimming it and understanding the main result is fine. Argues that different mathematized components of algorithmic fairness are fundamentally incompatible with each other in the ideal. | The Myth in the Methodology: Towards a Recontextualization of Fairness in Machine Learning. We’ve got it all wrong, philosopher Lily Hu shows us. Fairness cannot be mathematized. | What’s sex got to do with fair machine learning? An investigation of gender variables in machine learning models. | What is ‘race’ in algorithmic discrimination on the basis of race? An investigation of race variables in machine learning methods. | Moving beyond “algorithmic bias is a data problem”. Sara Hooker takes on the pervasive idea of GIGO (Garbage In, Garbage Out) suggests that data is the root source of bias. | What Do Compressed Deep Neural Networks Forget? An empirical follow-up from the previous opinion piece. How do different compression methods affect model performance? . | Optional: Characterizing and Mitigating Bias in Compact Models. Related work if you are interested in additional research in this direction. | . | The Curious Case of Common Sense. Our very own professor Yejin Choi reflects on the difficulty of codifying common sense into AI models. | You may be interested in Yejin Choi’s research papers, each of which address different dimensions of common sense reasoning: https://homes.cs.washington.edu/~yejin/ | . | Can Machines learn Morality? The Delphi Experiment. An attempt to train a language model to understand commonsense morality. You can play with the Delphi model at https://delphi.allenai.org/. | Constitutional AI: Harmlessness from AI Feedback. An important proposal for a framework to regulate AI with AI from a set of constitutional principles. | Predictability and Surprise in Large Generative Models. An empirical and theoretical investigation of the difficulties of regulating LLMs. | The Hardware Lottery. Thinking about how AI development is constrained by the hardware available. | Socially situated artificial intelligence enables learning from human interaction. A very interesting paper from our very own professor Ranjay Krishna on how humans can more actively engage with and shape AI models. | On the Opportunities and Risks of Foundation Models. A classic in AI safety. Read the introduction (section 1) and “Society” (section 5) at minimum. | The Dark Side of Techno-Utopianism. An accessible and thoughtful conclusion to this unit: what is our role in tech, and is it as rosy as we think it is? | . Task . Read the GPT-3 paper, the GPT-4 model card, or the LaMDA paper (or another recent large language model paper). Focus on the discussions on safety and fairness. Drawing upon the sources in both the theory and the fairness sections of this unit, criticize the evaluations – identify what is mistaken, what assumptions are made, what is socially problematic, what possible biases may have been unidentified or which lie latent in the design, etc. ",
    "url": "/pr-preview/pr-36/megadoc/unit-09/#unit-9-fairness-and-theory",
    
    "relUrl": "/megadoc/unit-09/#unit-9-fairness-and-theory"
  },"85": {
    "doc": "Unit 09",
    "title": "Unit 09",
    "content": " ",
    "url": "/pr-preview/pr-36/megadoc/unit-09/",
    
    "relUrl": "/megadoc/unit-09/"
  },"86": {
    "doc": "Unit 10",
    "title": "Unit 10: Cognitive Science and Psychology of Reward and Pain",
    "content": "Task: This unit is very simple. Read our paper! (1 hr) . Paper: Deinforcement Learning v2 . Post your thoughts/questions if you have any! Be sure to review Unit 6 if you need a refresher on Reinforcement Learning. ",
    "url": "/pr-preview/pr-36/megadoc/unit-10/#unit-10-cognitive-science-and-psychology-of-reward-and-pain",
    
    "relUrl": "/megadoc/unit-10/#unit-10-cognitive-science-and-psychology-of-reward-and-pain"
  },"87": {
    "doc": "Unit 10",
    "title": "Unit 10",
    "content": " ",
    "url": "/pr-preview/pr-36/megadoc/unit-10/",
    
    "relUrl": "/megadoc/unit-10/"
  },"88": {
    "doc": "Unit 11",
    "title": "Unit 11: Building a Brain: Networks and Systems",
    "content": "It would be negligent not to begin by acknowledging the inadequacy of this chapter. The connectivity and wiring of the brain as well as the genetics and epigenetics that comprise it are far from fully understood, and these resources are merely scratching the surface of a profound ocean of literature and undiscovered territory of building the systems of a mind. Nonetheless, we begin with a lecture investigating the genetic and learned nature of human behaviors. Task 1: 10. Development, Nature &amp; Nurture I . Synthesis Questions: . | What is one possible mechanism for building knowledge from parts of the brain present at birth? What kinds of knowledge might be innate and \"precursory\"? . | Why might it be useful for those precursors of knowledge to be innate rather than learned? | Google and find 1-2 other possible rudimentary or innate processes in the brain. Do any machine learning techniques use similar innate predispositions or ingrained knowledge? | . | What is perceptual narrowing? Are there analogous processes, protocols, or side effects in machine learning? What are possible downsides and upsides of the effect? . | What might you wish you could learn faster, and what might be a cost to having neural architectures that support that kind of learning? | . | If humans are uniquely suited to recognizing faces, what might be a useful analogous skill in machine learning which may support more human-like behavior? | . Task 2: Next, briefly skim the questions below then indulge in this scintillating lecture describing brain modules and the discovery of their connected wiring! . Start watching at 8:40, 21. Brain Networks . For your reference, a voxel is a 3D pixel. Think of it as a minecraft block of the brain. Also a term used in computer graphics. Synthesis Questions: . | What is white matter? Why does it matter? | What is a connectivity fingerprint? . | Why might we care about the connectivity similarities of other species and what implications might findings in this research have? | . | Describe three large connections between major regions in the brain and what those regions do, using Google if necessary. | What is the default mode network? What purpose is it hypothesized to serve? . | If you were to build an analog of the DMN in a machine learning network placed in your favorite video game as an environment, what function would you design it to serve? | . | Hypothesize how multiple demand regions might work and why they might be necessary. I don't know the right answer here so go nuts. | . ",
    "url": "/pr-preview/pr-36/megadoc/unit-11/#unit-11-building-a-brain-networks-and-systems",
    
    "relUrl": "/megadoc/unit-11/#unit-11-building-a-brain-networks-and-systems"
  },"89": {
    "doc": "Unit 11",
    "title": "Project Spec:",
    "content": "There is no programming for this project. Instead, we have provided a LaTeX template for you to fill out. | If you are unaware of what $\\LaTeX$ is, you can read about it here. | . I would recommend taking a look at Overleaf to edit/compile $\\LaTeX$ code. Simply copy the code in the template into a blank Overleaf project and type your answers into the TODO areas. Be sure to hit the “Recompile” button to see your work. GH Link: Unit 11 Template (40 min) . The questions in the template are also written below: . Ohhh this one’s good. I’m tapping my fingers together like Dr. Evil. You are designing an egg. It will become a lifeform on a new planet. The planet is almost completely covered in water. Small islands made from underwater volcanoes dot the surface. The gravity is stronger on this planet and the biodiversity is lower than on Earth. There is less direct sunlight and fewer living organisms in general. Your task is to design the brain and the phenotypes of a successful organism on this new planet, using some of the neuroscience and machine learning principles you have learned so far. Your designed brain and nervous system will be translated into genetic instructions and inserted into an egg that will be sent to the new planet. Be as specific as you can so your egg doesn’t become a mutant! . If you are stuck, here are some options for getting started . | What do you consider a successful organism? | What kinds of traits would support this success; what kinds of organisms on Earth have these traits? | What parts of the brain support these traits and what kind of machine learning algorithms might also exhibit these abilities? | How might these different traits and abilities need to work together, or connect? | . ",
    "url": "/pr-preview/pr-36/megadoc/unit-11/#project-spec",
    
    "relUrl": "/megadoc/unit-11/#project-spec"
  },"90": {
    "doc": "Unit 11",
    "title": "Unit 11",
    "content": " ",
    "url": "/pr-preview/pr-36/megadoc/unit-11/",
    
    "relUrl": "/megadoc/unit-11/"
  },"91": {
    "doc": "Unit 12",
    "title": "Unit 12: Human Characteristics of the Brain",
    "content": "Several traits of humans appear to be unique to our species and may be essential in designing an intelligence similar to our own. This chapter is dedicated to the study of these phenomena of our brains. We begin by trying to peel back the layers of humans’ strong social tendencies: . Task 1: Complete the following lecture and synthesis questions. 20. Theory of Mind &amp; Mentalizing . Synthesis Questions: . | Describe the false belief paradigm and what function it serves. | What part of the brain is/are specifically involved in thinking about others' thoughts? Where is it located? What are several close by modules and their functions? | Google the terms TMS, EEG, and DBS. What are several differences and similarities between these cognitive science methods? | . Task 2: Depending on your level of comfort with languge modeling, take a look at the following resources below, and then watch the Attention and Awareness lecture. If you are familiar with Attention in Transformers, try comparing and contrasting to what the lecture says about the brain. If you are not familiar with Attention in Transformers, just learn what you can from the video purely from a neuroscience standpoint. If we have not completed the LM unit yet, Attention in ML may not be the most familiar. If you would like, here are some resources to prime your understanding: . Optional: A very comprehensive and visually helpful intuition for what the attention mechanism actually does: Attention Mechanism In a Nutshell . Optional: If you want to play with the math behind LLMs, this is pretty cool: 3Blue1Brown: Attention in Transformers . Optional: Self Attention Colab Notebook . For a deeper dive, feel free to take a look at the Language Modeling chapter of this document. Now we will dive into the capabilities of the brain and its own beautiful, endogenous attention mechanisms! . 24. Attention and Awareness . Synthesis Questions: . | Describe the brain's ability to multitask? What are some scenarios where parallel processing is feasible and some where it is not? | Describe covert and overt attention. | Describe \"priming the visual cortex\" why it might be useful. | \"You have 10x as many connections going down from cortex, down to the LGN ([lateral geniculate nucleus](https://en.wikipedia.org/wiki/Lateral_geniculate_nucleus))… than going forward. One of the things you're doing is setting up selective filters so that only the stuff you want to process makes it to higher stages.\" Compare this fact to deep learning algorithms. | Describe the role of the Fronto-Parietal Attention Network | If familiar with Attention in ML: Research some machine learning attention mechanisms. Compare and contrast the mechanism and the capabilities of one with what you learned about our biological attention mechanism. | . ",
    "url": "/pr-preview/pr-36/megadoc/unit-12/#unit-12-human-characteristics-of-the-brain",
    
    "relUrl": "/megadoc/unit-12/#unit-12-human-characteristics-of-the-brain"
  },"92": {
    "doc": "Unit 12",
    "title": "Project Spec",
    "content": "Consider, for a moment, the ways in which there are or are not parallels between our current mechanisms of machine learning and the various modules and functions of the brain that we have learned about. In your opinion, are some crucial for intelligence? Which, if any, have we managed to emulate with algorithms? . Now consider attention. The brain seems to block out unwanted information from ever being processed (about minute 8:00, Attention and Awareness). Are there ML algorithms that do this? Should they? What should the function of attention be? Does it depend on the context or is it a fixed algorithm for all contexts? . Write some thoughts (200+ words) on these questions. Then, finally, find one article on Grey Matters that interests you and consider how it relates to the above questions. Provide the link and some thoughts :) . ",
    "url": "/pr-preview/pr-36/megadoc/unit-12/#project-spec",
    
    "relUrl": "/megadoc/unit-12/#project-spec"
  },"93": {
    "doc": "Unit 12",
    "title": "Unit 12",
    "content": " ",
    "url": "/pr-preview/pr-36/megadoc/unit-12/",
    
    "relUrl": "/megadoc/unit-12/"
  },"94": {
    "doc": "Unit 13",
    "title": "Unit 13: Intro to Movement",
    "content": "We are now going to be learning about how your brain makes you act and move in your environment. We start by investigating the cerebellum. This will tie into Reinforcement Learning (RL), so pay attention! . First, a few useful vocab words: . Afferent: Conducting towards something . Efferent: Conducting away from something . Task 1: Read the sections entitled “Feed forward control systems” and “The cerebellum may be a feedforward control system” from the notes here to get a sense for the purpose of the cerebellum. Cerebellum – The University of Texas Medical School . Then, watch the following brief videos, take notes if you’d like! . 2-Minute Neuroscience: Cerebellum . 19.3 Cerebellar Information Flow . Synthesis Questions: . | Explain the difference between mossy fibers and climbing fibers and their respective functions. | Which cells or fibers may be responsible for sending error signals to the cerebellum? | What is the function of a Purkinje cell? To what do they output? What do they look like? Why might they look like this? | What are the primary input sources of the cerebellum? Where do these signals originate? | . For more depth on these topics, here are some more fabulous resources. Bonus Videos: . 19.4 Cerebellar Circuits . 19.5 Afferent Tracts to the Cerebellum . ",
    "url": "/pr-preview/pr-36/megadoc/unit-13/#unit-13-intro-to-movement",
    
    "relUrl": "/megadoc/unit-13/#unit-13-intro-to-movement"
  },"95": {
    "doc": "Unit 13",
    "title": "Project Spec",
    "content": "There is no project for this unit yet. We hope to make one soon! . ",
    "url": "/pr-preview/pr-36/megadoc/unit-13/#project-spec",
    
    "relUrl": "/megadoc/unit-13/#project-spec"
  },"96": {
    "doc": "Unit 13",
    "title": "Unit 13",
    "content": " ",
    "url": "/pr-preview/pr-36/megadoc/unit-13/",
    
    "relUrl": "/megadoc/unit-13/"
  },"97": {
    "doc": "Unit A",
    "title": "Unit A: Gradient Descent Deep Dive",
    "content": "A deeper dive into Gradient Descent where you will be implementing backpropagation on your own! This is an involved unit that, while technically not required, will push your understanding of neural networks to the max. Task 1: Watch the following video and implement micrograd as specified: . The spelled-out intro to neural networks and backpropagation: building micrograd . The templates we made for you can be found here. Additionally, please implement the ReLU nonlinearity for the Value class. | (Note: if you’re having a hard time with this, take a look at this code.) | . Implement and train a small neural network using micrograd. The training, validation, and test data will be included in the starter code. - Try to find the best network you can! . You might want to change the learning rate, size of the network, or Note your training, validation, and test loss for your best network. Synthesis Questions: . | In what direction do gradients flow (with regards to loss)? | How do gradients flow through addition? How do they flow through the ReLU function? | What was your best loss for the test dataset? | Was there something that stood out to you? Something that confused you? | What's one resource that was helpful (suggested or found on your own)? | . ",
    "url": "/pr-preview/pr-36/megadoc/unit-A/#unit-a-gradient-descent-deep-dive",
    
    "relUrl": "/megadoc/unit-A/#unit-a-gradient-descent-deep-dive"
  },"98": {
    "doc": "Unit A",
    "title": "Unit A",
    "content": " ",
    "url": "/pr-preview/pr-36/megadoc/unit-A/",
    
    "relUrl": "/megadoc/unit-A/"
  },"99": {
    "doc": "Unit B",
    "title": "Unit B: Neuroscience of Creativity",
    "content": "Are you curious about the mysterious force of invention, art, mathematics, and more that seems to allow the mind to expand beyond the information it was given to create beautiful new ideas? This is creativity, and with neuroscience, we can begin to dissect it such that we can begin to recreate it. Task 1: Listen or watch the following podcast (also available on Spotify if you prefer) and answer the Synthesis questions! . The Science of Creativity &amp; How to Enhance Creative Innovation - Huberman Lab . Synthesis Questions: . | TODO: add questions | . ",
    "url": "/pr-preview/pr-36/megadoc/unit-B/#unit-b-neuroscience-of-creativity",
    
    "relUrl": "/megadoc/unit-B/#unit-b-neuroscience-of-creativity"
  },"100": {
    "doc": "Unit B",
    "title": "Unit B",
    "content": " ",
    "url": "/pr-preview/pr-36/megadoc/unit-B/",
    
    "relUrl": "/megadoc/unit-B/"
  }
}
